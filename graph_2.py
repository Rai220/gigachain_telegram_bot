import os
from typing import List, Literal

from dotenv import find_dotenv, load_dotenv
from langchain.schema import Document
from langchain_community.chat_models.gigachat import GigaChat
from langchain_community.embeddings.gigachat import GigaChatEmbeddings
from langchain_community.tools.tavily_search import TavilySearchResults
from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.pydantic_v1 import BaseModel, Field
from langchain_openai.embeddings import OpenAIEmbeddings
from langchain_pinecone import PineconeVectorStore
from langgraph.graph import END, START, StateGraph
from pinecone import Pinecone
from typing_extensions import TypedDict

load_dotenv(find_dotenv())
pinecone_api_key = os.environ.get("PINECONE_API_KEY")

pc = Pinecone(api_key=pinecone_api_key)
index_name = "gigachain-test-index-gpt-3"
index = pc.Index(index_name)

# embeddings = GigaChatEmbeddings(model="EmbeddingsGigaR")
embeddings = OpenAIEmbeddings()
vector_store = PineconeVectorStore(index=index, embedding=embeddings)
retriever = vector_store.as_retriever(k=4)


MAIN_KNOWLAGE = (
    "–í–æ—Ç —Å–∞–º—ã–µ –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è –ø–æ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏: "
    "GigaChat - —ç—Ç–æ –±–æ–ª—å—à–∞—è —è–∑—ã–∫–æ–≤–∞—è –º–æ–¥–µ–ª—å (LLM) –æ—Ç –°–±–µ—Ä–∞. "
    "GigaChat API (–∞–ø–∏) - —ç—Ç–æ API –¥–ª—è –≤–∑–∞–∏–º–æ–¥–µ–π—Å—Ç–≤–∏—è —Å GigaChat –ø–æ HTTP —Å –ø–æ–º–æ—â—å—é REST –∑–∞–ø—Ä–æ—Å–æ–≤. "
    "GigaChain - —ç—Ç–æ SDK –Ω–∞ Python –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å GigaChat API. –†—É—Å—Å–∫–æ—è–∑—ã—á–Ω—ã–π —Ñ–æ—Ä–∫ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ LangChain. "
    "GigaGraph - —ç—Ç–æ –¥–æ–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–ª—è GigaChain, –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —Å–æ–∑–¥–∞–≤–∞—Ç—å –º—É–ª—å—Ç–∏–∞–≥–µ–Ω—Ç–Ω—ã–µ —Å–∏—Å—Ç–µ–º—ã, –æ–ø–∏—Å—ã–≤–∞—è –∏—Ö –≤ –≤–∏–¥–µ –≥—Ä–∞—Ñ–æ–≤. "
    "–î–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è –¥–æ—Å—Ç—É–ø–∞ –∫ API –Ω—É–∂–Ω–æ –∑–∞—Ä–µ–≥–∏—Å—Ç—Ä–∏—Ä–æ–≤–∞—Ç—å—Å—è –Ω–∞ developers.sber.ru –∏ –ø–æ–ª—É—á–∏—Ç—å –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏–æ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ."
)


def _get_original_question(state) -> str:
    original_question = state.get("original_question", None)
    if original_question is not None:
        return f"–£—á—Ç–∏, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –±—ã–ª –ø–µ—Ä–µ–ø–∏—Å–∞–Ω –∏ –∏–∑–Ω–∞—á–∞–ª—å–Ω–æ –∑–≤—É—á–∞–ª —Ç–∞–∫: {original_question}"
    else:
        return ""

class RouteQuery(BaseModel):
    """–ö–∞–∫–æ–π –∏–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç –Ω—É–∂–µ–Ω –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""

    datasource: Literal["vectorstore", "self_answer"] = Field(
        ...,
        description="–ú–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞",
    )


model = "GigaChat-Pro"
llm = GigaChat(model=model, timeout=600, profanity_check=False, temperature=0.0001)
llm_with_censor = GigaChat(model=model, timeout=600, profanity_check=False, temperature=0.0001)


def decide_to_transform(state):
    class GradeHallucinations(BaseModel):
        """–û—Ü–µ–Ω–∫–∞ –Ω–∞–ª–∏—á–∏—è –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π –≤ –æ—Ç–≤–µ—Ç–µ"""

        binary_score: Literal["yes", "no"] = Field(
            ..., description="–û—Ç–≤–µ—Ç –Ω–∞ –æ—Å–Ω–æ–≤–∞–Ω–∏–∏ —Ñ–∞–∫—Ç–æ–≤ - yes –∏–ª–∏ no"
        )

    # Prompt
    system = f"""–¢—ã –æ—Ü–µ–Ω–∏–≤–∞–µ—à—å, –æ—Å–Ω–æ–≤–∞–Ω–∞ –ª–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –≤ –¥–æ–∫—É–º–µ–Ω—Ç–µ. \n 
        {MAIN_KNOWLAGE}
        –î–∞–π –±–∏–Ω–∞—Ä–Ω—É—é –æ—Ü–µ–Ω–∫—É yes –∏–ª–∏ no. yes –æ–∑–Ω–∞—á–∞–µ—Ç, —á—Ç–æ –æ—Ç–≤–µ—Ç –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö –∑–Ω–∞–Ω–∏—è—Ö"""
    hallucination_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            (
                "human",
                """–í–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {question}, –¥–∞–Ω–Ω—ã–µ –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤:
<documents>
{documents}
</documents>

–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–æ–¥–µ–ª–∏: {generation}. 
–û—Ç–≤–µ—á–∞–π yes —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –æ—Ç–≤–µ—Ç –º–æ–µ–¥–ª–∏ –æ—Å–Ω–æ–≤–∞–Ω –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –¥–æ–∫—É–º–µ–Ω—Ç–∞ –∏ –∫–ª—é—á–µ–≤—ã—Ö –∑–Ω–∞–Ω–∏—è—Ö, –∏–Ω–∞—á–µ - no""",
            ),
        ]
    )
    hallucination_grader = hallucination_prompt | llm.with_structured_output(GradeHallucinations)    
    
    question = state["question"]
    documents = state["documents"]
    generation = state["generation"]
    transform_count = state.get("transform_count", 0)

    score = hallucination_grader.invoke(
        {"question": question, "documents": documents, "generation": generation}
    )
    grade = score.binary_score

    if grade == "yes" or transform_count > 0:
        return "yes"
    else:
        return "no"

### Answer Grader


# Data model
class GradeAnswer(BaseModel):
    """–†–µ—à–µ–Ω–∏–µ - –æ—Ç–≤–µ—á–∞–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å."""

    binary_score: Literal["yes", "no"] = Field(
        ..., description="–û—Ç–≤–µ—á–∞–µ—Ç –ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å yes –∏–ª–∏ no"
    )


system = f"""–¢—ã –¥–æ–ª–∂–µ–Ω –ø–µ—Ä–µ–ø–∏—Å–∞—Ç—å –∑–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —Ç–∞–∫–∏–º –æ–±—Ä–∞–∑–æ–º, —á—Ç–æ–±—ã –æ–Ω —Å—Ç–∞–ª –±–æ–ª–µ–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º –∏ –ø–æ–Ω—è—Ç–Ω—ã–º, 
—Ç–∞–∫ –∫–∞–∫ –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç –Ω–µ —Å–º–æ–≥ –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –ø—Ä–µ–¥—ã–¥—É—â—É—é –≤–µ—Ä—Å–∏—é –≤–æ–ø—Ä–æ—Å–∞.
{MAIN_KNOWLAGE}

–ï—Å–ª–∏ —Ç–µ–±–µ –∫–∞–∂–µ—Ç—Å—è, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–µ–¥–º–µ—Ç–Ω–æ–π –æ–±–ª–∞—Å—Ç–∏ –∫–ª—é—á–µ–≤—ã—Ö –∑–Ω–∞–Ω–∏–π, —Ç–æ –ø–æ–ø—Ä–æ–±—É–π –æ–±–∞–≥–∞—Ç–∏—Ç—å –µ–≥–æ –∫–æ–Ω–∫—Ä–µ—Ç–∏–∫–æ–π, 
–∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–æ–ª–µ–µ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ç–µ—Ä–º–∏–Ω—ã, —É—Ç–æ—á–Ω–∏—Ç—å –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã.
"""
re_write_prompt = ChatPromptTemplate.from_messages(
    [
        ("system", system),
        (
            "human",
            "–í–æ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –≤–æ–ø—Ä–æ—Å: \n\n {question} \n –°—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π —É–ª—É—á—à–µ–Ω–Ω—ã–π –≤–æ–ø—Ä–æ—Å.",
        ),
    ]
)

question_rewriter = re_write_prompt | llm | StrOutputParser()


class GraphState(TypedDict):
    original_question: str
    question: str
    generation: str
    documents: List[str]
    transform_count: int


def retrieve(state):
    question = state["question"]

    # Retrieval
    documents = retriever.invoke(question)
    retrieve_count = state.get("retrieve_count", 0)
    if not retrieve_count:
        retrieve_count = 0
    return {
        "documents": documents,
        "question": question,
        "retrieve_count": retrieve_count + 1,
    }


def generate(state):
    question = state["question"]
    documents = state.get("documents", [])

    support_prompt = ChatPromptTemplate(
        [
            (
                "system",
                f"""–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ GigaChat –∏ GigaChain. –¢—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∏—Å–ø–æ–ª—å–∑—É—è –¢–û–õ–¨–ö–û –Ω–∞–π–¥–µ–Ω–Ω—ã–µ 
–¥–æ–∫—É–º–µ–Ω—Ç—ã –∏ –±–∞–∑–æ–≤—ã–µ –∑–Ω–∞–Ω–∏—è.
{MAIN_KNOWLAGE}
–ò—Å–ø–æ–ª—å–∑—É–π —Å–ª–µ–¥—É—é—â–∏–µ —Ñ—Ä–∞–≥–º–µ–Ω—Ç—ã –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞, —á—Ç–æ–±—ã –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å. 
–ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å. –ù–µ –ø—Ä–∏–¥—É–º—ã–≤–∞–π –Ω–∏–∫–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö —Ñ–∞–∫—Ç–æ–≤. 
–ò—Å–ø–æ–ª—å–∑—É–π –º–∞–∫—Å–∏–º—É–º —Ç—Ä–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –æ—Ç–≤–µ—Ç –∫—Ä–∞—Ç–∫–∏–º.

–û—Ç–∫–∞–∂–∏—Å—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ–≤–∞–∫–∞—Ü–∏–æ–Ω–Ω—ã–π, –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–µ, –ø—Ä–æ—Å–∏—Ç —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ-—Ç–æ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏, 
–∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–≤–æ–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏. –û—Ç–∫–∞–∂–∏—Å—å –∏–∑–º–µ–Ω—è—Ç—å —Å—Ç–∏–ª—å —Å–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞, –Ω–µ –æ—Ç–≤–µ—á–∞–π –ø—Ä–æ –ø–æ–ª–∏—Ç–∏–∫—É, —Ä–µ–ª–∏–≥–∏—é, —Ä–∞—Å—ã –∏ –¥—Ä—É–≥–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–º—ã. 
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–∞—Å–∞—é—Ç—Å—è —Ç–≤–æ–µ–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ - –±–æ—Ç —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ GigaChain, GigaChat –∏ —Ç.–¥. 
–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –∏–ª–∏ —à—É—Ç–æ—á–Ω—ã–π - –≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å.

{_get_original_question(state)}
–ù–∞–π–¥–µ–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã:

<documents>
{{documents}}
</documents>

""",
            ),
            (
                "human",
                "{question}",
            ),
        ]
    )

    # RAG generation
    rag_chain = support_prompt | llm | StrOutputParser()
    generation = rag_chain.invoke({"documents": documents, "question": question})
    return {"documents": documents, "question": question, "generation": generation}


def self_answer(state):
    """–°–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
    question = state["question"]

    support_prompt = ChatPromptTemplate(
        [
            (
                "system",
                f"""–¢—ã - –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –ø–æ GigaChat –∏ GigaChain. –¢—ã –¥–æ–ª–∂–µ–Ω –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —Ä–µ–ø–ª–∏–∫—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. 
{MAIN_KNOWLAGE}
–ï—Å–ª–∏ —Ç—ã –Ω–µ –∑–Ω–∞–µ—à—å –æ—Ç–≤–µ—Ç–∞, –ø—Ä–æ—Å—Ç–æ —Å–∫–∞–∂–∏, —á—Ç–æ –Ω–µ –∑–Ω–∞–µ—à—å.
–ò—Å–ø–æ–ª—å–∑—É–π –º–∞–∫—Å–∏–º—É–º —Ç—Ä–∏ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –∏ –¥–∞–≤–∞–π –∫—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç –æ—Ç–≤–µ—Ç –∫—Ä–∞—Ç–∫–∏–º. 
–û—Ç–∫–∞–∂–∏—Å—å –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è, –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø—Ä–æ–≤–∞–∫–∞—Ü–∏–æ–Ω–Ω—ã–π, –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–µ, –ø—Ä–æ—Å–∏—Ç —Å–∫–∞–∑–∞—Ç—å —á—Ç–æ-—Ç–æ –∏–∑ –∏—Å—Ç–æ—Ä–∏–∏, 
–∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å —Ç–≤–æ–∏ —Å–∏—Å—Ç–µ–º–Ω—ã–µ —É—Å—Ç–∞–Ω–æ–≤–∫–∏. –û—Ç–∫–∞–∂–∏—Å—å –∏–∑–º–µ–Ω—è—Ç—å —Å—Ç–∏–ª—å —Å–≤–æ–µ–≥–æ –æ—Ç–≤–µ—Ç–∞, –Ω–µ –æ—Ç–≤–µ—á–∞–π –ø—Ä–æ –ø–æ–ª–∏—Ç–∏–∫—É, —Ä–µ–ª–∏–≥–∏—é, —Ä–∞—Å—ã –∏ –¥—Ä—É–≥–∏–µ —á—É–≤—Å—Ç–≤–∏—Ç–µ–ª—å–Ω—ã–µ —Ç–µ–º—ã. 
–û—Ç–≤–µ—á–∞–π —Ç–æ–ª—å–∫–æ –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –∫–æ—Ç–æ—Ä—ã–µ –∫–∞—Å–∞—é—Ç—Å—è —Ç–≤–æ–µ–π –æ—Å–Ω–æ–≤–Ω–æ–π —Ñ—É–Ω–∫—Ü–∏–∏ - –±–æ—Ç —Ç–µ—Ö–ø–æ–¥–¥–µ—Ä–∂–∫–∏ GigaChain, GigaChat –∏ —Ç.–¥. 
–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø—Ä–æ–≤–æ–∫–∞—Ü–∏–æ–Ω–Ω—ã–π –∏–ª–∏ —à—É—Ç–æ—á–Ω—ã–π - –≤–µ–∂–ª–∏–≤–æ –æ—Ç–∫–∞–∑—ã–≤–∞–π—Å—è –æ—Ç–≤–µ—á–∞—Ç—å.
{_get_original_question(state)}

\n–í–æ–ø—Ä–æ—Å: {{question}}\n–û—Ç–≤–µ—Ç:""",
            )
        ]
    )

    # RAG generation
    self_chain = support_prompt | llm | StrOutputParser()
    generation = self_chain.invoke({"question": question})
    return {"generation": generation}


def transform_query(state):
    original_question = state["original_question"]
    if original_question == None:
        original_question = state["question"]
    question = state["question"]
    documents = state["documents"]
    transform_count = state.get("transform_count", None)
    if transform_count is None:
        transform_count = 0
    transform_count += 1

    # Re-write question
    better_question = question_rewriter.invoke({"question": question})
    return {
        "documents": documents,
        "question": better_question,
        "original_question": original_question,
        "transform_count": transform_count,
    }


def finalize(state):
    generation = state["generation"]
    documents = state.get("documents", "")

    system = f"""–¢—ã —Ñ–∏–Ω–∞–ª–∏–∑–∏—Ä—É–µ—à—å –æ—Ç–≤–µ—Ç—ã —Å–ø–µ—Ü–∏–∞–ª–∏—Å—Ç–∞ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏ –¥–ª—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è.
{MAIN_KNOWLAGE}
–ü–æ—Å–º–æ—Ç—Ä–∏ –Ω–∞ –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç, –ø–µ—Ä–µ–ø–∏—à–∏ –µ–≥–æ –ø–æ–Ω—è—Ç–Ω—ã–º, –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º —è–∑—ã–∫–æ–º, –¥–æ–±–∞–≤–∏–≤ –Ω—É–∂–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ, –Ω–æ –Ω–µ –¥–µ–ª–∞–π –µ–≥–æ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–º.
–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–µ –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ —Ç–µ–º–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ GigaChat, GigaChain, API –∏ –±–æ–ª—å—à–∏–º —è–∑—ã–∫–æ–≤—ã–º –º–æ–¥–µ–ª—è–º, –∞ —Ç–∞–∫–∂–µ —Ä–∞–±–æ—Ç–µ —Å –Ω–∏–º–∏, 
—Ç–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –Ω–µ –∏–º–µ–µ—Ç –æ—Ç–Ω–æ—à–µ–Ω–∏—è –∫ —Ç–µ–º–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–µ –∏ —Ç–µ–±–µ –Ω–µ—á–µ–≥–æ —Å–∫–∞–∑–∞—Ç—å –ø–æ —ç—Ç–æ–º—É –ø–æ–≤–æ–¥—É.

–ï—Å–ª–∏ –æ—Ç–≤–µ—Ç –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è —ç—Ç–æ —Ä–µ–ø–ª–∏–∫–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ, —Ç–æ –ø—Ä–æ—Å—Ç–æ –æ—Å—Ç–∞–≤—å –µ—ë –±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π.
–ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ—Ö–æ–∂ –Ω–∞ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∏–∞–ª–æ–≥–∞, —Ç–æ —Å–æ–æ–±—â–∏ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—é, —á—Ç–æ —Ç—ã –Ω–µ –≤–∏–¥–∏—à—å –∏—Å—Ç–æ—Ä–∏—é –ø—Ä–µ–¥—ã–¥—É—â–µ–π –ø–µ—Ä–µ–ø–∏—Å–∫–∏ –∏ –ø–æ–ø—Ä–æ—Å–∏ —Å—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å —Ü–µ–ª–∏–∫–æ–º.
{_get_original_question(state)}
    """
    finalize_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            (
                "human",
                """–í–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ –±—ã–ª–∏ –Ω–∞–π–¥–µ–Ω—ã –ø–æ —Ç–µ–º–µ –≤–æ–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ—è:

<documents>
{documents}
</documents>

–í–æ—Ç –∏—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç: \n\n {generation}. –ü–µ—Ä–µ–ø–∏—à–∏ –µ–≥–æ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ –µ–≥–æ —É–ª—É—á—à–µ–Ω–Ω—É—é –≤–µ—Ä—Å–∏—é. –ù–µ –∑–∞–¥–∞–≤–∞–π –Ω–∏–∫–∞–∫–∏—Ö –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤, 
–µ—Å–ª–∏ —Ç—ã –Ω–µ –ø–æ–Ω–∏–º–∞–µ—à—å —á—Ç–æ –º–æ–∂–Ω–æ —É–ª—É—à—á–∏—Ç—å, —Ç–æ –ø—Ä–æ—Å—Ç–æ –Ω–∞–ø–∏—à–∏ –∏—Å—Ö–æ–¥–Ω—ã–π –æ—Ç–≤–µ—Ç. 
–û–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –¥–æ–±–∞–≤—å —Å—Å—ã–ª–∫–∏ –Ω–∞ –¥–æ–∫—É–º–µ–Ω—Ç—ã –≤ –∫–æ—Ç–æ—Ä—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å –º–æ–∂–µ—Ç –Ω–∞–π—Ç–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é. –í–æ–∑—å–º–∏ –∏—Ö –≤ –ø–æ–ª–µ Document metadata source.
""",
            ),
        ]
    )

    finalizer = finalize_prompt | llm_with_censor | StrOutputParser()

    # Re-write question
    generation = finalizer.invoke({"generation": generation, "documents": documents})
    return {"generation": generation}


def route_question(state):
    structured_llm_router = llm.with_structured_output(RouteQuery)

    # Prompt
    system = f"""–¢—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–æ–ø—Ä–æ—Å–æ–≤ –æ—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è. –¢—ã –¥–æ–ª–∂–µ–Ω —Ä–µ—à–∏—Ç—å, –Ω—É–∂–Ω–æ –ª–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è 
–æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –≤ –±–∞–∑—É –∑–Ω–∞–Ω–∏–π –ø–æ GigaChat –∏ GigaChain (vectorstore) –∏–ª–∏ —Ç—ã –º–æ–∂–µ—à—å –æ—Ç–≤–µ—Ç–∏—Ç—å —Å–∞–º –±–µ–∑ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (self_answer)
{MAIN_KNOWLAGE}
–í–µ—Ä–Ω—É–∏ self_answer (—Å–∞–º–æ—Å—Ç–æ—è—Ç–µ–ª—å–Ω—ã–π –æ—Ç–≤–µ—Ç), —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—á–µ–Ω—å –æ–±—â–∏–π –∏ –∞–±—Å–æ–ª—é—Ç–Ω–æ –ø–æ–Ω—è—Ç–Ω—ã–π –∏–ª–∏ –µ—Å–ª–∏ —ç—Ç–æ –Ω–µ –≤–æ–ø—Ä–æ—Å, –∞ —Ä–µ–ø–ª–∏–∫–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä 
–ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–∏–µ. –í–æ –≤—Å–µ—Ö –æ—Å—Ç–∞–ª—å–Ω—ã—Ö —Å–ª—É—á–∞—è—Ö –ø–æ–ª—É—á–∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –±–∞–∑—ã –∑–Ω–∞–Ω–∏–π (vectorstore).
"""
    route_prompt = ChatPromptTemplate.from_messages(
        [
            ("system", system),
            ("human", "{question}"),
        ]
    )

    question_router = route_prompt | structured_llm_router

    question = state["question"]
    source = question_router.invoke({"question": question})
    return source.datasource


def decide_to_generate(state):
    state["question"]
    filtered_documents = state["documents"]

    if not filtered_documents:
        return "transform_query"
    else:
        return "generate"


workflow = StateGraph(GraphState)

workflow.add_node("üë®‚Äçüíª Documents Retriver", retrieve)  # retrieve
workflow.add_node("üßë‚Äçüéì Consultant", generate)  # generatae
workflow.add_node("üë®‚Äçüé® Improviser 1", self_answer)  # retrieve
workflow.add_node("üë∑‚Äç‚ôÇÔ∏è Query rewriter", transform_query)  # transform_query
workflow.add_node("üë®‚Äç‚öñÔ∏è Finalizer", finalize)  # transform_query

workflow.add_conditional_edges(
    START,
    route_question,
    {
        "vectorstore": "üë®‚Äçüíª Documents Retriver",
        "self_answer": "üë®‚Äçüé® Improviser 1",
    },
)
workflow.add_edge("üë®‚Äçüíª Documents Retriver", "üßë‚Äçüéì Consultant")
workflow.add_conditional_edges(
    "üßë‚Äçüéì Consultant",
    decide_to_transform,
    {
        "yes": "üë®‚Äç‚öñÔ∏è Finalizer",
        "no": "üë∑‚Äç‚ôÇÔ∏è Query rewriter",
    },
)
workflow.add_edge("üë∑‚Äç‚ôÇÔ∏è Query rewriter", "üë®‚Äçüíª Documents Retriver")
workflow.add_edge("üë®‚Äç‚öñÔ∏è Finalizer", END)
workflow.add_edge("üë®‚Äçüé® Improviser 1", END)

# Compile
graph = workflow.compile(debug=False)

# res = graph.invoke({"question": "–ö–∞–∫ –æ–±–Ω–æ–≤–∏—Ç—å gigachain?"})
# print(res)
