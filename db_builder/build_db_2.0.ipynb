{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузка напрямую из документации GigaChat API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import Optional\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "from langchain_community.document_loaders.sitemap import SitemapLoader\n",
    "\n",
    "\n",
    "def metadata_extractor(\n",
    "    meta: dict, soup: BeautifulSoup, title_suffix: Optional[str] = None\n",
    ") -> dict:\n",
    "    title_element = soup.find(\"title\")\n",
    "    description_element = soup.find(\"meta\", attrs={\"name\": \"description\"})\n",
    "    html_element = soup.find(\"html\")\n",
    "    title = title_element.get_text() if title_element else \"\"\n",
    "    if title_suffix is not None:\n",
    "        title += title_suffix\n",
    "\n",
    "    return {\n",
    "        \"source\": meta[\"loc\"],\n",
    "        \"title\": title,\n",
    "        \"description\": description_element.get(\"content\", \"\")\n",
    "        if description_element\n",
    "        else \"\",\n",
    "        \"language\": html_element.get(\"lang\", \"\") if html_element else \"\",\n",
    "        **meta,\n",
    "    }\n",
    "\n",
    "def simple_extractor(html: str | BeautifulSoup) -> str:\n",
    "    if isinstance(html, str):\n",
    "        soup = BeautifulSoup(html, \"lxml\")\n",
    "    elif isinstance(html, BeautifulSoup):\n",
    "        soup = html\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Input should be either BeautifulSoup object or an HTML string\"\n",
    "        )\n",
    "    return re.sub(r\"\\n\\n+\", \"\\n\\n\", soup.text).strip()\n",
    "\n",
    "def load_gigachat_docs():\n",
    "    return SitemapLoader(\n",
    "        \"https://developers.sber.ru/docs/sitemap.xml\",\n",
    "        filter_urls=[r\".*/gigachat/.*\"],\n",
    "        parsing_function=simple_extractor,\n",
    "        default_parser=\"lxml\",\n",
    "        bs_kwargs={\"parse_only\": SoupStrainer(name=(\"article\", \"title\"))},\n",
    "        meta_function=lambda meta, soup: metadata_extractor(\n",
    "            meta, soup, title_suffix=\" | GigaChat\"\n",
    "        ),\n",
    "    ).load()\n",
    "\n",
    "\n",
    "def load_langchain_gigachat_docs():\n",
    "    return SitemapLoader(\n",
    "        \"https://developers.sber.ru/docs/sitemap.xml\",\n",
    "        filter_urls=[r\".*/gigachain/.*\"],\n",
    "        parsing_function=simple_extractor,\n",
    "        default_parser=\"lxml\",\n",
    "        bs_kwargs={\"parse_only\": SoupStrainer(name=(\"article\", \"title\"))},\n",
    "        meta_function=lambda meta, soup: metadata_extractor(\n",
    "            meta, soup, title_suffix=\" | langchain-gigachat\"\n",
    "        ),\n",
    "    ).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 58/58 [00:17<00:00,  3.29it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/about', 'title': 'Возможности GigaChat | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/about', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Возможности GigaChat | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Возможности GigaChatОбновлено 6 мая 2024GigaChat — это сервис, который умеет взаимодействовать с пользователем в формате диалога, писать код, создавать тексты и картинки по запросу пользователя. При этом GigaChat стремится избегать спорных этических вопросов или провокаций.GigaChat поддерживает русский и английский языки.Особенности и преимущества\\ufeffОбучение модели\\ufeffКорпус данных, использованных для обучения включает в себя книги и новости на русском и английском языках, разговорную речь, научные статьи и другие домены. Объем данных, использованных для обучения, составил 300 Гб. Домены постоянно пополняются и расширяются.Нейросетевая модель обучается по методу supervised fine-tuning, reinforcement learning with human feedback с помощью оценки ответов. Старайтесь оценивать каждый ответ GigaChat. Все оценки учитываются при дальнейшем обучении.Модальности GigaChat\\ufeffКроме текстовой модальности в GigaChat уже работает создание изображений с использованием модели Kandinsky 3.1. В планах развития работа со звуком и интеграция с другими инструментами через динамические модули.Работа с кодом\\ufeffДля обучения GigaChat использовались части датасета The Stack (открытый сет с кодом) от коллаборации исследователей BigCode, а также различные задачи по написанию кода, определению уязвимостей и ошибок.Как и с другими темами, ответы на вопросы по программированию нужно проверять самостоятельно.Оценка модели\\ufeffСравнение и оценка нейросетевой модели проводилась автоматически, полуавтоматически и вручную.Метрики, использованные при автоматической оценке:перплексия на отложенной выборке;сравнение ответов модели с эталонами при помощи метрик дистанции;оценка при помощи модели-оракула;описательные статистики, например, средняя длина ответа и лексическое разнообразие;контрастивная оценка;общепринятые наборы оценки, такие как RussianSuperGLUE и BigBench.При полуавтоматической оценке использовались диалоговые метрики безопасности, достоверности, грамотности и интересности.Обратная связь\\ufeffЕсли у вас остались вопросы, пишите нам на почту.GigaChat APIБыстрый старт для физических лиц'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/embeddings', 'title': 'Векторное представление текста | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/embeddings', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Векторное представление текста | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Векторное представление текстаОбновлено 14 ноября 2024Эмбеддинг (англ. embedding) — это вектор в виде массива чисел, который получается после преобразования текста языковой моделью.\\nПолученный вектор можно использовать для измерения семантического сходства преобразованного текста.\\nКомбинация чисел, составляющих вектор, действует как многомерная карта для измерения сходства.Векторное представление текста (эмбеддинг) используется для:улучшения качества поиска — эмбеддинги позволяют оценивать сходство между текстовыми запросами на основе расстояния между соответствующими векторами. Это позволяет улучшить качество поиска и релевантность результатов;уменьшения размерности данных — с помощью эмбеддингов вы можете представить текстовые запросы в виде числовых векторов, что позволяет снизить размерность данных и ускорить их обработку;обеспечения универсальности — эмбеддинги можно использовать для различных задач обработки естественного языка, таких как Retrieval Augmented Generation (RAG), классификация текстов, кластеризация и других.Для преобразования строк в эмбеддинги в GigaChat API есть метод POST /embeddings.\\nЗапрос выполняется к модели Embeddings (\"model\": \"Embeddings\") и авторизуется с помощью токена доступа.\\nДля работы с моделью и создания эмбеддингов вы также можете использовать GigaChain.Создание эмбеддингов оплачивается отдельно от генерации текста.Подробнее в разделе Тарифы и оплата.GigaChat APIGigaChainПример запроса на создание эмбеддинга:curl https://gigachat.devices.sberbank.ru/api/v1/embeddings \\\\  --header \\'Content-Type: application/json\\' \\\\  --header \\'Authorization: Bearer <токен доступа>\\' \\\\  --data \\'{    \"model\": \"Embeddings\",    \"input\": [        \"Расскажи о современных технологиях\",        \"Какие новинки в мире IT?\"    ]  }\\'Параметры запроса:model required string Default:  \"Embeddings\" Название модели, которая будет использована для создания эмбеддинга.\\ninput required Array of strings Строка или массив строк, которые будут использованы для генерации эмбеддинга.\\nCopy Expand all  Collapse all {\"model\": \"Embeddings\",\"input\": [\"Расскажи о современных технологиях\"]}Пример ответа:{  \"object\": \"list\",  \"data\": [    {      \"object\": \"embedding\",      \"embedding\": [        0.0023064255,        -0.009327292,        ...        -0.0028842222      ],      \"index\": 0    }  ],  \"model\": \"Embeddings\"}Параметры ответа:object required string Default:  \"list\" Формат структуры данных.\\ndata required Array of objects[ items ] modelstring Default:  \"Embeddings\" Название модели, которая используется для вычисления эмбеддинга.\\nCopy Expand all  Collapse all {\"object\": \"list\",\"data\": [{\"object\": \"embedding\",\"embedding\": [0],\"index\": 0,\"usage\": {\"prompt_tokens\": 6}}],\"model\": \"Embeddings\"}Для создания эмбеддингов с помощью SDK используйте функцию embed_documents(), модуля GigaChatEmbeddings, импортированного из langchain_community.embeddings.gigachat:from langchain_gigachat.embeddings import GigaChatEmbeddingsembeddings = GigaChatEmbeddings(credentials=\"ключ_авторизации\", verify_ssl_certs=False)result = embeddings.embed_documents(texts=[\"Привет!\"])print(result)В ответ функция возвращает массив чисел, представляющих значения эмбеддинга для переданного текста:[    [        0.72149658203125,        -0.18883895874023438,        0.013126373291015625,        -1.27783203125,        1.4967041015625,        -0.97698974609375,        -0.1722869873046875,        1.4625244140625,        ...        -0.007974624633789062,        -0.77838134765625,        1.167236328125    ]]Использование эмбеддингов для поиска\\ufeffПоиск по неструктурированному тексту — один из наиболее распространненых сценариев использования эмбеддингов.\\nДля этого:Создайте векторное представление текста, по которому будет выполняться поиск.Сохраните эмбеддинг в векторной базе данных.Выполните запрос к базе.Ниже показан простой пример реализации поиска по эмбеддингу, реализованный с помощью GigaChain и векторного хранилища Chroma.Пример демонстрирует поиск по документам — экземплярам GigaChain-класса Document, который представляет единицу текста и связанные с ним метаданные.\\nКласс имеет два атрибута:page_content — строку, представляющую содержимое;metadata — словарь, содержащий произвольные метаданные.Атрибут metadata может содержать данные об источнике документа, его связи с другими документами и другую дополнительную информацию.Для запуска примера установите зависимости:pip install langchain langchain-community langchain-chromaСоздайте несколько документов и сохраните их в векторном хранилище:from langchain_core.documents import Documentfrom langchain_chroma import Chromafrom langchain_gigachat.embeddings import GigaChatEmbeddings# Список документов, по которым будет выполняться поискdocuments = [    Document(        page_content=\"Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),    Document(        page_content=\"Кошки — независимые животные, которым нужно собственное пространство.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),    Document(        page_content=\"Золотые рыбки — отличные домашние животные для начинающих. За ними достаточно просто ухаживать.\",        metadata={\"source\": \"fish-pets-doc\"},    ),    Document(        page_content=\"Попугаи — умные птицы, которые способны имитировать человеческую речь.\",        metadata={\"source\": \"bird-pets-doc\"},    ),    Document(        page_content=\"Кролики — социальные животные, которым нужно много места, чтобы прыгать.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),]# Создайте векторное хранилище и передайте в него список документов и модель для создания векторного представленияvectorstore = Chroma.from_documents(    documents,    embedding = GigaChatEmbeddings(    credentials=\"ключ_авторизации\", scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=False    ),)Теперь вы можете использовать методы vectorstore для выполнения поиска по документам.Поиск по документам на основе схожести с тексовым запросом:vectorstore.similarity_search(\"кошка\")Результат поиска:[Document(page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\', metadata={\\'source\\': \\'bird-pets-doc\\'})]Оценка схожести запроса и содержимого хранилища:# Оценка зависит от выбранного векторного хранилища.# Chroma возвращает метрику расстояния, которая должна варьироваться обратно пропорционально схожести.vectorstore.similarity_search_with_score(\"кошка\")Результат оценки:[(Document(page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}),  218.2356719970703), (Document(page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}),  319.75384521484375), (Document(page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}),  349.84930419921875), (Document(page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\', metadata={\\'source\\': \\'bird-pets-doc\\'}),  352.6993103027344)]Поиск документов на основе схожести с запросом, представленным в виде вектора:embedding = GigaChatEmbeddings(    credentials=\"ключ_авторизации\", scope=\"GIGACHAT_API_PERS\", verify_ssl_certs=False    )embedded_query = embedding.embed_query(\"кошка\")vectorstore.similarity_search_by_vector(embedded_query)Результат поиска:[Document(page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\', metadata={\\'source\\': \\'mammal-pets-doc\\'}), Document(page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\', metadata={\\'source\\': \\'bird-pets-doc\\'})]Cмотрите также\\ufeffПример использования модели Embeddings и GigaChain для создания RAG-приложения, которое генерирует ответы на основе предоставленного текста.Потоковая генерация токеновСоздание изображений'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/errors-description', 'title': 'Описание ошибок | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/errors-description', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Описание ошибок | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Описание ошибокОбновлено 31 октября 2024В этом разделе вы найдете краткое описание ошибок REST и gRPC API GigaChat.Ошибки REST API\\ufeffПримеры ошибок, причины их возникновения, а также возможные способы решения.400 Ошибка в параметрах запросаВозможные причины возникновения ошибки при получении токена доступа:Проблема Не задан заголовок RqUID или форма заголовка не соответствует uuid4.Решение Добавьте в запрос заголовок RqUID с произвольным идентификатором запроса в формате uuid4.Проблема В поле scope не указана версия API, к которой выполняется запрос:{  \"code\": 5,  \"message\": \"scope is empty\"}Решение Укажите версию API, к которой выполняется запрос:GIGACHAT_API_PERS — доступ для физических лиц.GIGACHAT_API_B2B — доступ для ИП и юридических лиц по предоплате.GIGACHAT_API_CORP — доступ для ИП и юридических лиц по постоплате.Проблема Ключ авторизации не соответствует версии API, которая указана в поле scope или не указана версия API:{    \"code\": 7,    \"message\": \"scope from db not fully includes consumed scope\"}Решение Укажите корректную версию API. Версия API отображается в личном кабинете.GigaChain по умолчанию работает с версией API для физических лиц — GIGACHAT_API_PERS.\\nДля использования другой версии API явно укажите ее в параметре scope при инициализации объекта GigaChat:llm = GigaChat(  credentials=\"ключ_авторизации\",  scope=\"GIGACHAT_API_B2B\",  model=\"GigaChat-Pro\",)Проблема Поле scope содержит невалидные данные:{  \"code\": 1,  \"message\": \"scope data format invalid\"}Решение Возможно, версия API указана с ошибкой. Проверьте значение поля Scope и попробуйте еще раз.Если ошибка возникает при отправке других POST-запросов, то тело ошибки будет содержать название параметра, который привел к ошибке:{    \"status\": 400,    \"message\": \"Id must not be empty\"}401 Ошибка авторизацииОшибка может возникать при запросе токена доступа.\\nВ таком случае она может быть вызвана следующими проблемами.Проблема Заголовок Authorization содержит некорректные данные:{  \"code\": 4,  \"message\": \"Can\\'t decode \\'Authorization\\' header\"}Решение Возможно, ключ авторизации содержит опечатку. Укажите корректный ключ авторизации, полученный в личном кабинете и попробуйте снова.Проблема Ключ авторизации, который передается в заголовке Authorization не соответствует версии API, заданной в поле scope:{  \"code\": 6,  \"message\": \"credentials doesn\\'t match db data\"}Решение Перевыпустите ключ авторизации в личном кабинете и попробуйте снова.В других запросах ошибка может возникать из-за данных, переданных в заголовке Authorization: заголовок пустой или содержит токен доступа, который был создан более 30 минут назад.Пример: {    \"status\": 401,    \"message\": \"Unauthorized\"}Для исправления ошибки укажите корректный токен доступа.402 Требуется оплатить сервисПример:{    \"status\": 402,    \"message\": \"Payment Required\"}Проблема Закончились токены модели, к которой выполняется запрос.Решение Проверьте лимит токенов модели в личном кабинете и убедитесь, что вы передаете запросы именно в ту модель, у которой закончились токены.\\nПосле этого пополните баланс в личном кабинете.403 Нет доступа к запрашиваемому ресурсуОшибка возникает при отправке запроса GET /balance если вы оплачиваете работу с API по схеме pay-as-you-go.Это связано с тем, что метод возвращает остаток предоплаченных токенов, которых не может быть при оплате API по факту использования.Пример:{    \"status\": 403,    \"message\": \"Permission denied\"}413 Превышен максимальный размер входных данныхПример:{    \"status\": 413,    \"message\": \"Payload too large\"}Для решения проблемы уменьшите размер промпта.\\nКоличество токенов в промпте должно быть меньше размера окна контекста модели.\\nОценить количество токенов в промпте можно с помощью запроса POST /tokens/count.422 Модель не поддерживает пользовательские функцииОшибка может возникнуть при вызове собственных функций.\\nПример:{    \"status\": 422,    \"message\": \"Requested model does not support functions\"}Для решения проблемы — обратитесь на почту.429 Слишком много запросовПример:{    \"status\": 429,    \"message\": \"Too Many Requests\"}Количество выполняемых одновременных запросов не соответствует вашему client_id.\\nПо умолчанию физическим лицам доступен один одновременный поток, а ИП и юридическим лицам — 10.500 Внутренняя ошибка сервисаПример:{    \"status\": 500,    \"message\": \"Internal Server Error\"}Обратитесь в службу поддержки.Ошибки gRPC\\ufeffКод ошибки gRPCАналогичный HTTP-кодОписание3400, 413, 422Ошибка в параметрах запроса4408Истекло время ожидания5404Запрошенный ресурс не найден. Например, допущена ошибка в названии модели7403Ошибка авторизации8402, 429Закончились токены модели, к которой выполняется запрос13500 или любой другой кодВнутренняя ошибка сервисаПодробнее о кодах состояния gRPC — в официальной документации.Контакты\\ufeffЕсли проблема сохраняется, обратитесь в поддержку по электронной почте.Коллекции запросов PostmanСоздание промптов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/function-calling', 'title': 'Работа с функциями | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/function-calling', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Работа с функциями | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Работа с функциямиОбновлено 22 октября 2024Функции — внешние инструменты (фрагменты кода), к которым могут обращаться модели GigaChat для решения задач пользователей.\\nМодель не исполняет функции, но самостоятельно принимает решение о том как, когда и с какими параметрами их следует вызвать.\\nПри принятии решения о вызове функции модель исходит из доступных знаний, данных текущего разговора и описания функции.\\nПосле обращения к функции модель может обработать результат ее работы.Несколько примеров функций:запрос на поиск информации в базе данных;поиск в интернете по запросу и параметрам;изменение статуса устройств умного дома;вычисление математической формулы;создание изображения по текстовому запросу с помощью сторонней нейронной сети.Функции значительно повышают возможности языковых моделей, давая им возможности:получать и обрабатывать информацию из внешних источников;взаимодействовать с окружающей средой;обрабатывать результаты этого взаимодействия.Функции - ключевой элемент для построения сложных решений с применением LLM, таких, как AI-агенты и ассистенты.Все модели GigaChat для генерации поддерживают два вида функций:пользовательские — функции, которые вы реализуете и исполняете самостоятельно. Модель автоматически определяет необходимость вызова функции на основе ее описания. Для таких функций модель может сгенерировать объект с данными в подходящем вам формате, после чего вы сможете использовать их для дальнейших преобразований;встроенные — функции, которые модель использует для выполнения различных задач, например, генерации изображений. Функции исполняются внутри сервиса.Для работы с функциями используется запрос POST /chat/completions.\\nА именно — необязательное поле function_call, которое задает режим работы с функциями и может принимать значения:\"none\" — режим работы по умолчанию.Если запрос не содержит поля function_call или значение поля — none, модель не будет вызывать функции (в том числе встроенные), а просто сгенерирует ответ в соответствии с полученными сообщениями.\"auto\" — в зависимости от содержимого запроса, модель решает что нужно сделать: вызывать встроенные функции, сгенерировать аргументы для исполнения пользовательской функции или просто сгенерировать сообщение.Модель вызывает встроенные функции, только если отсутствует массив functions с описанием пользовательских функций.Если запрос содержит \"function_call\": \"auto\" и массив functions с описанием пользовательских функций, модель будет генерировать аргументы для описанных функций и не сможет вызвать встроенные функции независимо от содержимого запроса.Ниже, на примере функции прогноза погоды, показано как работать с пользовательскими функциями с помощью GigaChat.Работа с пользовательскими функциями\\ufeffФункция, использованная для примера, возвращает данные о температуре в зависимости от аргументов, полученных на входе:места, для которого запрашивается погода;единиц измерения температуры;периода в днях, которому должны соответствовать данные о температуре.Описание функции\\ufeffЧтобы модель могла определить, что нужно исполнить пользовательскую функцию, а также могла сгенерировать для нее аргументы, подготовьте ее описание в формате JSON Schema.{    \"name\": \"weather_forecast\",    \"description\": \"Возвращает температуру на заданный период\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"location\": {                \"type\": \"string\",                \"description\": \"Местоположение, например, название города\"            },            \"format\": {                \"type\": \"string\",                \"enum\": [                    \"celsius\",                    \"fahrenheit\"                ],                \"description\": \"Единицы измерения температуры\"            },            \"num_days\": {                \"type\": \"integer\",                \"description\": \"Период, для которого нужно вернуть\"            }        },        \"required\": [            \"location\",            \"num_days\"        ]    }}Для улучшения генерации аргументов в описании функции вы также можете передать:few_shot_examples — массив с примерами запросов пользователя и ответов модели;return_parameters — объект с описанием данных в формате JSON Schema, которые возвращает функция.Модели GigaChat значительно лучше работают с функциями, которые описаны согласно приведенным примерам.\\nПри описании функции уделяйте внимание подробному описанию структуры входных и выходных данных, не забывайте указывать краткое описание самой функции и примеры ее использования.Ниже вы найдете несколько примеров хорошо описанных функций.{    \"name\": \"weather_forecast\",    \"description\": \"Возвращает температуру на заданный период\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"location\": {                \"type\": \"string\",                \"description\": \"Местоположение, например, название города\"            },            \"format\": {                \"type\": \"string\",                \"enum\": [                    \"celsius\",                    \"fahrenheit\"                ],                \"description\": \"Единицы измерения температуры\"            },            \"num_days\": {                \"type\": \"integer\",                \"description\": \"Период, для которого нужно вернуть\"            }        },        \"required\": [            \"location\",            \"num_days\"        ]    },    \"few_shot_examples\": [        {            \"request\": \"Какая погода в Москве в ближайшие три дня\",            \"params\": {                \"location\": \"Moscow, Russia\",                \"format\": \"celsius\",                \"num_days\": \"3\"            }        }    ],    \"return_parameters\": {        \"type\": \"object\",        \"properties\": {            \"location\": {                \"type\": \"string\",                \"description\": \"Местоположение, например, название города\"            },            \"temperature\": {                \"type\": \"integer\",                \"description\": \"Температура для заданного местоположения\"            },            \"forecast\": {                \"type\": \"array\",                \"items\": {                    \"type\": \"string\"                },                \"description\": \"Описание погодных условий\"            },            \"error\": {                \"type\": \"string\",                \"description\": \"Возвращается при возникновении ошибки. Содержит описание ошибки\"            }        }    }}Примеры описания функций\\ufeffПредставленные примеры описания функций используются в Jupyter-блокноте, который демонстрирует работу с функциями с помощью GigaChain.Функция расчета расстояния{    \"name\": \"calculate_trip_distance\",    \"description\": \"Рассчитать расстояние между двумя местоположениями\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"start_location\": {                \"type\": \"string\",                \"description\": \"Начальное местоположение\"            },            \"end_location\": {                \"type\": \"string\",                \"description\": \"Конечное местоположение\"            }        },        \"required\": [            \"start_location\",            \"end_location\"        ]    },    \"return_parameters\": {        \"type\": \"object\",        \"properties\": {            \"distance\": {                \"description\": \"Расстояние между начальным и конечным местоположением в километрах\",                \"type\": \"integer\"            }        },        \"required\": [            \"distance\"        ]    },    \"few_shot_examples\": [        {            \"request\": \"Насколько далеко от Москвы до Санкт-Петербурга?\",            \"params\": {                \"start_location\": \"Москва\",                \"end_location\": \"Санкт-Петербург\"            }        }    ]}Функция отправки SMS-сообщения{    \"name\": \"send_sms\",    \"description\": \"Отправить SMS-сообщение\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"recipient\": {                \"type\": \"string\",                \"description\": \"Номер телефона получателя\"            },            \"message\": {                \"type\": \"string\",                \"description\": \"Содержимое сообщения\"            }        },        \"required\": [            \"recipient\",            \"message\"        ]    },    \"return_parameters\": {        \"type\": \"object\",        \"properties\": {            \"status\": {                \"description\": \"Статус отправки сообщения\",                \"type\": \"string\"            },            \"message\": {                \"description\": \"Сообщение о результате отправки SMS\",                \"type\": \"string\"            }        },        \"required\": [            \"status\",            \"message\"        ]    },    \"few_shot_examples\": [        {            \"request\": \"Можешь ли ты отправить SMS-сообщение на номер 123456789 с содержимым \\'Привет, как дела?\\'\",            \"params\": {                \"recipient\": \"123456789\",                \"message\": \"Привет, как дела?\"            }        }    ]}Функция поиска фильмов{    \"name\": \"search_movies\",    \"description\": \"Поиск фильмов на основе заданных критериев\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"genre\": {                \"type\": \"string\",                \"description\": \"Жанр фильма\"            },            \"year\": {                \"type\": \"integer\",                \"description\": \"Год выпуска фильма\"            },            \"actor\": {                \"type\": \"string\",                \"description\": \"Имя актера, снимавшегося в фильме\"            }        },        \"required\": []    },    \"return_parameters\": {        \"type\": \"object\",        \"properties\": {            \"movies\": {                \"description\": \"Список названий фильмов, соответствующих заданным критериям поиска\",                \"type\": \"array\",                \"items\": {                    \"description\": \"Название фильма\",                    \"type\": \"string\"                }            }        },        \"required\": [            \"movies\"        ]    },    \"few_shot_examples\": [        {            \"request\": \"\\\\\"Найди все фильмы жанра комедия\\\\\".\",            \"params\": {                \"genre\": \"комедия\"            }        }    ]}Примеры составных функций\\ufeffМодели GigaChat могут использовать результаты работы одних функций для вызова других.\\nО такой возможности нужно сообщать в описании соответствующих функций.\\nВ остальном они описываются так же, как и обычные функции.\\nФункции, которые работают таким образом, называются составными.Ниже — пример нескольких функций, в описании которых заданы инструкции для модели.\\nСогласно этим инструкциям при недостатке данных модель должна самостоятельно вызвать соответствующую функцию, которая может дать недостающие данные.Функция получения данных о напоминании{    \"name\": \"get_reminder\",    \"description\": \"Получить метаинформацию обо всех установленных напоминаниях. Вызови эту функцию перед удалением или изменением напоминаний, чтобы получить id напоминаний. В случае если пользователь хочет удалить или изменить напоминание и в контексте диалога нет необходимых id, то сначала вызови эту функцию для получения идентификатора id и ответь пустым сообщением, а далее при необходимости вызови следующую функцию для выполнения запроса пользователя.\\\\nПосле вызова данной функции ответь пользователю в следующем стиле: \\\\\"У вас установлено 2 напоминания. Через 10 минут выключить духовку на кухне, а завтра в 3 часа сходить в гости.\\\\\"\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"title\": {                \"type\": \"string\",                \"description\": \"Текст напоминания\"            },            \"date_time\": {                \"type\": \"string\",                \"description\": \"Относительное время и дата напоминания на русском языке\"            },            \"device_name\": {                \"type\": \"string\",                \"description\": \"Название устройства, на котором следует проверить напоминание\"            },            \"room\": {                \"type\": \"string\",                \"description\": \"Название комнаты в которой следует проверить напоминание\"            }        },        \"required\": []    },    \"few_shot_examples\": [        {            \"request\": \"мои напоминания\",            \"params\": {}        },        {            \"request\": \"удали напоминалку на завтра в пять\",            \"params\": {}        },        {            \"request\": \"перенеси напоминание поздравить маму на шесть вечера\",            \"params\": {}        },        {            \"request\": \"какое у меня количество напоминаний\",            \"params\": {}        },        {            \"request\": \"озвучь напоминалки\",            \"params\": {}        }    ],    \"return_parameters\": {        \"type\": \"object\",        \"description\": \"Ответ на get_reminder\",        \"properties\": {            \"status\": {                \"type\": \"string\",                \"enum\": [                    \"success\",                    \"fail\"                ],                \"description\": \"Статус - удалось ли найти список установленных напоминаний\"            },            \"error\": {                \"type\": \"string\",                \"description\": \"Текст ошибки в случае, если status == fail\"            },            \"items\": {                \"type\": \"array\",                \"description\": \"Список установленных напоминаний. В списке перечислены идентификаторы напоминаний (id), дата и время старта напоминания (reminderTime), периодичность напоминания в человекочитаемом формате (cron), название напоминания (title), дата и время создания напоминания (createdAt).\",                \"items\": {                    \"type\": \"object\",                    \"description\": \"Метаинформация напоминания.\",                    \"properties\": {                        \"id\": {                            \"type\": \"string\",                            \"description\": \"Идентификатор напоминания.\"                        },                        \"cron\": {                            \"type\": \"string\",                            \"description\": \"Описание периодичности напоминания. Здесь будет передано человекочитаемое описание переодичности напоминания. Если поле отсутствует, то у напоминания нет периодичности (единоразовое).\"                        },                        \"title\": {                            \"type\": \"string\",                            \"description\": \"Название напоминания, о чем надо напомнить.\"                        },                        \"devices\": {                            \"type\": \"array\",                            \"description\": \"Словарь устройств, к которым привязаны напоминания\",                            \"items\": {                                \"type\": \"string\",                                \"description\": \"Название устройства\"                            }                        },                        \"reminderTime\": {                            \"type\": \"string\",                            \"description\": \"Дата и время старта напоминания.\"                        },                        \"createdAt\": {                            \"type\": \"string\",                            \"description\": \"Дата и время создания напоминания.\"                        }                    }                }            }        },        \"required\": [            \"status\"        ]    }}Функция удаления напоминания{    \"name\": \"delete_reminder\",    \"description\": \"Удалить напоминания по id. Если пользователь явно не передал id напоминания, то получи метаинформацию о напоминаниях, вызвав сначала соответствующую функцию, и только затем используй функцию удаления напоминания по id.\\\\nЕсли в контексте беседы с пользователем у тебя есть необходимый id, то перед запуском этой функции тебе необходимо переспросить пользователя точно ли он хочет удалить данное напоминание и только после согласия удалять. Если пользователь просит удалить все напоминания и в контексте диалога есть необходимые id или пользователь явно передает id напоминания, которое надо удалить, то вызови эту функцию, переспрашивать пользователя не нужно. В остальных случаях, при наличии необходимых id в контексте диалога и готовности удалить напоминание, сначала переспроси пользователя подтверждает ли он удаление напоминания и вызывай функцию только при наличии подтверждения от пользователя.\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"ids\": {                \"type\": \"array\",                \"items\": {                    \"type\": \"string\",                    \"description\": \"Идентификатор id напоминания, которое нужно удалить\"                },                \"description\": \"Список идентификаторов id напоминаний, которые нужно удалить\"            }        },        \"required\": [            \"ids\"        ]    },    \"few_shot_examples\": [],    \"return_parameters\": {        \"type\": \"object\",        \"description\": \"Ответ на delete_reminder\",        \"properties\": {            \"status\": {                \"type\": \"string\",                \"enum\": [                    \"success\",                    \"fail\"                ],                \"description\": \"Статус - удалось ли удалить напоминание.\"            },            \"error\": {                \"type\": \"string\",                \"description\": \"Текст ошибки в случае, если status == fail\"            }        },        \"required\": [            \"status\"        ]    }}Функция изменения напоминания{    \"name\": \"change_reminder\",    \"description\": \"Изменить напоминание по id.\\\\nЕсли пользователь просит изменить напоминание, но не указывает какое и какие изменения надо внести, то в ответе попроси предоставить дополнительную информацию.\\\\nЕсли просит изменить напоминание и не указывает какое, но указывает какие изменения внести, то сначала получи метаинформацию о напоминаниях, вызвав нужную функцию, перечисли их в ответе и уточни какое из них изменить.\\\\nЕсли просит изменить напоминание, указывая какое, но не указывая изменения, то сначала получи метаинформацию обо всех напоминаниях, вызвав нужную функцию, перечисли их в ответе и при наличии id, соответствующего запросу, уточни какие изменения надо внести.\\\\nЕсли просит изменить напоминание, указывая какое и какие изменения внести, то получи метаинформацию обо всех напоминаниях, вызвав нужную функцию, и при наличии id, соответствующего запросу пользователя, вызови функцию изменения напоминаня по id.\\\\n\\\\nВызывай данную функцию только при наличии нужного id и информации о том как надо изменить напоминание.\",    \"parameters\": {        \"type\": \"object\",        \"properties\": {            \"id\": {                \"type\": \"string\",                \"description\": \"id напоминания\"            },            \"title\": {                \"type\": \"string\",                \"description\": \"Новый текст напоминания\"            },            \"date_time\": {                \"type\": \"string\",                \"description\": \"Новые время и дата напоминания на русском языке. Передай только то, что сказал пользователь, не меняя формат.\"            },            \"device_name\": {                \"type\": \"string\",                \"description\": \"Новое название устройства, на которое следует поставить напоминание\"            }        },        \"required\": [            \"id\"        ]    },    \"few_shot_examples\": [        {            \"request\": \"Изменить напоминание с id 123 на сегодня в 19 30\",            \"params\": {                \"id\": \"123\",                \"date_time\": \"сегодня в 19 30\"            }        }    ],    \"return_parameters\": {        \"type\": \"object\",        \"properties\": {            \"status\": {                \"type\": \"string\",                \"enum\": [                    \"success\",                    \"fail\"                ],                \"description\": \"Статус - удалось ли изменить напоминание.\"            },            \"error\": {                \"type\": \"string\",                \"description\": \"Текст ошибки в случае, если status == fail\"            },            \"reminder\": {                \"type\": \"object\",                \"description\": \"Параметры созданного напоминания\",                \"properties\": {                    \"id\": {                        \"type\": \"string\",                        \"description\": \"Идентификатор напоминания.\"                    },                    \"cron\": {                        \"type\": \"string\",                        \"description\": \"Описание периодичности напоминания. Здесь будет передано человекочитаемое описание переодичности напоминания. Если поле отсутствует, то у напоминания нет периодичности (единоразовое).\"                    },                    \"title\": {                        \"type\": \"string\",                        \"description\": \"Название напоминания, о чем надо напомнить.\"                    },                    \"devices\": {                        \"type\": \"array\",                        \"description\": \"Словарь устройств, к которым привязаны напоминания\",                        \"items\": {                            \"type\": \"string\",                            \"description\": \"Название устройства\"                        }                    },                    \"reminderTime\": {                        \"type\": \"string\",                        \"description\": \"Дата и время старта напоминания.\"                    },                    \"createdAt\": {                        \"type\": \"string\",                        \"description\": \"Дата и время создания напоминания.\"                    }                }            }        },        \"required\": [            \"status\"        ]    }}Генерация аргументов\\ufeffТеперь, когда вы подготовили описание функции, используйте его для генерации аргументов с помощью модели.Модели GigaChat могут генерировать аргументы для вызова функций в автоматическом режиме.В этом режиме модель анализирует полученные сообщения (массив messages) и сама решает нужно использовать функции или нет.Для работы в автоматическом режиме передавайте в запросе поле \"function_call\": \"auto\":{    \"model\": \"GigaChat\",    \"messages\": [        {            \"role\": \"user\",            \"content\": \"Погода в Москве на три дня\"        }    ],    \"function_call\": \"auto\",    \"functions\": [        {            \"name\": \"weather_forecast\",            \"description\": \"Возвращает температуру на заданный период\",            \"parameters\": {                \"type\": \"object\",                \"properties\": {                    \"location\": {                        \"type\": \"string\",                        \"description\": \"Местоположение, например, название города\"                    },                    \"format\": {                        \"type\": \"string\",                        \"enum\": [                            \"celsius\",                            \"fahrenheit\"                        ],                        \"description\": \"Единицы измерения температуры\"                    },                    \"num_days\": {                        \"type\": \"integer\",                        \"description\": \"Период, для которого нужно вернуть прогноз\"                    }                },                \"required\": [                    \"location\",                    \"num_days\"                ]            }        }    ],}При этом работа модели зависит от того, содержит массив functions описание пользовательских функций или нет:Если массив отсутствует или пустой — модель сможет обращаться только ко встроенным функциям.Если массив не пустой — модель сможет генерировать аргументы только для заданных функций.Ответ модели\\ufeffКогда модель решает, что нужно исполнить пользовательскую функцию, она возвращает ответ с результатом \"finish_reason\": \"function_call\".\\nСгенерированные аргументы для вызова вашей функции передаются в объекте message.function_call:{    \"choices\": [        {            \"message\": {                \"role\": \"assistant\",                \"content\": \"\",                \"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",                \"function_call\": {                    \"name\": \"weather_forecast\",                    \"arguments\": {                        \"location\": \"Москва\",                        \"format\": \"celsius\"                    }                }            },            \"index\": 0,            \"finish_reason\": \"function_call\"        }    ],    \"created\": 1700471392,    \"model\": \"GigaChat\",    \"usage\": {        \"prompt_tokens\": 150,        \"completion_tokens\": 35,        \"total_tokens\": 185    },    \"object\": \"chat.completion\"}Значение поля \"finish_reason\": \"error\", сообщает о том, что ответ модели содержит невалидные аргументы функции.Передача ответа функции в модель\\ufeffПосле исполнения пользовательской функции со сгенерированными аргументами, передайте результат ее работы обратно в модель.Для этого используйте сообщение с ролью function в контексте диалога (массив messages):{    \"model\": \"GigaChat\",    \"messages\": [        {            \"role\": \"user\",            \"content\": \"Какая погода в Москве сегодня?\"        },        {            \"role\": \"assistant\",            \"content\": \"\",            \"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",            \"function_call\": {                \"name\": \"weather_forecast\",                \"arguments\": {                    \"location\": \"Москва\",                    \"format\": \"celsius\"                    }            }        },        {            \"role\": \"function\",            \"content\": \"{\\\\\"temperature\\\\\": \\\\\"27\\\\\"}\",            \"name\": \"weather_forecast\"        }    ],    \"functions\": [        {            \"name\": \"weather_forecast\",            \"description\": \"Возвращает температуру на заданный период\",            \"parameters\": {                \"type\": \"object\",                \"properties\": {                    \"location\": {                        \"type\": \"string\",                        \"description\": \"Местоположение, например, название города\"                    },                    \"format\": {                        \"type\": \"string\",                        \"enum\": [                            \"celsius\",                            \"fahrenheit\"                        ],                        \"description\": \"Единицы измерения температуры\"                    },                    \"num_days\": {                        \"type\": \"integer\",                        \"description\": \"Период, для которого нужно вернуть прогноз\"                    }                },                \"required\": [                    \"location\",                    \"num_days\"                ]            }        },    ],}Подробнее о работе с контекстом диалога — в разделе Работа с историей чата.Потоковая генерация аргументов\\ufeffПри генерации аргументов в потоковом режиме (\"stream\": true) название функции (function_call.name) и ее аргументы всегда передаются в одной порции:data: {\"choices\":[{\"delta\":{\"content\":\"Мне нужно посмотреть погоду в Москве\",\"role\":\"assistant\"},\"index\":0}],\"created\":1698850241,\"model\":\"GigaChat\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":50,\"prompt_tokens\":152,\"total_tokens\":202}}  data: {\"choices\":[{\"delta\":{\"content\":\" на\"},\"index\":0}],\"created\":1698850241,\"model\":\"GigaChat\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":1,\"prompt_tokens\":0,\"total_tokens\":1}}  data: {\"choices\":[{\"delta\":{\"content\":\" завтра\"},\"index\":0}],\"created\":1698850241,\"model\":\"GigaChat\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":1,\"prompt_tokens\":0,\"total_tokens\":1}}  data: {\"choices\":[{\"delta\":{\"function_call\": {\"name\": \"weather_forecast\", \"arguments\": {\"location\": \"Moscow\",\"num_days\": 1}}},\"index\":0}],\"created\":1698850241,\"model\":\"GigaChat\",\"object\":\"chat.completion\",\"usage\":{\"completion_tokens\":1,\"prompt_tokens\":0,\"total_tokens\":1}}  data: {\"choices\":[{\"delta\":{\"content\":\"\",\"functions_state_id\":\"77d3fb14-457a-46ba-937e-8d856156d003\",\"created\":1718801171,\"model\":\"GigaChat\",\"object\":\"chat.completion\"}  data: [DONE]Вызов встроенных функций\\ufeffGigaChat поддерживает встроенные функции, например, для генерации изображений.\\nВстроенные функции вызываются только в автоматическом режиме (\"function_call\": \"auto\") на основе запроса пользователя.При вызове встроенных функций модель возвращает ответ с результатом \"finish_reason\": \"stop\".Пример запроса на генерацию изображения:curl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"system\",      \"content\": \"Ты — Василий Кандинский\"          },    {      \"role\": \"user\",      \"content\": \"Нарисуй розового кота\"    }  ],  \"function_call\": \"auto\",}\\'Пример ответа:{    \"choices\": [        {            \"message\": {                \"content\": \"Запускаю генерацию изображения. Ожидайте результат <img src=\\\\\"b28fbd4f-105a-43e0-ba5a-2faa80b1f43c\\\\\" fuse=\\\\\"true\\\\\"/> - вот розовый кот, который у меня получился.\",                \"role\": \"assistant\",                \"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",                \"data_for_context\": [                    {                        \"content\": \"Запускаю генерацию изображения. Ожидайте результат\",                        \"role\": \"assistant\",                        \"function_call\": {                            \"name\": \"text2image\",                            \"arguments\": {                                \"query\": \"pink cat, cartoon, colorful, drawing\"                            }                        }                    },                    {                        \"content\": \"{\\\\\"status\\\\\":\\\\\"success\\\\\"}\",                        \"role\": \"function\",                        \"name\": \"text2image\"                    },                    {                        \"content\": \" - вот розовый кот, который у меня получился.\",                        \"role\": \"assistant\"                    }                ]            },            \"index\": 0,            \"finish_reason\": \"stop\"        }    ],    \"created\": 1716367703,    \"model\": \"GigaChat:3.1.25.3\",    \"object\": \"chat.completion\",    \"usage\": {        \"prompt_tokens\": 372,        \"completion_tokens\": 48,        \"total_tokens\": 420    }}При этом контекст выполнения функции, который нужен для качественной работы модели, сохраняется одним из двух способов:С помощью поля functions_state_id — идентификатора, который объединяет массив функций, переданных в запросе. При работе в режиме потоковой передачи идентификатор передается в последнем фрагменте.С помощью массива сообщений data_for_context. Это устаревший способ, поддержка которого в будущем прекратится.Сохранение контекста\\ufeffC помощью поля functions_state_id\\ufeffЭто приоритетный способ, который в будущем заменит использование массива с данными контекста data_for_context.Для сохранения контекста после вызова встроенных функций, передавайте поле functions_state_id в запросе в сообщениях с ролью assistant:```json{    \"messages\": [        {            \"role\": \"user\",            \"content\": \"нарисуй корову\"        },        {            \"content\": \"Добавил в очередь на генерацию изображения... <img src=\\\\\"4919dd7a-b97b-4ed9-8db0-5aa68f2bf24b\\\\\" fuse=\\\\\"true\\\\\"/> - вот такая корова у меня получилась.\",            \"role\": \"assistant\",            \"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\"        },        {            \"content\": \"а теперь нарисуй слона\",            \"role\": \"user\"        }    ],    \"model\": \"GigaChat\"}С помощью блока data_for_context\\ufeffДля сохранения контекста после вызова встроенных функций, передавайте массив data_for_context в запросе в сообщениях с ролью assistant:{    \"messages\": [        {            \"role\": \"user\",            \"content\": \"Нарисуй розового кота\"        },        {            \"role\": \"assistant\",            \"content\": \"Запускаю генерацию изображения. Ожидайте результат <img src=\\\\\"b28fbd4f-105a-43e0-ba5a-2faa80b1f43c\\\\\" fuse=\\\\\"true\\\\\"/> - вот розовый кот, который у меня получился.\",            \"data_for_context\": [                    {                        \"content\": \"Запускаю генерацию изображения. Ожидайте результат\",                        \"role\": \"assistant\",                        \"function_call\": {                            \"name\": \"text2image\",                            \"arguments\": {                                \"query\": \"pink cat, cartoon, colorful, drawing\"                            }                        }                    },                    {                        \"content\": \"{\\\\\"status\\\\\":\\\\\"success\\\\\"}\",                        \"role\": \"function\",                        \"name\": \"text2image\"                    },                    {                        \"content\": \" - вот розовый кот, который у меня получился.\",                        \"role\": \"assistant\"                    }            ]        },        {            \"role\": \"user\",            \"content\": \"Дорисуй ему крылья\"        }    ],    \"model\": \"GigaChat\"}Потоковая передача токенов\\ufeffРабота встроенных функций может занимать продолжительное время.\\nВы можете обрабатывать ответ модели по мере его генерации с помощью потоковой передачи токенов (параметр запроса \"stream\": true).Пример запроса:curl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat-Pro\",  \"messages\": [    {      \"role\": \"system\",      \"content\": \"Ты — Василий Кандинский\"          },    {      \"role\": \"user\",      \"content\": \"Нарисуй розового кота\"    }  ],  \"function_call\": \"auto\",  \"stream\": true,}\\'При этом сообщения о том, что работает встроенная функция, будут приходить с ролью function_in_progress и данными о том, когда был создан фрагмент сообщения.Пример ответа:data: {\"choices\":[{\"delta\":{\"content\":\"Запускаю генерацию изображения...\",\"role\":\"assistant\"},\"index\":0}],\"created\":1718801160,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: {\"choices\":[{\"delta\":{\"content\":\"осталось 00:09\",\"role\":\"function_in_progress\"},\"index\":0}],\"created\":1718801161,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: {\"choices\":[{\"delta\":{\"content\":\"осталось 00:09\",\"role\":\"function_in_progress\"},\"index\":0}],\"created\":1718801166,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: {\"choices\":[{\"delta\":{\"content\":\"<img src=\\\\\"a786fa9d-2821-4dec-82b0-ef62bc2d51b2\\\\\" fuse=\\\\\"true\\\\\"/>\",\"role\":\"assistant\"},\"index\":0}],\"created\":1718801171,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: {\"choices\":[{\"delta\":{\"content\":\"- вот такой кот у меня получился.\",\"role\":\"assistant\"},\"index\":0}],\"created\":1718801171,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: {\"choices\":[{\"delta\":{\"content\":\"\",\"functions_state_id\":\"77d3fb14-457a-46ba-937e-8d856156d003\",\"created\":1718801171,\"model\":\"GigaChat-Pro:2.2.25.3\",\"object\":\"chat.completion\"} data: [DONE]Смотрите также\\ufeffPOST /chat/completionsГенерация изображенийСохранение контекстаСоздание изображенийОбработка файлов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/images-generation', 'title': 'Создание изображений | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/images-generation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Создание изображений | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Создание изображенийОбновлено 12 ноября 2024GigaChat API вернет изображение, если в запросе на генерацию POST /chat/completions получит соответствующее сообщение, например: «Нарисуй розового кота».\\nИзображения генерируются в бинарном виде в формате JPG с помощью встроенной функции text2image.В ответ GigaChat возвращает идентификатор созданного изображения, которое можно скачать с помощью запроса POST /files/:file_id/content.Для создания изображения в запросе нужно передать параметр \"function_call\": \"auto\", с помощью которого модель определяет необходимость вызова функции text2image.\\nПри создании изображений с помощью встроенной функции модель возвращает ответ с результатом \"finish_reason\": \"stop\".Вы можете стилизовать изображения с помощью системного промпта.Пример запроса на создание изображения:curl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"system\",      \"content\": \"Ты — Василий Кандинский\"          },    {      \"role\": \"user\",      \"content\": \"Нарисуй розового кота\"    }  ],  \"function_call\": \"auto\"}\\'Пример ответа:{    \"choices\": [        {            \"message\": {                \"content\": \"Запускаю генерацию изображения. Ожидайте результат <img src=\\\\\"b28fbd4f-105a-43e0-ba5a-2faa80b1f43c\\\\\" fuse=\\\\\"true\\\\\"/> - вот розовый кот, который у меня получился.\",                \"role\": \"assistant\",                \"data_for_context\": [                    {                        \"content\": \"Запускаю генерацию изображения. Ожидайте результат\",                        \"role\": \"assistant\",                        \"function_call\": {                            \"name\": \"text2image\",                            \"arguments\": {                                \"query\": \"pink cat, cartoon, colorful, drawing\"                            }                        }                    },                    {                        \"content\": \"{\\\\\"status\\\\\":\\\\\"success\\\\\"}\",                        \"role\": \"function\",                        \"name\": \"text2image\"                    },                    {                        \"content\": \" - вот розовый кот, который у меня получился.\",                        \"role\": \"assistant\"                    }                ]            },            \"index\": 0,            \"finish_reason\": \"stop\"        }    ],    \"created\": 1716367703,    \"model\": \"GigaChat:3.1.25.3\",    \"object\": \"chat.completion\",    \"usage\": {        \"prompt_tokens\": 372,        \"completion_tokens\": 48,        \"total_tokens\": 420    }}Массив data_for_context содержит сообщения для работы модели в правильном контексте.Подробнее о функциях — в разделе Работа с функциями.Скачивание изображения\\ufeffОтвет модели будет содержать идентификатор получившегося изображения в формате uuid4.\\nИдентификатор передается в поле message.content, в теге <img>, в атрибуте src:{    \"message\": {        \"content\": \"Запускаю генерацию изображения. Ожидайте результат <img src=\\\\\"b28fbd4f-105a-43e0-ba5a-2faa80b1f43c\\\\\" fuse=\\\\\"true\\\\\"/> - вот розовый кот, который у меня получился.\",        \"role\": \"assistant\",        \"data_for_context\": [            {                \"content\": \"Запускаю генерацию изображения. Ожидайте результат\",                \"role\": \"assistant\",                \"function_call\": {                    \"name\": \"text2image\",                    \"arguments\": {                        \"query\": \"pink cat, cartoon, colorful, drawing\"                    }                }            },            {                \"content\": \"{\\\\\"status\\\\\":\\\\\"success\\\\\"}\",                \"role\": \"function\",                \"name\": \"text2image\"            },            {                \"content\": \" - вот розовый кот, который у меня получился.\",                \"role\": \"assistant\"            }        ]    },    \"index\": 0,    \"finish_reason\": \"stop\"}Для скачивания изображения передайте полученный идентификатор в запросе GET /files/{file_id}/content:cURLPythonPostmancurl -L -X GET \\'https://gigachat.devices.sberbank.ru/api/v1/files/<идентификатор_изображения>/content\\' -o \"<имя_файла>.jpg\" \\\\-H \\'Accept: application/jpg\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\'Если запрос на создание изображения содержал заголовок X-Client-ID, то такой же заголовок нужно передавать в запросе на скачивание файла.curl -L -X GET \\'https://gigachat.devices.sberbank.ru/api/v1/files/<идентификатор_изображения>/content\\' -o \"<имя_файла>.jpg\" \\\\-H \\'Accept: application/jpg\\' \\\\-H \\'X-Client-ID: <идентификатор_пользователя>\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\'import requestsimport shutilurl = \"https://gigachat.devices.sberbank.ru/api/v1/files/<идентификатор_изображения>/content\"headers = {  \\'Accept\\': \\'application/jpg\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"GET\", url, headers=headers, stream=True)with open(\\'<имя_файла>.jpg\\', \\'wb\\') as out_file:    shutil.copyfileobj(response.raw, out_file)del responseЕсли вы используете коллекцию запросов Postman, вы можете сохранить ответ на запрос GET /files/{file_id}/content в файл с помощью опции Save response to file.Ответ на запрос будет содержать бинарное представление файла в формате JPG.Смотрите также\\ufeffПримеры промптов для создания изображенийРабота с функциямиВекторное представление текстаРабота с функциями'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/keeping-context', 'title': 'Работа с историей чата | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/keeping-context', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Работа с историей чата | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Работа с историей чатаОбновлено 12 ноября 2024Передача истории чата позволяет GigaChat работать с результатами прошлых запросов пользователя.\\nКогда вы переписываетесь с нейросетевой моделью в веб-интерфейсе, она автоматически учитывает историю чата.Если для обмена сообщениями вы используете GigaChat API, историю чата нужно передавать явно в поле messages запроса POST /chat/completions.Пример запроса с историей чата:curl https://gigachat.devices.sberbank.ru/api/v1/chat/completions \\\\  -H \\'Content-Type: application/json\\' \\\\  -H \\'Authorization: Bearer access_token\\' \\\\  -d \\'{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"user\",            \"content\": \"Когда уже ИИ захватит этот мир?\"        },        {            \"role\": \"assistant\",            \"content\": \"Пока что это не является неизбежным событием. Несмотря на то, что искусственный интеллект (ИИ) развивается быстрыми темпами и может выполнять сложные задачи все более эффективно, он по-прежнему ограничен в своих возможностях и не может заменить полностью человека во многих областях. Кроме того, существуют этические и правовые вопросы, связанные с использованием ИИ, которые необходимо учитывать при его разработке и внедрении.\"        },        {            \"role\": \"user\",            \"content\": \"Думаешь, у нас еще есть шанс?\"        }    ],}\\'Кэширование запросов\\ufeffВы можете использовать необязательный идентификатор сессии X-Session-ID для кэширования контекста разговора с GigaChat.\\nИдентификатор передается в заголовке запроса и может содержать произвольную строку.\\nЕсли при получении запроса, модель находит в кэше данные о запросе с таким же идентификатором и частично совпадающим контекстом, то она не пересчитывает этот контекст.\\nТакой подход позволяет снизить время на генерацию ответа. Кэширование позволяет снизить расходы на генерацию, благодаря тому, что модель тратит меньше токенов на обработку сообщений контекста с одинаковыми идентификаторами.Кэширование изображений в настоящий момент не поддерживается.Кэширование может быть полезно при:разработке разговорных агентов, которые должны учитывать большой контекст для ведения диалога.создании асситентов, которые помогают писать код. Например, вы можете закэшировать кодовую базу, которую модель должна будет учитывать при автодополнении.работе с большими документами.необходимости передать в модель большой набор инструкций. Например, вы можете сохранить в кэше множество различных примеров желаемого результата работы модели.многократном вызове функций, для сохранения результатов вызовов.Пример запроса с заголовком X-Session-ID, в котором передан идентификатор в формате uuid4:curl https://gigachat.devices.sberbank.ru/api/v1/chat/completions \\\\  -H \\'Content-Type: application/json\\' \\\\  -H \\'Authorization: Bearer access_token\\' \\\\  -H \\'X-Session-ID: dfa87a40-99a9-42c4-b810-6c7caa1e1e8b\\' \\\\  -d \\'{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"user\",            \"content\": \"Запрос пользователя\"        },        {            \"role\": \"assistant\",            \"content\": \"Ответ модели\"        },        {            \"role\": \"user\",            \"content\": \"Запрос пользователя\"        }    ],}\\'Выбор модели для генерацииПотоковая генерация токенов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/overview', 'title': 'GigaChat API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='GigaChat API | Документация для разработчиков'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/postman-request-collection', 'title': 'Коллекции запросов Postman | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/postman-request-collection', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Коллекции запросов Postman | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Коллекции запросов PostmanОбновлено 1 ноября 2024С GigaChat API можно работать с помощью подготовленных коллекций запросов Postman.\\nКоллекции позволяют обращаться как к REST, так и к gRPC API GigaChat.HTTPgRPCДля использования коллекции запросов Postman:Войдите в свою учетную запись Postman.Нажмите кнопку:Нажмите Fork Collection, чтобы скопировать коллекцию запросов в свое рабочее пространство в Postman.В открывшемся окне укажите название копии и рабочего пространства, в котором будет создана копия коллекции. Установите флажок Watch original collection, если хотите получать уведомления об изменении в оригинальной коллекции запросов.Нажмите Fork Collection.Коллекцию можно скопировать только в публичный профиль Postman.В описании коллекции вы найдете краткую инструкцию о работе с переменными и выполнении запросов в Postman.Подробнее о том, как пользоваться GigaChat API в Postman:Отправлять запросы к gRPC API можно только из приложения Postman, установленного на компьютер.\\nВеб-версия Postman не поддерживает работу с gRPC.Вы можете скопировать коллекцию gRPC-запросов из публичного пространства Postman.Для работы с коллекцией понадобится proto-файл, который вы можете скачать или скопировать из документации.Как подключить proto-файл в коллекцию — в официальной документации.Для авторизации запросов:Откройте Postman-коллекцию.Перейдите на вкладку Variables.В переменной authorization_key, в поле Current Value укажите ключ авторизации, полученный в личном кабинете.О том как получить ключ авторизации — в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юрлиц.В переменной scope, в поле Current Value укажите версию API, к которой будет выполняться запрос:GIGACHAT_API_PERS;GIGACHAT_API_B2B;GIGACHAT_API_CORP.Смотрите также\\ufeffАвторизация запросовОписание APIgRPC APIОписание ошибок'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference-grpc', 'title': 'gRPC API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference-grpc', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='gRPC API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?gRPC APIОбновлено 17 октября 2024Для обмена данными с сервисом GigaChat вы можете использовать gRPC-протокол. Подробнее о нем читайте в официальной документации.Совершать запросы по протоколу gRPC удобно, если нужно:максимально быстро получить ответ;поддержать отзывчивый интерфейс с отображением пользователю промежуточных результатов работы нейросети.Адрес для передачи запросов по протоколу gRPC:gigachat.devices.sberbank.ruДля работы с API используйте proto-файл.gigachatv1.protosyntax = \"proto3\"; package gigachat.v1; option go_package = \"./;protocol\";// Возвращает ответ модели на сообщение в формате ChatRequestservice ChatService {  // Возврат ответа одним фрагментов  rpc Chat (ChatRequest) returns (ChatResponse);  // Потоковая передача фрагментов ответа  rpc ChatStream (ChatRequest) returns (stream ChatResponse);}// Сообщение, на которое ответит модельmessage ChatRequest {  // Параметры сообщения  ChatOptions options = 1;  // [Модель](https://developers.sber.ru/docs/ru/gigachat/models), которая будет генерировать ответ.  string model = 2;  // Массив сообщений. Передавайте сообщения с ролями user и assistant, чтобы сохранить контекст разговора с моделью.  repeated Message messages = 3;}// Параметры запроса, которые учитываются при генерировании ответаmessage ChatOptions {  reserved 3;  /**   * Температура выборки. Значение температуры должно быть больше ноля. Чем выше значение, тем более случайным будет ответ модели. При значениях температуры больше двух, набор токенов в ответе модели может отличаться избыточной случайностью.   * Значение по умолчанию зависит от выбранной модели (поле `model`) и может изменяться с обновлениями модели.   */  optional float temperature = 1;  /**   * Параметр используется как альтернатива температуре (поле `temperature`). Задает вероятностную массу токенов, которые должна учитывать модель.   * Так, если передать значение 0.1, модель будет учитывать только токены, чья вероятностная масса входит в верхние 10%.   * Значение по умолчанию зависит от выбранной модели (поле `model`) и может изменяться с обновлениями модели.   * Значение изменяется в диапазоне от 0 до 1 включительно.   */  optional float top_p = 2;  // Максимальное количество токенов, которые будут использованы для создания ответов. По умолчанию используется 2048 токенов.  optional int32 max_tokens = 4;  /**   * Количество повторений слов. Должно быть больше ноля. Возможные значения:   * - При значении от 0 до 1 модель повторять уже использованные слова.   * - Значение 1.0 — нейтральное значение.   * - При значении больше 1 модель будет стараться не повторять слова.   * Значение по умолчанию зависит от выбранной модели (поле `model`) и может изменяться с обновлениями модели.   */  optional float repetition_penalty = 5;  /**   * Параметр потокового режима (`\"stream\": \"true\"`).   * Задает минимальный интервал в секундах, который проходит между отправкой токенов.   * Например, если указать `1`, сообщения будут приходить каждую секунду, но размер каждого из них будет больше, так как за секунду накапливается много токенов.   * По умолчанию 0.   */  optional float update_interval = 6;  repeated string flags = 7;  /**   * Поле, которое отвечает за то, как GigaChat будет [работать с функциями](/ru/gigachat/api/function-calling). Может быть строкой или объектом.   *   * Возможные режимы работы функций определяются в FunctionCallPolicy   */  FunctionCallPolicy function_call = 8;  // Массив с описанием пользовательских функций.  repeated Function functions = 9;}// Режимы работы пользовательских функцийmessage FunctionCallPolicy {  // Перечисление возможных режимов вызовов функций.  // В зависимости от содержимого запроса, модель решает сгенерировать сообщение или вызвать функцию. Модель вызывает встроенные функции, если отсутствует массив `functions` с описанием пользовательских функций.  enum Mode {    undefined = 0;    // Если запрос содержит `\"function_call\": \"auto\"` и массив `functions` с описанием пользовательских функций, модель будет генерировать аргументы для описанных функций и не сможет вызвать встроенные функции независимо от содержимого запроса;    auto = 1;    // Режим работы по умолчанию. Если запрос не содержит массив функций `functions` или значение поля — `none`, GigaChat не вызовет функции, а просто сгенерирует ответ в соответствии с полученными сообщениями.    none = 2;  }  // Выбранный режим работы функции  Mode mode = 1;}// Описание пользовательской функцииmessage Function {  // Название пользовательской функции, для которой будут сгенерированы аргументы  string name = 1;  // Текстовое описание функции  string description = 2;  // Валидный JSON-объект с набором пар ключ-значение, которые описывают аргументы функции  string parameters = 3;  // Массив примеров работы функции в виде объектами с парами `запрос_пользователя`-`параметры_функции`, которые будут служить модели примерами ожидаемого результата.  repeated AnyExample few_shot_examples = 4;  // JSON-объект с описанием параметров, которые может вернуть ваша функция  optional string return_parameters = 5;}// Описание примера работы функцииmessage AnyExample {  // Запрос пользователя  string request = 1;  // Массив примеров заполнения параметров пользовательской функции  Params params = 2;}// Массив параметров пользовательской функцииmessage Params {  // Параметры функции, представленные объектами с парами `название_параметра`-`значение_параметра`, которые будут служить модели примерами ожидаемого результата.  repeated Pair pairs = 1;}// Параметры фукнции, сгенерированные моделью в формате ключ-значение.message Pair {  // Название параметра  string key = 1;  // Значение параметра  string value = 2;}// Описывает сообщение, которое можно передавать в запросе message Message {  reserved 3,4;  /**   * Роль автора сообщения:   * - `system` — системный промпт, который задает роль модели, например, должна модель отвечать как академик или как школьник;   * - `assistant` — ответ модели;   * - `user` — сообщение пользователя;   * - `function` — сообщение с результатом работы [пользовательской функции](/ru/gigachat/api/function-calling#rabota-s-sobstvennymi-funktsiyami). В сообщении с этой ролью передавайте в поле `content` валидный JSON-объект с результатами работы функции.   * Для сохранения контекста диалога с пользователем передайте несколько сообщений. Подробнее читайте в разделе [Работа с историей чата](/ru/gigachat/api/keeping-context).   */  string role = 1;  /**   * Содержимое сообщения. Зависит от роли.   * Если поле передается в сообщении с ролью `function`, то в нем указывается валидный JSON-объект с результатом выполнения функции.   * В остальных случаях содержит либо системный промпт (сообщение с ролью `system`), либо текст сообщения пользователя или модели.   */  string content = 2;  optional FunctionCall function_call = 5;  // Название функции, которое передается в сообщение с ролью `function`.  optional string function_name = 6;  bytes data_for_context = 7 [deprecated=true];  /**   * Идентификатор, который объединяет массив функций, переданных в запросе.   * Возвращается в ответе модели (сообщение с `\"role\": \"assistant\"`) если сообщение к модели содержало функции.   * Позволяет сохранить [контекст вызова функции](/ru/gigachat/api/function-calling#sohranenie-konteksta) и повысить качество работы модели.   * Для этого нужно передать идентификатор в запросе на генерацию в сообщении с ролью `assistant`.   */  optional string functions_state_id = 8;  /**   * Массив идентификаторов файлов, которые нужно использовать при генерации.   *    * Идентификатор присваивается файлу при [загрузке в хранилище](/ru/gigachat/api/reference/rest/post-file). Посмотреть список файлов в хранилище можно с помощью метода [`GET /files`](/ru/gigachat/api/reference/rest/get-files).   *   * В одном запросе можно передать только одно изображение. В одной сессии можно передать до 10 изображений.   * Подробнее — в разделе [Генерация с помощью файлов изображений](/ru/gigachat/api/working-with-files)   */  repeated string attachments = 11;}// Описание ответа моделиmessage ChatResponse {  reserved 5;  repeated Alternative alternatives = 1;  // Данные об использовании модели.  Usage usage = 2;  // Данные о модели  ModelInfo model_info = 3;  // Время ответа.  int64 timestamp = 4;}// Сгенерированное сообщениеmessage Alternative {  Message message = 1;  string finish_reason = 2;  int32 index = 3;}// Информация о количестве токенов, потраченных при генерации ответаmessage Usage {  reserved 4;  // Количество токенов во входящем сообщении (роль `user`)  int32 prompt_tokens = 1;  // Количество токенов, сгенерированных моделью (роль `assistant`)  int32 completion_tokens = 2;  // Общее количество токенов  int32 total_tokens = 3;}// Информация о моделиmessage ModelInfo {  // Название модели  string name = 1;  // Версия модели. Подробнее о версиях — в разделе [Обновления моделей](/ru/gigachat/models/updates).  string version = 2;}// Сгенерированный моделью вызов функции.message FunctionCall {  // Название функции  string name = 1;  //Аргументы функции. Содержат описание в JSON-формате.  string arguments = 2;}// Возвращает массив объектов с данными доступных моделей. Описание доступных моделей в разделе [Модели GigaChat](/ru/gigachat/models).service ModelsService {  rpc ListModels (ListModelsRequest) returns (ListModelsResponse);  rpc RetrieveModel (RetrieveModelRequest) returns (RetrieveModelResponse);}// Запрос списка доступных моделейmessage ListModelsRequest {}// Список с описанием доступных моделейmessage ListModelsResponse {  repeated Model models = 1;}// Описание моделиmessage Model {  // Название модели. Описание доступных моделей смотрите в разделе [Модели GigaChat](/ru/gigachat/models).  // При обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс `-preview`. Например, `GigaChat-Pro-preview`.  string name = 1;  // Тип сущности в ответе, например, модель  string object = 2;  // Владелец модели  string owned_by = 3;  // Тип модели. При запросах на генерацию передается тип chat.  string type = 8;} // Запрос модели по конекретному имениmessage RetrieveModelRequest {  string name = 1;} message RetrieveModelResponse {  Model model = 1;}Авторизация\\ufeffЗапросы к сервису авторизуются с помощью токена доступа по протоколу OAuth 2.0. Токен доступа передается в заголовке authorization.\\nПример:Bearer <токен доступа>Подробно о том как получить токен доступа читайте в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юридических лиц.Описание методов\\ufeffПолучить список моделей\\ufeffВозвращает массив объектов с данными доступных моделей.\\nВыполняется с пустым телом запроса.Ответ:ПримерОписаниеdataArray of objects (Model) [ items ] objectstring Тип сущности в ответе, например, список.\\nCopy Expand all  Collapse all {\"data\": [{\"id\": \"GigaChat\",\"object\": \"model\",\"owned_by\": \"salutedevices\"}],\"object\": \"list\"}dataArray of objects (Model) [ items ] objectstring Тип сущности в ответе, например, список.\\nCopy Expand all  Collapse all {\"data\": [{\"id\": \"GigaChat\",\"object\": \"model\",\"owned_by\": \"salutedevices\"}],\"object\": \"list\"}Получить модель\\ufeffВозвращает объект с описанием указанной модели.Параметры запроса:modelstring Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nCopy{\"model\": \"GigaChat\"}Ответ:ПримерОписаниеidstring Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nobjectstring Тип сущности в ответе, например, модель\\nowned_bystring Владелец модели\\nCopy{\"id\": \"GigaChat\",\"object\": \"model\",\"owned_by\": \"salutedevices\"}idstring Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nobjectstring Тип сущности в ответе, например, модель\\nowned_bystring Владелец модели\\nCopy{\"id\": \"GigaChat\",\"object\": \"model\",\"owned_by\": \"salutedevices\"}Получить ответ модели\\ufeffВозвращает ответ модели с учетом переданных сообщений.Параметры запроса:model required string Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nmessages required Array of objects (message) [ items ] Массив сообщений, которыми пользователь обменивался с моделью.\\nfunction_callfunction_call_custom_function (object) or function_call_none_auto (string) Поле, которое отвечает за то, как GigaChat будет работать с функциями.\\nМожет быть строкой или объектом.\\nВозможные значения:\\n\\nnone — режим работы по умолчанию. Если запрос не содержит function_call или значение поля — none, GigaChat не вызовет функции, а просто сгенерирует ответ в соответствии с полученными сообщениями;\\n\\nauto — в зависимости от содержимого запроса, модель решает сгенерировать сообщение или вызвать функцию.\\nМодель вызывает встроенные функции, если отсутствует массив functions с описанием пользовательских функций.\\nЕсли запрос содержит \"function_call\": \"auto\" и массив functions с описанием пользовательских функций, модель будет генерировать аргументы для описанных функций и не сможет вызвать встроенные функции независимо от содержимого запроса;\\n\\n{\"name\": \"название_функции\"} — принудительная генерация аргументов для указанной функции. Вы можете явно задать часть аргументов с помощью объекта partial_arguments. Остальные аргументы модель сгенерирует самостоятельно. При принудительной генерации, массив functions обязан содержать объект с описанием указанной функции. В противном случае вернется ошибка.\\n\\nfunctionsArray of objects[ items ] Массив с описанием пользовательских функций.\\ntemperaturenumber <float>   > 0  Температура выборки. Значение температуры должно быть больше ноля. Чем выше значение, тем более случайным будет ответ модели. При значениях температуры больше двух, набор токенов в ответе модели может отличаться избыточной случайностью.\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.\\ntop_pnumber <float>   [ 0 .. 1 ]  Параметр используется как альтернатива температуре (поле temperature). Задает вероятностную массу токенов, которые должна учитывать модель.\\nТак, если передать значение 0.1, модель будет учитывать только токены, чья вероятностная масса входит в верхние 10%.\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.\\nЗначение изменяется в диапазоне от 0 до 1 включительно.\\nninteger <int64>   [ 1 .. 4 ]  Deprecated  Default:  1 Количество вариантов ответов, которые нужно сгенерировать для каждого входного сообщения.\\nКоличество вариантов может изменяться от одного до четырех. По умолчанию модель возвращает один вариант ответа.\\nstreamboolean Default:  false Указывает что сообщения надо передавать по частям в потоке.\\nСообщения передаются по протоколу SSE.\\nПоток завершается событием data: [DONE].\\nПодробнее читайте в разделе Потоковая генерация токенов.\\nmax_tokensinteger <int32>  Максимальное количество токенов, которые будут использованы для создания ответов.\\nrepetition_penaltynumber <float>  Количество повторений слов:\\n\\nЗначение 1.0 — нейтральное значение.\\nПри значении больше 1 модель будет стараться не повторять слова.\\n\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.\\nupdate_intervalnumber Default:  0 Параметр потокового режима (\"stream\": \"true\").\\nЗадает минимальный интервал в секундах, который проходит между отправкой токенов.\\nНапример, если указать 1, сообщения будут приходить каждую секунду, но размер каждого из них будет больше, так как за секунду накапливается много токенов.\\nCopy Expand all  Collapse all {\"model\": \"GigaChat\",\"messages\": [{\"role\": \"user\",\"content\": null,\"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",\"data_for_context\": [{ }],\"attachments\": [[\"e7f0b84b-3d4f-4c2c-ac31-8855b1b0db0a\"]]}],\"function_call\": {\"name\": \"sbermarket-pizza_order\",\"partial_arguments\": { }},\"functions\": [{\"name\": \"pizza_order\",\"description\": \"Функция для заказа пиццы\",\"parameters\": { },\"few_shot_examples\": [{\"request\": \"Погода в Москве в ближайшие три дня\",\"params\": { }}],\"return_parameters\": { }}],\"temperature\": 0,\"top_p\": 1,\"n\": 1,\"stream\": false,\"max_tokens\": 0,\"repetition_penalty\": 1,\"update_interval\": 0}Ответ:ПримерОписаниеchoicesArray of objects (Choices) [ items ] Массив ответов модели.\\ncreatedinteger <int64>  Дата и время создания ответа в формате Unix time.\\nmodelstring Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nusageobject (Usage)  Данные об использовании модели.\\nobjectstring Название вызываемого метода.\\nCopy Expand all  Collapse all {\"choices\": [{\"message\": {\"role\": \"assistant\",\"content\": \"Здравствуйте! К сожалению, я не могу дать точный ответ на этот вопрос, так как это зависит от многих факторов. Однако обычно релиз новых функций и обновлений в GigaChat происходит постепенно и незаметно для пользователей. Рекомендую следить за новостями и обновлениями проекта в официальном сообществе GigaChat или на сайте разработчиков.\",\"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",\"function_call\": {\"name\": \"string\",\"arguments\": { }},\"data_for_context\": [{ }]},\"index\": 0,\"finish_reason\": \"stop\"}],\"created\": 1678878333,\"model\": \"GigaChat\",\"usage\": {\"prompt_tokens\": 18,\"completion_tokens\": 68,\"total_tokens\": 86},\"object\": \"chat.completion\"}choicesArray of objects (Choices) [ items ] Массив ответов модели.\\ncreatedinteger <int64>  Дата и время создания ответа в формате Unix time.\\nmodelstring Enum: \"GigaChat\" \"GigaChat-Pro\" \"GigaChat-Max\"  Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.\\nusageobject (Usage)  Данные об использовании модели.\\nobjectstring Название вызываемого метода.\\nCopy Expand all  Collapse all {\"choices\": [{\"message\": {\"role\": \"assistant\",\"content\": \"Здравствуйте! К сожалению, я не могу дать точный ответ на этот вопрос, так как это зависит от многих факторов. Однако обычно релиз новых функций и обновлений в GigaChat происходит постепенно и незаметно для пользователей. Рекомендую следить за новостями и обновлениями проекта в официальном сообществе GigaChat или на сайте разработчиков.\",\"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",\"function_call\": {\"name\": \"string\",\"arguments\": { }},\"data_for_context\": [{ }]},\"index\": 0,\"finish_reason\": \"stop\"}],\"created\": 1678878333,\"model\": \"GigaChat\",\"usage\": {\"prompt_tokens\": 18,\"completion_tokens\": 68,\"total_tokens\": 86},\"object\": \"chat.completion\"}Смотрите также\\ufeffОписание ошибокПолучить остаток токеновКоллекции запросов Postman'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/file-delete', 'title': 'Удалить файл | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/file-delete', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Удалить файл | Документация для разработчиковУдалить файлОбновлено 25 ноября 2024Скачать спецификациюPOST /files/:file/deleteПереводит статус файла в значение deleted.Запрос\\ufeffPath Parametersfile stringrequiredИдентификатор файла, который нужно удалитьОтветы\\ufeff200OKapplication/jsonСхемаПример из схемыSchemaid stringИдентификатор файлаdeleted booleanПризнак удаления файла{  \"id\": \"d3277ca1-a140-484a-a3b4-9a121bea4bdc\",  \"deleted\": true}Loading...Loading...Получить информацию о файлеСоздать эмбеддинг'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-balance', 'title': 'Получить остаток токенов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-balance', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить остаток токенов | Документация для разработчиковПолучить остаток токеновОбновлено 25 ноября 2024Скачать спецификациюGET /balanceВозвращает доступный остаток токенов для каждой из моделей.\\nМетод доступен только при покупке пакетов токенов.\\nЕсли вы оплачиваете работу с API по схеме pay-as-you-go, запрос вернет ошибку 403 Permission Denied.Подробнее о пакетах токенов — в разделах платные пакеты для физических лиц или для ИП и юридических лиц.Запрос\\ufeffHeader ParametersX-Request-ID stringX-Session-ID stringОтветы\\ufeff200401403OKapplication/jsonСхемаПример из схемыSchemabalance object[]Array [usage stringНазвание модели, например, GigaChat или embeddings.value integerОстаток токенов]{  \"balance\": [    {      \"usage\": \"GigaChat\",      \"value\": 100500    }  ]}Ошибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Ошибка доступа. Возникает возникает при отправке запроса если вы оплачиваете работу с API по схеме pay-as-you-go.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 403HTTP-код сообщения.message stringПо умолчанию: Permission deniedОписание ошибки.{  \"status\": 403,  \"message\": \"Permission denied\"}Loading...Loading...Подсчитать количество токеновgRPC API'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-file', 'title': 'Получить информацию о файле | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-file', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить информацию о файле | Документация для разработчиковПолучить информацию о файлеОбновлено 25 ноября 2024Скачать спецификациюGET /files/:fileВозвращает объект с описанием указанного файла.Запрос\\ufeffPath Parametersfile stringrequiredИдентификатор файла. Идентификатор содержится в поле найти в поле id объекта, который создается при загрузке файла в хранилище.Ответы\\ufeff200OKapplication/jsonСхемаПример из схемыSchemabytes integerrequiredРазмер файла в байтахcreated_at integerrequiredВремя создания файла в формате Unix-timefilename stringrequiredНазвание файлаid uuidv4requiredВозможные значения: Value must match regular expression (([0-9a-fA-F-])36)Идентификатор файла, который можно использовать при запросах на генерацию.\\nДля этого идентификаторы нужно передать в массиве attachments.\\nПодробнее — в разделе Обработка файлов.object stringrequiredТип объектаpurpose stringrequiredВозможные значения: [general]Назначение файлов. Значение general указывает на то, что файлы могут использоваться для генерации ответа моделиaccess_policy stringВозможные значения: [public, private]По умолчанию: privateДоступность файла возможные значения:\\n\\npublic;\\nprivate.\\n{  \"bytes\": 120000,  \"created_at\": 1677610602,  \"filename\": \"file123\",  \"id\": \"6f0b1291-c7f3-43c6-bb2e-9f3efb2dc98e\",  \"object\": \"file\",  \"purpose\": \"general\",  \"access_policy\": \"private\"}Loading...Loading...Скачать файлУдалить файл'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-file-id', 'title': 'Скачать файл | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-file-id', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Скачать файл | Документация для разработчиковСкачать файлОбновлено 25 ноября 2024Скачать спецификациюGET /files/:file_id/contentВозвращает файл изображения в бинарном представлении в формате JPG.Изображения создаются с помощью запроса POST /chat/completions.Подробнее читайте в разделе Создание изображений.Консоль запроса отключена из-за бинарного формата ответа.Request\\ufeffPath Parametersfile_id stringrequiredИдентификатор изображения, полученный в ответ на запрос пользователя о генерации изображений.\\nСодержится в ответе модели, в теге <img>, в атрибуте src.\\nПодробнее в разделе Генерация изображений.Header ParametersX-Client-ID stringОтветы\\ufeff200400401404OKimage/jpgСхемаSchemaanyInvalid model IDОшибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Указан неверный идентификатор модели.Список доступных моделей и их идентификаторов — в разделе Модели GigaChat.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 404HTTP-код сообщения.message stringПо умолчанию: No such modelОписание ошибки.{  \"status\": 404,  \"message\": \"No such model\"}Loading...Loading...Получить список доступных файловПолучить информацию о файле'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-files', 'title': 'Получить список доступных файлов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-files', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить список доступных файлов | Документация для разработчиковПолучить список доступных файловОбновлено 25 ноября 2024Скачать спецификациюGET /filesВозвращает массив объектов с данными доступных файлов.Запрос\\ufeffОтветы\\ufeff200OKapplication/jsonСхемаПример из схемыSchemadata object[]requiredArray [bytes integerrequiredРазмер файла в байтахcreated_at integerrequiredВремя создания файла в формате Unix-timefilename stringrequiredНазвание файлаid uuidv4requiredВозможные значения: Value must match regular expression (([0-9a-fA-F-])36)Идентификатор файла, который можно использовать при запросах на генерацию.\\nДля этого идентификаторы нужно передать в массиве attachments.\\nПодробнее — в разделе Обработка файлов.object stringrequiredТип объектаpurpose stringrequiredВозможные значения: [general]Назначение файлов. Значение general указывает на то, что файлы могут использоваться для генерации ответа моделиaccess_policy stringВозможные значения: [public, private]По умолчанию: privateДоступность файла возможные значения:\\n\\npublic;\\nprivate.\\n]{  \"data\": [    {      \"bytes\": 120000,      \"created_at\": 1677610602,      \"filename\": \"file123\",      \"id\": \"6f0b1291-c7f3-43c6-bb2e-9f3efb2dc98e\",      \"object\": \"file\",      \"purpose\": \"general\",      \"access_policy\": \"private\"    }  ]}Loading...Loading...Загрузить файлСкачать файл'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-models', 'title': 'Получить список моделей | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/get-models', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить список моделей | Документация для разработчиковПолучить список моделейОбновлено 25 ноября 2024Скачать спецификациюGET /modelsВозвращает массив объектов с данными доступных моделей. Описание доступных моделей в разделе Модели GigaChat.Request\\ufeffОтветы\\ufeff200401OKapplication/jsonСхемаПример из схемыSchemadata object[]Array [id stringВозможные значения: [GigaChat, GigaChat-Pro, GigaChat-Max]Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.object stringТип сущности в ответе, например, модельowned_by stringВладелец модели]object stringТип сущности в ответе, например, список.{  \"data\": [    {      \"id\": \"GigaChat\",      \"object\": \"model\",      \"owned_by\": \"salutedevices\"    }  ],  \"object\": \"list\"}Ошибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Loading...Loading...Получить токен доступаПолучить ответ модели на сообщения'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/gigachat-api', 'title': 'GigaChat API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/gigachat-api', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='GigaChat API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Version: 1.0.0GigaChat APIОбновлено 25 ноября 2024Справочная документация по REST API нейросетевой модели GigaChat.О стоимости и условиях использования GigaChat API вы можете узнать в разделе Тарифы и оплата.Получение токена доступа и авторизация запросов\\ufeffЗапросы к GigaChat API передаются по адресу https://gigachat.devices.sberbank.ru/ и авторизуются с помощью токена доступа по протоколу OAuth 2.0.\\nТокен доступа передается в заголовке Authorization:curl -L -X GET \\'https://gigachat.devices.sberbank.ru/api/v1/models\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\'Вы также можете передавать запросы к моделям в раннем доступе.\\nИх возможности могут отличаться от моделей, доступных в промышленном контуре.Для обращения к моделям в раннем доступе передавайте запросы по адресу https://gigachat-preview.devices.sberbank.ru/.Чтобы получить токен, отправьте запрос POST /api/v2/oauth:curl -L -X POST \\'https://ngw.devices.sberbank.ru:9443/api/v2/oauth\\' \\\\-H \\'Content-Type: application/x-www-form-urlencoded\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'RqUID: <идентификатор_запроса>\\' \\\\-H \\'Authorization: Basic ключ_авторизации\\' \\\\--data-urlencode \\'scope=GIGACHAT_API_PERS\\'Где:RqUID — обязательный заголовок, в котором нужно передать уникальный идентификатор запроса в формате uuid4. Идентификатор нужно указать самостоятельно, для этого можно использовать стандартные библиотеки и классы для генерации UUID и GUID.Authorization — обязательный заголовок, в котором нужно передать ключ авторизации — строку, полученную в результате кодирования в base64 идентификатора (Client ID) и клиентского ключа (Client Secret) API.scope — обязательное поле в теле запроса, которое указывает к какой версии API выполняется запрос. Возможные значения:GIGACHAT_API_PERS — доступ для физических лиц.GIGACHAT_API_B2B — доступ для ИП и юридических лиц по платным пакетам.GIGACHAT_API_CORP — доступ для ИП и юридических лиц по схеме pay-as-you-go.При успешном выполнении запроса GigaChat API вернет токен доступа, который действует в течение 30 минут:{  \"access_token\": \"eyJhbGci3iJkaXIiLCJlbmMiOiJBMTI4R0NNIiwidHlwIjoiSldUIn0..Dx7iF7cCxL8SSTKx.Uu9bPK3tPe_crdhOJqU3fmgJo_Ffvt4UsbTG6Nn0CHghuZgA4mD9qiUiSVC--okoGFkjO77W.vjYrk3T7vGM6SoxytPkDJw\",  \"expires_at\": 1679471442}Запросы на получение токена можно отправлять до 10 раз в секунду.Как получить ключ авторизации и токен доступа Access token читайте в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юридических лиц.Обращение к моделям в раннем доступе\\ufeffМодели для генерации GigaChat регулярно обновляются и у них появляются новые возможности, например, вызов функций.\\nВ таких случаях новые версии моделей некоторое время доступны в раннем доступе.Для обращения к таким моделям используйте адрес https://gigachat-preview.devices.sberbank.ru/, а к названию модели, которое передается в поле model, добавьте постфикс -preview.Подробнее — в разделе Модели GigaChat.Authentication\\ufeffHTTP: Basic AuthHTTP: Bearer AuthБазовая (Basic) аутентификация с помощью ключа авторизации — строки, полученной в результате кодирования в base64 идентификатора (Client ID) и клиентского ключа (Client Secret) API.Ключ авторизации передается в заголовке Authorization, в запросе на получение токена доступа.Как получить ключ авторизации и токен доступа Access token читайте в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юридических лиц.Security Scheme Type:httpHTTP Authorization Scheme:basicАутентификация с помощью токена доступа Access token. Используется во всех запросах к GigaChat API, кроме запроса на получение токена доступа.Security Scheme Type:httpHTTP Authorization Scheme:bearerBearer format:JWTContactGigaChat API: gigachat@sberbank.ruURL: https://developers.sber.ru/portal/products/gigachat-apiМониторинг статистики потребления GigaChat APIПолучить токен доступа'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-chat', 'title': 'Получить ответ модели на сообщения | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-chat', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить ответ модели на сообщения | Документация для разработчиковПолучить ответ модели на сообщенияОбновлено 25 ноября 2024Скачать спецификациюPOST /chat/completionsВозвращает ответ модели, сгенерированный на основе переданных сообщений.При генерации ответа модель может учитывать текстовые докуметы и изображения, сохраненные в хранилище.\\nДля этого передайте список идентификаторов файлов в массиве attachments.\\nВ одном сообщении (объект в массиве messages) можно передать только одно изображение.\\nВ одном запросе можно передать до 10 изображений, независимо от количества сообщений.При этом общий размер запроса должен быть меньше 20 Мб.Например, ваш запрос может включать текст промпта и два идентификатора изображений, которые ссылаются на файлы размерами 6 Мб и 12 Мб.Подробнее — в разделе Обработка файлов.Запрос на генерацию можно передавать моделям в раннем доступе.\\nДля обращения к ним используйте адрес https://gigachat-preview.devices.sberbank.ru/, а к названию модели, которое передается в поле model, добавьте постфикс -preview.Запрос\\ufeffHeader ParametersX-Client-ID stringX-Request-ID stringX-Session-ID stringapplication/jsonBodymodel stringrequiredВозможные значения: [GigaChat, GigaChat-Pro, GigaChat-Max]Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.messages object[]requiredМассив сообщений, которыми пользователь обменивался с моделью.Array [role stringВозможные значения: [system, user, assistant, function]Роль автора сообщения:\\n\\nsystem — системный промпт, который задает роль модели, например, должна модель отвечать как академик или как школьник;\\nassistant — ответ модели;\\nuser — сообщение пользователя;\\nfunction — сообщение с результатом работы пользовательской функции. В сообщении с этой ролью передавайте в поле content валидный JSON-объект с результатами работы функции.\\n\\nДля сохранения контекста диалога с пользователем передайте несколько сообщений. Подробнее читайте в разделе Работа с историей чата.content Содержимое сообщения. Зависит от роли.\\nЕсли поле передается в сообщении с ролью function, то в нем указывается валидный JSON-объект с аргументами функции, указанной в поле function_call.name.\\nВ остальных случаях содержит либо системный промпт (сообщение с ролью system), либо текст сообщения пользователя или модели.functions_state_id uuidv4Идентификатор, который объединяет массив функций, переданных в запросе.\\nВозвращается в ответе модели (сообщение с \"role\": \"assistant\") при вызове встроенных или собственных функций.\\nПозволяет сохранить контекст вызова функции и повысить качество работы модели.\\nДля этого нужно передать идентификатор в запросе на генерацию в сообщении с ролью assistant.\\nПоле заменяет массив data_for_context и является целевым решением для работы с функциями.\\nСейчас поле работает только при обращении к моделям в раннем доступе.data_for_context object[]Массив сообщений, описывающих работу встроенных функций.Для сохранения контекста, обязательно передавайте массив в запросе на генерацию, в сообщении с ролью assistant.Целевое решение для работы с функциями — поле functions_state_id.Array []attachments string[]Массив идентификаторов файлов, которые нужно использовать при генерации.\\nИдентификатор присваивается файлу при загрузке в хранилище.\\nПосмотреть список файлов в хранилище можно с помощью метода GET /files.\\nПри работе с текстовыми документами в одном запросе на генерацию нужно передавать только один идентификатор.\\nЕсли вы передадите несколько идентификаторов файлов, для генерации будет использован только первый файл из списка.\\nВ одном сообщении (объект в массиве messages) можно передать только одно изображение.\\nВ одной сессии можно передать до 10 изображений.\\n:::note\\nПри этом общий размер запроса должен быть меньше 20 Мб.\\nНапример, ваш запрос может включать текст промпта и два идентификатора изображений, которые ссылаются на файлы размерами 6 Мб и 12 Мб.\\n:::\\nПодробнее — в разделе Обработка файлов]function_call objectПоле, которое отвечает за то, как GigaChat будет работать с функциями.\\nМожет быть строкой или объектом.Возможные значения:none — режим работы по умолчанию. Если запрос не содержит function_call или значение поля — none, GigaChat не вызовет функции, а просто сгенерирует ответ в соответствии с полученными сообщениями;auto — в зависимости от содержимого запроса, модель решает сгенерировать сообщение или вызвать функцию.\\nМодель вызывает встроенные функции, если отсутствует массив functions с описанием пользовательских функций.\\nЕсли запрос содержит \"function_call\": \"auto\" и массив functions с описанием пользовательских функций, модель будет генерировать аргументы для описанных функций и не сможет вызвать встроенные функции независимо от содержимого запроса;{\"name\": \"название_функции\"} — принудительная генерация аргументов для указанной функции. Вы можете явно задать часть аргументов с помощью объекта partial_arguments. Остальные аргументы модель сгенерирует самостоятельно. При принудительной генерации, массив functions обязан содержать объект с описанием указанной функции. В противном случае вернется ошибка.oneOffunction_call_custom_functionfunction_call_none_autoname stringНазвание функции.partial_arguments objectJSON-объект в котором вы можете явно задать некоторые аргументы указанной функции. Остальные аргументы модель сгенерирует самостоятельно.stringPossible values: [auto, none]Режим работы с функциямиfunctions object[]Массив с описанием пользовательских функций.Array [name stringrequiredНазвание пользовательской функции, для которой будут сгенерированы аргументы.description stringТекстовое описание функции.parameters objectrequiredВалидный JSON-объект с набором пар ключ-значение, которые описывают аргументы функции.few_shot_examples object[]Объекты с парами запрос_пользователя-параметры_функции, которые будут служить модели примерами ожидаемого результата.Array [request stringrequiredЗапрос пользователя.params objectrequiredПример заполнения параметров пользовательской функции.]return_parameters objectJSON-объект с описанием параметров, которые может вернуть ваша функция.]temperature floatТемпература выборки. Значение температуры должно быть больше ноля. Чем выше значение, тем более случайным будет ответ модели. При значениях температуры больше двух, набор токенов в ответе модели может отличаться избыточной случайностью.\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.top_p floatВозможные значения: >= 0 и  <= 1Параметр используется как альтернатива температуре (поле temperature). Задает вероятностную массу токенов, которые должна учитывать модель.\\nТак, если передать значение 0.1, модель будет учитывать только токены, чья вероятностная масса входит в верхние 10%.\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.\\nЗначение изменяется в диапазоне от 0 до 1 включительно.n int64deprecatedВозможные значения: >= 1 и <= 4По умолчанию: 1Количество вариантов ответов, которые нужно сгенерировать для каждого входного сообщения.\\nКоличество вариантов может изменяться от одного до четырех. По умолчанию модель возвращает один вариант ответа.stream booleanПо умолчанию: falseУказывает что сообщения надо передавать по частям в потоке.\\nСообщения передаются по протоколу SSE.\\nПоток завершается событием data: [DONE].\\nПодробнее читайте в разделе Потоковая генерация токенов.max_tokens int32Максимальное количество токенов, которые будут использованы для создания ответов.repetition_penalty floatКоличество повторений слов:\\n\\nЗначение 1.0 — нейтральное значение.\\nПри значении больше 1 модель будет стараться не повторять слова.\\n\\nЗначение по умолчанию зависит от выбранной модели (поле model) и может изменяться с обновлениями модели.update_interval numberПараметр потокового режима (\"stream\": \"true\").\\nЗадает минимальный интервал в секундах, который проходит между отправкой токенов.\\nНапример, если указать 1, сообщения будут приходить каждую секунду, но размер каждого из них будет больше, так как за секунду накапливается много токенов.Ответы\\ufeff200400401404422429500OKapplication/jsonСхемаПример из схемыSchemachoices object[]Массив ответов модели.Array [message objectСгенерированное сообщение.role stringВозможные значения: [assistant, function_in_progress]Роль автора сообщения.\\nРоль function_in_progress используется при работе встроенных функций в режиме потоковой передачи токенов.content stringСодержимое сообщения, например, результат генерации.\\nВ сообщениях с ролью function_in_progress содержит информацию о том, сколько времени осталось до завершения работы встроенной функции.functions_state_id uuidv4Идентификатор, который объединяет массив функций, переданных в запросе.\\nВозвращается в ответе модели (сообщение с \"role\": \"assistant\") при вызове встроенных или собственных функций.\\nПозволяет сохранить контекст вызова функции и повысить качество работы модели.\\nДля этого нужно передать идентификатор в запросе на генерацию в сообщении с ролью assistant.\\nПоле заменяет массив data_for_context и является целевым решением для работы с функциями.\\nСейчас поле работает только при обращении к моделям в раннем доступе.function_call objectname stringНазвание функции.arguments objectАргументы для вызова функции в виде пар ключ-значение.data_for_context object[]Массив сообщений, описывающих работу встроенных функций.Для сохранения контекста, обязательно передавайте массив в запросе на генерацию, в сообщении с ролью assistant.Целевое решение для работы с функциями — поле functions_state_id.Array []index int32Индекс сообщения в массиве, начиная с ноля.finish_reason stringВозможные значения: [stop, length, function_call, blacklist, error]Причина завершения гипотезы. Возможные значения:\\n\\nstop — модель закончила формировать гипотезу и вернула полный ответ;\\nlength — достигнут лимит токенов в сообщении;\\nfunction_call — указывает, что при запросе была вызвана встроенная функция или сгенерированы аргументы для пользовательской функции;\\nblacklist — запрос попадает под тематические ограничения.\\nerror — ответ модели содержит невалидные аргументы пользовательской функции.\\n]created int64Дата и время создания ответа в формате Unix time.model stringВозможные значения: [GigaChat, GigaChat-Pro, GigaChat-Max]Название модели. Описание доступных моделей смотрите в разделе Модели GigaChat.\\nПри обращении к моделям в раннем доступе к названию модели нужно добавлять постфикс -preview.\\nНапример, GigaChat-Pro-preview.usage objectДанные об использовании модели.prompt_tokens int32Количество токенов во входящем сообщении (роль user).completion_tokens int32Количество токенов, сгенерированных моделью (роль assistant).total_tokens int32Общее количество токенов.object stringНазвание вызываемого метода.{  \"choices\": [    {      \"message\": {        \"role\": \"assistant\",        \"content\": \"Здравствуйте! К сожалению, я не могу дать точный ответ на этот вопрос, так как это зависит от многих факторов. Однако обычно релиз новых функций и обновлений в GigaChat происходит постепенно и незаметно для пользователей. Рекомендую следить за новостями и обновлениями проекта в официальном сообществе GigaChat или на сайте разработчиков.\",        \"functions_state_id\": \"77d3fb14-457a-46ba-937e-8d856156d003\",        \"function_call\": {          \"name\": \"string\",          \"arguments\": {}        },        \"data_for_context\": [          {}        ]      },      \"index\": 0,      \"finish_reason\": \"stop\"    }  ],  \"created\": 1678878333,  \"model\": \"GigaChat\",  \"usage\": {    \"prompt_tokens\": 18,    \"completion_tokens\": 68,    \"total_tokens\": 86  },  \"object\": \"chat.completion\"}400 Bad request.Некорректный формат запроса.Ошибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Указан неверный идентификатор модели.Список доступных моделей и их идентификаторов — в разделе Модели GigaChat.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 404HTTP-код сообщения.message stringПо умолчанию: No such modelОписание ошибки.{  \"status\": 404,  \"message\": \"No such model\"}Ошибка валидации параметров запроса. Проверьте названия полей и значения параметров.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 422HTTP-код сообщения.message stringОписание ошибки.{  \"status\": 422,  \"message\": \"Invalid params: repetition_penalty must be in range (0, +inf)\"}Слишком много запросов в единицу времени.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 429HTTP-код сообщения.message stringПо умолчанию: Too many requestsОписание ошибки.{  \"status\": 429,  \"message\": \"Too many requests\"}Внутренняя ошибка сервера.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 500HTTP-код сообщения.message stringПо умолчанию: Internal Server ErrorОписание ошибки.{  \"status\": 500,  \"message\": \"Internal Server Error\"}Loading...Loading...Получить список моделейЗагрузить файл'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-embeddings', 'title': 'Создать эмбеддинг | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-embeddings', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Создать эмбеддинг | Документация для разработчиковСоздать эмбеддингОбновлено 25 ноября 2024Скачать спецификациюPOST /embeddingsВозвращает векторные представления соответствующих текстовых запросов. Индекс объекта с векторным представлением (поле index) соответствует индексу строки в массиве input запроса.Векторное представление выглядит как массив чисел embedding. Каждое значение в массиве представляет одну из характеристик или признаков текста, учтенных при вычислении эмбеддинга. Значения образуют числовое представление текста и позволяют анализировать и использовать текст в различных задачах. Как правило, чем ближе значения эмбеддингов друг к другу, тем более семантически близки тексты.Запрос\\ufeffapplication/jsonBodymodel stringrequiredПо умолчанию: EmbeddingsНазвание модели, которая будет использована для создания эмбеддинга.input string[]requiredСтрока или массив строк, которые будут использованы для генерации эмбеддинга.Ответы\\ufeff200401OKapplication/jsonСхемаПример из схемыSchemaobject stringrequiredПо умолчанию: listФормат структуры данных.data object[]requiredArray [object stringrequiredПо умолчанию: embeddingТип объекта.embedding float[]requiredМассив чисел, представляющих значения эмбеддинга для предоставленного текста.index integerrequiredИндекс соответствующий индексу текста, полученного в массиве input запроса.usage objectrequiredprompt_tokens numberКоличество токенов в строке, для которой сгенерирован эмбеддинг.]model stringПо умолчанию: EmbeddingsНазвание модели, которая используется для вычисления эмбеддинга.{  \"object\": \"list\",  \"data\": [    {      \"object\": \"embedding\",      \"embedding\": [        0      ],      \"index\": 0,      \"usage\": {        \"prompt_tokens\": 6      }    }  ],  \"model\": \"Embeddings\"}Ошибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Loading...Loading...Удалить файлПодсчитать количество токенов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-file', 'title': 'Загрузить файл | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-file', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Загрузить файл | Документация для разработчиковЗагрузить файлОбновлено 25 ноября 2024Скачать спецификациюPOST /filesЗагружает в хранилище текстовые документы или изображения.\\nВозвращает объект с данными загруженного файла.\\nЗагруженные файлы доступны только вам.Идентификатор файла, указанный в поле id, можно использовать при запросах на генерацию.\\nДля этого идентификаторы нужно передать в массиве attachments.\\nПодробнее — в разделе Обработка файлов.Хранилище поддерживает текстовые документы и изображения разных форматов.Текстовые документыИзображенияФорматMIME-типtxttext/plaindocapplication/vnd.openxmlformats-officedocument.wordprocessingml.documentdocxapplication/mswordpdfapplication/pdfФорматMIME-типjpgimage/jpgpngimage/pngtiffimage/tiffbmpimage/bmpНа размеры файлов действуют ограничения:максимальный размер одного текстового файла в запросе — 30 Мб;максимальный размер одного изображения в запросе — 15 Мб.Запрос\\ufeffmultipart/form-dataBodyrequiredfile binaryrequiredЗагружаемый объектpurpose stringrequiredВозможные значения: [general]По умолчанию: generalНазначение загружаемого файлаОтветы\\ufeff200OKapplication/jsonСхемаПример из схемыSchemabytes integerrequiredРазмер файла в байтахcreated_at integerrequiredВремя создания файла в формате Unix-timefilename stringrequiredНазвание файлаid uuidv4requiredВозможные значения: Value must match regular expression (([0-9a-fA-F-])36)Идентификатор файла, который можно использовать при запросах на генерацию.\\nДля этого идентификаторы нужно передать в массиве attachments.\\nПодробнее — в разделе Обработка файлов.object stringrequiredТип объектаpurpose stringrequiredВозможные значения: [general]Назначение файлов. Значение general указывает на то, что файлы могут использоваться для генерации ответа моделиaccess_policy stringВозможные значения: [public, private]По умолчанию: privateДоступность файла возможные значения:\\n\\npublic;\\nprivate.\\n{  \"bytes\": 120000,  \"created_at\": 1677610602,  \"filename\": \"file123\",  \"id\": \"6f0b1291-c7f3-43c6-bb2e-9f3efb2dc98e\",  \"object\": \"file\",  \"purpose\": \"general\",  \"access_policy\": \"private\"}Loading...Loading...Получить ответ модели на сообщенияПолучить список доступных файлов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-token', 'title': 'Получить токен доступа | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-token', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Получить токен доступа | Документация для разработчиковПолучить токен доступаОбновлено 25 ноября 2024Скачать спецификациюPOST /oauthВозвращает токен доступа для авторизации запросов к API.\\nТокен доступа действителен в течение 30 минут.\\nЗапросы на получение токена можно отправлять до 10 раз в секунду.В заголовке Authorization нужно передать ключ авторизации — строку, полученную в результате кодирования в base64 идентификатора (Client ID) и клиентского ключа (Client Secret) API.Консоль запросов автоматически кодирует заданные идентификатор и клиентский ключ.Как получить ключ авторизации и токен доступа Access token читайте в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юридических лиц.Запрос\\ufeffHeader ParametersRqUID uuidv4requiredВозможные значения: Value must match regular expression (([0-9a-fA-F-])36)Уникальный идентификатор запроса. Соответствует формату uuid4.\\nПараметр для журналирования входящих вызовов и разбора инцидентов.\\nИдентификатор нужно указать самостоятельно, для этого можно использовать стандартные библиотеки и классы для генерации UUID и GUID.\\nПример: 6f0b1291-c7f3-43c6-bb2e-9f3efb2dc98e.application/x-www-form-urlencodedBodyscope stringrequiredВозможные значения: [GIGACHAT_API_PERS, GIGACHAT_API_B2B, GIGACHAT_API_CORP]Версия API. Возможные значения:\\n\\nGIGACHAT_API_PERS — доступ для физических лиц.\\nGIGACHAT_API_B2B — доступ для ИП и юридических лиц по платным пакетам.\\nGIGACHAT_API_CORP — доступ для ИП и юридических лиц по схеме pay-as-you-go.\\nОтветы\\ufeff200400401OKapplication/jsonСхемаПример из схемыSchemaaccess_token stringТокен для авторизации запросов.expires_at int64Дата и время истечения действия токена в формате Unix time.{  \"access_token\": \"eyJhbGci3iJkaXIiLCJlbmMiOiJBMTI4R0NNIiwidHlwIjoiSldUIn0..Dx7iF7cCxL8SSTKx.Uu9bPK3tPe_crdhOJqU3fmgJo_Ffvt4UsbTG6Nn0CHghuZgA4mD9qiUiSVC--okoGFkjO77W.vjYrk3T7vGM6SoxytPkDJw\",  \"expires_at\": 1679471442}400 Bad request.Некорректный формат запроса.Ошибка авторизации.application/jsonСхемаПример из схемыSchemacode integerКод ошибки.message stringОписание ошибки.{  \"code\": 6,  \"message\": \"credentials doesn\\'t match db data\"}Loading...Loading...IntroductionПолучить список моделей'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-tokens-count', 'title': 'Подсчитать количество токенов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/reference/rest/post-tokens-count', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Подсчитать количество токенов | Документация для разработчиковПодсчитать количество токеновОбновлено 25 ноября 2024Скачать спецификациюPOST /tokens/countВозвращает объект с информацией о количестве токенов, подсчитанных заданной моделью в строках. Строки передаются в массиве input.Запрос\\ufeffapplication/jsonBodymodel stringrequiredВозможные значения: [GigaChat, GigaChat-Pro, GigaChat-Max]Название модели, которая будет использована для подсчета количества токенов.input string[]requiredСтрока или массив строк, в которых надо подсчитать количество токенов.Ответы\\ufeff200401OKapplication/jsonСхемаПример из схемыSchemaArray [object stringПо умолчанию: tokensОписание того, какая информация содержится в объекте.tokens integerКоличество токенов в соответствующей строке.characters integerКоличество символов в соответствующей строке.][  {    \"object\": \"tokens\",    \"tokens\": 7,    \"characters\": 36  }]Ошибка авторизации.application/jsonСхемаПример из схемыSchemastatus integerПо умолчанию: 401HTTP-код сообщения.message stringПо умолчанию: UnauthorizedОписание ошибки.{  \"status\": 401,  \"message\": \"Unauthorized\"}Loading...Loading...Создать эмбеддингПолучить остаток токенов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/response-token-streaming', 'title': 'Потоковая генерация токенов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/response-token-streaming', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Потоковая генерация токенов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Потоковая генерация токеновОбновлено 11 ноября 2024Режим получения потока токенов поможет обрабатывать ответ GigaChat по мере его генерации.При включении этого режима GigaChat передает токены в потоке коротких сообщений, формат которых соответствует протоколу server-sent events. Последним в потоке будет событие data: [DONE].GigaChat APIGigaChainВы можете включить потоковую генерацию токенов.\\nДля этого в запросе POST /chat/completions нужно передать параметр \"stream\": true.Пример запроса:curl https://gigachat.devices.sberbank.ru/api/v1/chat/completions \\\\  -H \\'Content-Type: application/json\\' \\\\  -H \\'Authorization: Bearer Token ***\\' \\\\  -d \\'{  \"model\": \"GigaChat\",  \"messages\": [{\"role\": \"user\", \"content\": \"Say this is a test!\"}],  \"stream\": true}\\'Пример потока событий:data: {    \"choices\":    [        {            \"delta\":            {                \"content\": \"GigaСhat\",                \"role\": \"assistant\"            },            \"index\": 0        }    ],    \"created\": 1683034756,    \"model\": \"GigaChat\",    \"object\": \"chat.completion\"}data:{    \"choices\":    [        {            \"delta\":            {                \"content\": \" спешит\"            },            \"index\": 0        }    ],    \"created\": 1683034756,    \"model\": \"GigaChat\",    \"object\": \"chat.completion\"}data:{    \"choices\":    [        {            \"delta\":            {                \"content\": \" на\"            },            \"index\": 0        }    ],    \"created\": 1683034756,    \"model\": \"GigaChat\",    \"object\": \"chat.completion\"}data:{    \"choices\":    [        {            \"delta\":            {                \"content\": \" помощь\"            },            \"index\": 0        }    ],    \"created\": 1683034756,    \"model\": \"GigaChat\",    \"object\": \"chat.completion\"}data: [DONE]Для поддержки потоковой генерации токенов с помощью GigaChain нужно унаследоваться от класса BaseCallbackHandler и инициализировать модуль GigaChat в режиме обработки потока токенов streaming=True:from langchain.schema import HumanMessagefrom langchain.callbacks.base import BaseCallbackHandlerfrom langchain_gigachat.chat_models import GigaChatclass StreamHandler(BaseCallbackHandler):    def __init__(self, initial_text=\"\"):        pass    def on_llm_new_token(self, token: str, **kwargs) -> None:        print(f\"{token} -\", end=\"\", flush=True)        chat = GigaChat(credentials=\\'ключ_авторизации\\', streaming=True, callbacks=[StreamHandler()])chat([HumanMessage(content=\"Напиши краткое содержание романа «Евгений Онегин»\")])Работа с историей чатаВекторное представление текста'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/selecting-a-model', 'title': 'Выбор модели для генерации | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/selecting-a-model', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Выбор модели для генерации | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Выбор модели для генерацииОбновлено 11 ноября 2024При работе с GigaChat с помощью API и SDK нужно выбирать модель, к которой будет сделан запрос.\\nРазные модели можно использовать в разных сценариях.\\nПодробное описание моделей — в разделе Модели GigaChat.GigaChat APIGigaChainЧтобы задать модель, передайте ее название в поле model, в запросе POST /chat/completions:curl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"<название_модели>\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Привет! Расскажи о себе.\"    }  ],  \"n\": 1,  \"stream\": false,  \"max_tokens\": 512,  \"repetition_penalty\": 1,  \"update_interval\": 0}\\'GigaChain по умолчанию работает с базовой моделью GigaChat.\\nЧтобы явно задать модель, передайте параметр model при инициализации GigaChat:from langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\\'ключ_авторизации\\', model=\\'<название_модели>\\', verify_ssl_certs=False)Возможные значения поля model:GigaChat — подойдет для решения более простых задач, требующих при этом максимальной скорости работы модели. При этом стоимость работы с моделью ниже, так как для ее работы нужно меньше аппаратных ресурсов.GigaChat-Pro — модель лучше следует сложным инструкциям и может выполнять более комплексные задачи: значительно повысилось качество суммаризации, переписывания и редактирования текстов, ответов на различные вопросы.Смотрите также\\ufeffМодели GigaChatТарифы и оплатаБыстрый старт GigaChainНачало работы с APIРабота с историей чата'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/tariffs', 'title': 'Тарифы GigaChat API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/tariffs', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Тарифы GigaChat API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Тарифы GigaChat APIОбновлено 25 ноября 2024В этом разделе содержится информация о тарифах GigaChat API и способах оплаты.Все цены указаны включая НДС.Тарифы GigaChat API для физлиц\\ufeffФизическим лицам доступен freemium-режим и платные пакеты токенов.Freemium-режим\\ufeffВ рамках freemium-режима пользователи получают 1 000 000 бесплатных токенов для генерации текста:УслугаМодельСрок действия900 000 токенов для генерации текстаGigaChat Lite12 месяцев50 000 токенов для генерации текстаGigaChat Pro12 месяцев50 000 токенов для генерации текстаGigaChat Max12 месяцевГенерация текста выполняется в одном потоке.\\nЛимит обновляется раз в 12 месяцев.Платные пакеты\\ufeffПри недостатке бесплатных токенов можно докупить пакеты услуг для генерации и векторного представления текста.\\nВсе цены указаны в рублях, включая НДС.\\nПодробнее об условиях оплаты — в разделе Покупка токенов. Стоимость генерации текстаПакетЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия5 000 000 токенов GigaChat LiteGigaChatGigaChat-preview5 000 0001 000 ₽12 месяцев30 000 000 токенов GigaChat LiteGigaChatGigaChat-preview30 000 0005 820 ₽12 месяцев1 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview1 000 0001 500 ₽12 месяцев5 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview5 000 0007 275 ₽12 месяцев1 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview1 000 0001 950 ₽12 месяцев5 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview5 000 0007 566 ₽12 месяцевСтоимость векторного представления текстаУслугаЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия10 000 000 токенов EmbeddingsEmbeddings10 000 000400 ₽шесть месяцевТарифы GigaChat API для юрлиц\\ufeffЮридическим лицам и индивидуальным предпринимателям доступны платные пакеты токенов и оплата по схеме pay-as-you-go.Платные пакеты\\ufeffПакетная тарификация с оплатой по счету-оферте или договору.\\nВсе цены указаны в рублях, включая НДС.Подробнее об условиях и способах оплаты — в разделе Регистрация и покупка токенов.Стоимость генерации с помощью модели GigaChat LiteПакетЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия25 000 000 токенов GigaChat LiteGigaChatGigaChat-preview25 000 0005 000 ₽12 месяцев125 000 000 токенов GigaChat LiteGigaChatGigaChat-preview125 000 00025 000 ₽12 месяцев250 000 000 токенов GigaChat LiteGigaChatGigaChat-preview250 000 00048 500 ₽12 месяцев500 000 000 токенов GigaChat LiteGigaChatGigaChat-preview500 000 00095 000 ₽12 месяцевСтоимость генерации с помощью модели GigaChat ProПакетЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия7 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview7 000 00010 500 ₽12 месяцев50 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview50 000 00075 000 ₽12 месяцев100 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview100 000 000145 500 ₽12 месяцев200 000 000 токенов GigaChat ProGigaChat-ProGigaChat-Pro-preview200 000 000285 000 ₽12 месяцевСтоимость генерации с помощью модели GigaChat MaxПакетЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия8 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview8 000 00015 600 ₽12 месяцев50 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview50 000 00097 500 ₽12 месяцев100 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview100 000 000189 500 ₽12 месяцев200 000 000 токенов GigaChat MaxGigaChat-MaxGigaChat-Max-preview200 000 000370 500 ₽12 месяцевСтоимость векторного представления текстаУслугаЗначение поля modelКоличество токеновЦена, вкл. НДССрок действия125 000 000 токенов EmbeddingsEmbeddings125 000 0005 000 ₽12 месяцев400 000 000 токенов EmbeddingsEmbeddings400 000 00016 000 ₽12 месяцев800 000 000 токенов EmbeddingsEmbeddings800 000 00031 040 ₽12 месяцев1 600 000 000 токенов EmbeddingsEmbeddings1 600 000 00060 800 ₽12 месяцевОплата pay-as-you-go\\ufeffPay-as-you-go — фактическая тарификация с оплатой по счету-оферте или договору с ежемесячным списанием.\\nВсе цены указаны в рублях, включая НДС.Подробнее об условиях — в разделе Регистрация и покупка токенов.Минимальный базовый тарифМинимальная стоимость использования сервиса — 600 рублей в месяц, включая НДС (не является абонентской платой).Если вы не использовали сервис в отчетном месяце, то вы ничего не платите.Если объем использования сервиса в отчетном месяце — менее 600 рублей, то вы платите 600 рублей.Если объем использования сервиса в отчетном месяце — 600 рублей и более, стоимость рассчитывается по правилам тарифа.Стоимость генерации текстаМодельЗначение поля modelЦена за 1000 токенов, вкл. НДСGigaChat LiteGigaChatGigaChat-preview0,2 ₽GigaChat ProGigaChat-ProGigaChat-Pro-preview1,5 ₽GigaChat MaxGigaChat-MaxGigaChat-Max-preview1,95 ₽Если вы работаете с GigaChat API как юридическое лицо по схеме pay-as-you-go, обратите внимание, что отдельный тариф для GigaChat Max начнет действовать с 1.12.2024.\\nДо начала работы тарифов запросы к модели GigaChat Max будут тарифицироваться как запросы GigaChat Pro.Стоимость векторного представления текстаМодельЗначение поля modelЦена за 1000 токенов, вкл. НДСБазовая модель EmbedderEmbeddings0,04 ₽Обновления моделейКвоты и ограничения'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/token-consumption', 'title': 'Мониторинг статистики потребления GigaChat API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/token-consumption', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Мониторинг статистики потребления GigaChat API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Мониторинг статистики потребления GigaChat APIОбновлено 3 октября 2024Для просмотра данных о потреблении токенов GigaChat API:Авторизуйтесь в личном кабинете.Откройте проект GigaChat API.Перейдите в раздел Статистика использования.В разделе доступны график и таблица с данными об использованных услугах: генерации с помощью различных моделей, создании эмбеддингов, а также данные о количестве затраченных сессий и токенов.Для скачивания отчета в формате xlsx, нажмите кнопку Скачайте отчет в верхнем правом углу.Обработка файловIntroduction'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/video-tutorials', 'title': 'Обучающие материалы | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/video-tutorials', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Обучающие материалы | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Обучающие материалыОбновлено 11 сентября 2024В этом разделе собраны обучающие материалы по работе с GigaChat API.НазваниеТипАвторВводное видео о возможностях API на платформе EdutoriaВидеоБыстрый старт: GigaChat API и GigaChain за 1 минутуВидеоКак начать работу с GigaChat API? Подробный туториал на PythonВидеоурокСергей ТращенковКак подключить GigaChat API к Telegram-боту? Подробное руководство на PythonВидеоурокСергей ТращенковSaluteSpeech API + GigaChat API: Как научить бота слушать и говорить, используя Python?ВидеоурокСергей ТращенковGigaChat API и БД. Как можно общаться с базами данных с помощью ИИ?ВидеоурокСергей ТращенковLangflow. Как создавать приложения с GigaChat API или Ollama из блоков?ВидеоурокСергей ТращенковSaluteSpeech API + GigaChat API: Как научить бота слушать и говорить, используя Python?ВидеоурокСергей ТращенковMoondream2 + GigaChat API: Помогаем LLM видетьВидеоурокСергей ТращенковРабота с LLM GigaChatКурсGigaChat: нейросетевая модель для маркетологов и не толькоКурсИспользование сертификатов НУЦ Минцифры в GigaChatИстория обновлений'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/api/working-with-files', 'title': 'Обработка файлов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/api/working-with-files', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Обработка файлов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Обработка файловОбновлено 25 ноября 2024Модели GigaChat умеют обрабатывать текстовые документы и изображения, и использовать их при генерации ответов.\\nДля этого вы можете загрузить необходимые файлы в хранилище и передать запрос с идентификатором файла в выбранную модель GigaChat.\\nПри генерации ответа, модель будет учитывать указанное изображение.Работа с хранилищем файлов\\ufeffХранилище файлов позволяет получить идентификатор файла, который можно использовать при запросе к модели.\\nДля работы с хранилищем GigaChat API предоставляет методы:POST /files;GET /files;GET /files/{file};POST /files/{file}/delete.Загрузка файла в хранилище\\ufeffДля загрузки файла в хранилище используйте метод POST /files.\\nЗагруженные файлы будут доступны только вам.Хранилище поддерживает текстовые документы и изображения разных форматов.Текстовые документыИзображенияФорматMIME-типtxttext/plaindocapplication/vnd.openxmlformats-officedocument.wordprocessingml.documentdocxapplication/mswordpdfapplication/pdfФорматMIME-типjpgimage/jpgpngimage/pngtiffimage/tiffbmpimage/bmpНа размеры файлов действуют ограничения:максимальный размер одного текстового файла в запросе — 30 Мб;максимальный размер одного изображения в запросе — 15 Мб.Чтобы модель использовала файл для генерации, укажите его идентификатор в массиве attachments, в запросе на генерацию POST /chat/completions.Пример запроса для загрузки файлов:cURLPythoncurl --location --request POST \\'https://gigachat.devices.sberbank.ru/api/v1/files\\' \\\\--header \\'Authorization: Bearer access_token\\' \\\\--form \\'file=@\"<путь_к_файлу>/example.jpeg\"\\' \\\\--form \\'purpose=\"general\"\\'import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/files\"payload = {\\'purpose\\': \\'general\\'}files=[(\\'file\\',(\\'response.jpeg\\',open(\\'<путь_к_файлу)>/example.jpeg\\',\\'rb\\'),\\'image/jpeg\\'))]headers = {\\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"POST\", url, headers=headers, data=payload, files=files)print(response.text)В запросе обязательно нужно указать значение поля purpose=\"general\".\\nЭто позволит использовать файл в запросах на генерацию ответов.В ответ вы получите объект с описанием файла:{  \"bytes\": 120000,  \"created_at\": 1677610602,  \"filename\": \"file123\",  \"id\": \"6f0b1291-c7f3-43c6-bb2e-9f3efb2dc98e\",  \"object\": \"file\",  \"purpose\": \"general\",  \"access_policy\": \"private\"}Описание параметров — в справке API.Получение информации о файлах\\ufeffДля получения информации о доступных в хранилище файлах GigaChat API предоставляет два метода: GET /files и GET /files/{file}.Для получения списка всех доступных вам файлов используйте метод GET /files:cURLPythoncurl -L -X GET \\'https://gigachat.devices.sberbank.ru/api/v1/files\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer access_token\\'import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/files\"payload={}headers = {\\'Accept\\': \\'application/json\\',\\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"GET\", url, headers=headers, data=payload)print(response.text)Для получения информации об отдельном файле используйте метод GET /files/{file}:cURLPythoncurl -L -X GET \\'https://gigachat.devices.sberbank.ru/api/v1/files/:file\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer access_token\\'import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/files/:file\"payload={}headers = {\\'Accept\\': \\'application/json\\',\\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"GET\", url, headers=headers, data=payload)print(response.text)Удаление файла из хранилища\\ufeffДля удаления файла из хранилища используйте метод POST /files/{file}/delete.\\nВ параметрах пути укажите идентификатор файла, который был получен при его загрузке в хранилище:cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/files/:file/delete\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer access_token\\'import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/files/:file/delete\"payload={}headers = {\\'Accept\\': \\'application/json\\',\\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)После удаления файл нельзя будет использовать для генерации.Использование файлов для генерации ответов\\ufeffПосле загрузки файла в хранилище и получения его идентификатора, вы можете использовать его в запросах на генерацию.Для этого передайте идентификаторы файлов, которые нужно использовать для генерации, в массиве attachments.Использование текстовых файлов\\ufeffДля генерации с помощью загруженного текстового документа передайте его идентификатор в массиве attachments. Одновременно можно использовать только один документ. Если вы передадите несколько идентификаторов файлов, для генерации будет использован только первый документ из списка.cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer access_token\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Расскажи вкратце, что изложено в документе?\",      \"attachments\": [        \"1460d895-2b26-4ce0-8b0d-cc7665a969df\"      ]    }  ],  \"stream\": false,  \"update_interval\": 0}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\"payload = json.dumps({  \"model\": \"GigaChat-Pro\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Расскажи вкратце, что изложено в документе?\",      \"attachments\": [        \"1460d895-2b26-4ce0-8b0d-cc7665a969df\"      ]    }  ],  \"stream\": False,  \"update_interval\": 0})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Использование изображений\\ufeffВ одном сообщении (объект в массиве messages) можно передать только одно изображение.\\nВ одном запросе можно передать до 10 изображений, независимо от количества сообщений.При этом общий размер запроса должен быть меньше 20 Мб.Например, ваш запрос может включать текст промпта и два идентификатора изображений, которые ссылаются на файлы размерами 6 Мб и 12 Мб.Примеры запросов на генерацию с использованием загруженных изображений.cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer access_token\\' \\\\--data-raw \\'{  \"model\": \"GigaChat-Pro\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Что изображено на рисунке?\",      \"attachments\": [        \"80e0bcd5-2b78-4fa7-8783-903995f56b4b\"      ]    }  ],  \"stream\": false,  \"update_interval\": 0}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\"payload = json.dumps({  \"model\": \"GigaChat-Pro\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Что изображено на рисунке?\",      \"attachments\": [        \"d41a9a52-1918-4c53-9158-df96986737ac\"      ]    }  ],  \"stream\": False,  \"update_interval\": 0})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer access_token\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Тарификация изображений\\ufeffПри отправке изображений в GigaChat они преобразуются в токены.\\nКоличество токенов после преобразования зависит от размера и разрешения изображения.\\nМаксимальное количество токенов, которые могут быть потрачены на обработку изображения — 1792.Токены оплачиваются в соответствии с тарифами GigaChat API.Смотрите также\\ufeffСоздание изображенийОписание запроса на генерациюРабота с функциямиМониторинг статистики потребления GigaChat API'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/certificates', 'title': 'Использование сертификатов НУЦ Минцифры в GigaChat | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/certificates', 'changefreq': 'weekly', 'priority': '0.5'}, page_content=\"Использование сертификатов НУЦ Минцифры в GigaChat | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Использование сертификатов НУЦ Минцифры в GigaChatОбновлено 12 сентября 2024TLS-сертификат был заменен на сертификаты НУЦ Минцифры. Чтобы обмен данными вашего приложения с сервисом GigaChat был и дальше возможен, установите публичный сертификат НУЦ Минцифры в качестве доверенного в коде приложения или на уровне операционной системы.Установка в коде приложения\\ufeffЧтобы установить публичный сертификат НУЦ Минцифры в качестве доверенного в коде приложения:Перейдите на портал Госуслуг и скачайте сертификат для вашей ОС.Укажите в коде вашего приложения путь к сертификату:для Python — опция командной строки --ca;для C++ — переменная окружения GRPC_DEFAULT_SSL_ROOTS_FILE_PATH.Пример установки сертификата в коде JavaScript:const path = require('path')process.env.NODE_EXTRA_CA_CERTS= path.resolve(__dirname, 'dir', 'with', 'certs')process.env.NODE_TLS_REJECT_UNAUTHORIZED = '0'Установка на уровне ОС\\ufeffОС Windows и MacOS\\ufeffПерейдите на портал Госуслуг, скачайте сертификат для вашей ОС и следуйте инструкциям по установке.ОС Linux\\ufeffПерейдите на портал Госуслуг и скачайте корневой и выпускающий сертификаты для Linux в формате .crt.Затем установите их на компьютер.Если вы скачали сертификаты по прямой ссылке в формате .pem, конвертируйте их с помощью команды:openssl x509 -outform der -in russiantrustedca.pem -out russiantrustedca.crtПримеры установки сертификатов в разных версиях Linux\\ufeffDebian и UbuntuRedHat Enterprise Linux 7Arch LinuxСоздайте папку для хранения сертификатов:sudo mkdir /usr/local/share/ca-certificates/russian-trustedСкопируйте сертификаты в созданную папку:sudo cp russian_trusted_root_ca_pem.crt russian_trusted_sub_ca_pem.crt /usr/local/share/ca-certificates/russian-trustedОбновите хранилища доверенных сертификатов от имени суперпользователя с помощью команды update-ca-certificates:sudo update-ca-certificates -vУбедитесь, что сертификаты установлены успешно с помощью команды trust list | grep Russian.В случае успеха, ответ должен быть примерно таким:label: Russian Trusted Root CAlabel: Russian Trusted Sub CAЗапустите в терминале команду конвертации:openssl x509 -outform der -in russiantrustedca.pem -out russiantrustedca.crtДобавьте сертификат в хранилище доверенных сертификатов. Для этого от имени суперпользователя запустите команду cp, скопируйте файл с сертификатом в директорию /etc/pki/ca-trust/source/anchors/:sudo cp <path>/russiantrustedca.crt /etc/pki/ca-trust/source/anchors/Для обновления хранилища доверенных сертификатов от имени суперпользователя запустите команду update-ca-trust:sudo update-ca-trustЗапустите в терминале команду конвертации:openssl x509 -outform der -in russiantrustedca.pem -out russiantrustedca.crtДобавьте сертификат в хранилище доверенных сертификатов. Для этого от имени суперпользователя запустите команду cp, скопируйте файл с сертификатом в директорию /etc/ca-certificates/trust-source/anchors/:sudo cp <path>/russiantrustedca.crt /etc/ca-certificates/trust-source/anchors/Для обновления хранилища доверенных сертификатов от имени суперпользователя запустите команду update-ca-trust:sudo update-ca-trustКвоты и ограниченияОбучающие материалы\"),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/changelog/latest', 'title': 'История обновлений | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/changelog/latest', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='История обновлений | Документация для разработчиковИстория обновлений2024\\ufeffНоябрь\\ufeff14.11.2024\\ufeffДобавили возможность загружать текстовые файлы и использовать их при генерации ответов.01.11.2024\\ufeffДобавили описание метода GET /balance. Используйте его, чтобы узнать сколько токенов у вас осталось. Метод не работает, если вы оплачиваете работу с API по схеме pay-as-you-go.Описали ошибку 403, которую может вернуть метод GET /balance.Добавили Postman-коллекцию для работы с gRPC и рассказали, что нужно для начала работы с ней.Октябрь\\ufeff31.10.2024\\ufeffМодель GigaChat Max, а также новые версии моделей GigaChat и GigaChat Pro запущены в режиме раннего доступа.29.10.2024\\ufeffРассказали как работать с новым инструментом отладки промптов.25.10.2024\\ufeffДобавили возможнолсть кэшировать запросы к GigaChat.23.10.2024\\ufeffОписали ошибку 422 REST API GigaChat.Описали ответ модели, который возвращается при генерации невалидных аргументов пользовательской функции.02.10.2024\\ufeffТеперь при запросах на генерацию можно использовать загруженные изображения.Добавлены новые методы для загрузки изображений в хранилище:POST /files;GET /files;GET /files/{file};GET /files/{file}/delete.Сентябрь\\ufeff27.09.2024\\ufeffДобавлено описание ошибок REST API GigaChat.12.09.2024\\ufeffВ разделы Обучающие видео GigaChat API и GigaChain добавлены новые видеоуроки от Сергея Тращенкова.Август\\ufeff09.08.2024\\ufeffДобавлены примеры описания составных функций.Июль\\ufeff30.07.2024\\ufeffДобавлена возможность отправлять запросы к новым версиям моделей, которые находятся в раннем доступе. Ранний доступ позволяет самостоятельно убедиться в повышенной производительности и ознакомиться с новыми возможностями моделей.Для сохранения контекста при работе с функциями добавлено новое поле functions_state_id. В будущем поле functions_state_id заменит массив data_for_context.25.07.2024\\ufeffДобавлена возможность использовать GigaChat API по предоплатной схеме. Для этого нужно создать Корпоративное пространство с поддержкой работы по предоплате. Для тарификации по предоплатной схеме запросы нужно отправлять к соответствующей версии API scope=GIGACHAT_API_B2B. Подробнее — в быстром старте для ИП и юрлиц.05.07.2024\\ufeffПараметр n (количество вариантов ответов модели) отмечен как deprecated. После отключения параметра все модели будут возвращать только один вариант ответа.01.07.2024\\ufeffДобавлены образцы описания функцийМай\\ufeff22.05.2024\\ufeffТеперь во все модели добавлена поддержка функций, поэтому обновлена документация по созданию изображений — оставлено описание создания изображения только с помощью встроенной функции.Март\\ufeff27.03.2024\\ufeffДобавлена возможность работать со встроенными и собственными функциями.25.03.2024\\ufeffПереработан раздел с примерами промптов. Добавлена новая разводящая страница с фильтрацией промптов по категориям.22.03.2024\\ufeffОпубликована английская версия документации GigaChain. 19.03.2024\\ufeffДобавлено описание мониторинга потребления токенов, доступное для ИП и юридических лиц.Февраль\\ufeff14.02.2024\\ufeffОписан выбор моделей с помощью API и SDK.9.02.2024\\ufeffДобавлены разделы Быстрый старт для физлиц и Быстрый старт для ИП и юрлиц.Описана возможность отключать цензора при работе с версией API для ИП и юридических лиц.7.02.2024\\ufeffДобавлены промпты для обработки текстов и генерации:перевод;стилизация;генерация таблиц;генерация описания товаров;суммаризация.6.02.2024\\ufeffОписаны доступные модели GigaChat.Январь\\ufeff19.01.2024\\ufeffОбновили структуру документации.Обновили дизайн и функциональность справки REST API GigaChat. В новой документации появилась возможность отправлять запросы к API.15.01.2024\\ufeffGigaChat научился создавать векторное представление текста (эмбеддинги). О работе с эмбеддингами с помощью GigaChat API и GigaChain — в разделе Векторное представление текста.Добавлена возможность создавать изображения с помощью GigaChat API.12.01.2024\\ufeffОпубликован каталог промптов.2023\\ufeffДекабрь\\ufeff22.12.2023\\ufeffОпубликована документация GigaServe — python-библиотеки, которая позволяет размещать цепочки и runnable-интерфейсы GigaChain и предоставлять к ним доступ через REST API.04.12.2023\\ufeffТеперь для доступа к GigaChat вы можете использовать не только REST API, но и GRPC.Сентябрь\\ufeff20.09.2023\\ufeffТеперь для работы с GigaChat вы можете использовать REST API и SDK GigaChain.\\nДля работы с API вы можете использовать специально подготовленную коллекцию запросов Postman.Обучающие материалы'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/individuals-quickstart', 'title': 'Быстрый старт для физических лиц | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/individuals-quickstart', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Быстрый старт для физических лиц | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Быстрый старт для физических лицОбновлено 30 сентября 2024Следуйте инструкциям в этом разделе, чтобы узнать как:Зарегистрироваться в личном кабинете и создать проект GigaChat API, который нужен для управления доступом к API и просмотру статистики.Покупать токены для оплаты запросов к API.Делать простые запросы к API с помощью разных инструментов.Для работы с GigaChat API установите сертификаты НУЦ Минцифры.Возможности GigaChatРегистрация в личном кабинете'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/legal-quickstart', 'title': 'Быстрый старт для ИП и юридических лиц | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/legal-quickstart', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Быстрый старт для ИП и юридических лиц | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Быстрый старт для ИП и юридических лицОбновлено 30 сентября 2024Следуйте инструкциям в этом разделе, чтобы узнать как:Зарегистрироваться в личном кабинете для покупки токенов и получения ключа авторизации.Делать простые запросы к API с помощью разных инструментов.Для работы с GigaChat API установите сертификаты НУЦ Минцифры.Начало работы с APIРегистрация и покупка токенов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/limitations', 'title': 'Квоты и ограничения | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/limitations', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Квоты и ограничения | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Квоты и ограниченияОбновлено 27 февраля 2024Квотирование\\ufeffТокены\\ufeffОбмен данными с GigaChat ограничен количеством доступных токенов.\\nВ среднем один токен состоит из 3—4 символов.\\nКоличество токенов в промпте с контекстом и ответе зависит от модели.\\nОценить количество токенов, которое потратит та или иная модель, можно с помощью запроса POST /tokens/countПотоки\\ufeffПри работе с GigaChat API действуют ограничения на потоки:Физическим лицам для работы с API доступен один поток, независимо от того используются токены из платного пакета или freemium-режима.Юридическим лицам и ИП для работы с API по умолчанию доступно 10 потоков. Количество потоков может быть увеличено после отправки запроса на электронный адрес gigachat@sberbank.ru.Тематические ограничения запросов\\ufeffС нейросетевой моделью вы можете обсуждать любые темы, кроме тех, которые призывают к противозаконным действиям или потенциально опасной деятельности, а также нарушают требования законодательства.\\nЕсли запрос подпадает под ограничения GigaChat, то ответ будет содержать поле \"choices.finish_reason\": \"blacklist\".Корпоративным клиентам доступна возможность настройки ограничений.\\nНапишите письмо по адресу gigachat@sberbank.ru, чтобы узнать более подробную информацию о настройке ограничений.Всегда проверяйте ответы GigaChat. В связи с тем, что ответы генерируются нейросетью, информация в них может быть неактуальна или искажена.Темы, которых необходимо избегать:порнография, эротика и темы сексуального характера;пропаганда употребления алкогольных, наркотических и табачных веществ;политика, предвыборная агитация и обсуждение представителей власти;темы экстремистского и террористического характера;призывы к насилию, убийствам и самоубийствам;призывы к жестокому обращению с животными;призывы к нарушению законов (разжиганию военных конфликтов, пропаганде криминальных структур);изготовление наркотических веществ и их аналогов, взрывчатых веществ и иного оружия.Результат генерации не является официальным мнением компании, модель постоянно дообучается, в том числе в вопросах этики.Тарифы GigaChat APIИспользование сертификатов НУЦ Минцифры в GigaChat'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/models', 'title': 'Модели GigaChat | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/models', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Модели GigaChat | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Модели GigaChatОбновлено 19 ноября 2024Сервис GigaChat дает доступ к нескольким моделям для генерации и одной модели для создания векторного представления текста.В зависимости от задач вы можете использовать разные модели.\\nПри этом стоимость запросов будет отличаться.\\nИнформацию о тарифах, а также примеры расчетов ищите в разделе Тарифы и оплата.Перед запуском в промышленном контуре новые версии моделей для генерации некоторое время работают в режиме раннего доступа.Модели для генерации\\ufeffДля получения списка моделей, доступных для генерации, используйте запрос GET /models.Для генерации доступны модели:Название моделиЗначение поля modelРазмер контекстав токенахПоддержкафункцийОписаниеGigaChat LiteGigaChat32768даЛегкая модель для простых задач, требующихмаксимальной\\xa0скорости\\xa0работыGigaChat ProGigaChat-Pro32768даПродвинутая\\xa0модель\\xa0для\\xa0сложных\\xa0задач,\\xa0требующихкреативности\\xa0и\\xa0лучшего\\xa0следования\\xa0инструкциямGigaChat MaxGigaChat-Max32768даПродвинутая модель для сложных задач,требующих высокого уровня креативности и качества работыЧтобы получить ответ определенной модели, ее название нужно передать в поле model запроса POST /chat/completions:curl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"system\",      \"content\": \"Ты профессиональный переводчик на английский язык. Переведи точно сообщение пользователя.\"    },    {      \"role\": \"user\",      \"content\": \"GigaChat — это сервис, который умеет взаимодействовать с пользователем в формате диалога, писать код, создавать тексты и картинки по запросу пользователя.\"    }  ],  \"stream\": false,  \"update_interval\": 0}\\'Модель для векторного представления текста\\ufeffДля векторного представления текстов доступна модель Embeddings:Название моделиЗначение поля modelОписаниеEmbeddingsEmbeddingsБазовая модель, доступная по умолчанию для векторного представления текстовМодель используется в запросах на создание эмбеддингов POST /embeddings:{  \"model\": \"Embeddings\",  \"input\": [    \"Расскажи о современных технологиях\"  ]}Смотрите также\\ufeffВыбор модели для генерацииВекторное представление текстовЗапрос на генерациюТарифы и оплатаГенератор медитацийРанний доступ к моделям'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/models/preview-models', 'title': 'Ранний доступ к моделям | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/models/preview-models', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Ранний доступ к моделям | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Ранний доступ к моделямОбновлено 4 октября 2024Модели для генерации GigaChat регулярно обновляются и у них появляются новые возможности, например, вызов функций.\\nВ таких случаях новые версии моделей некоторое время доступны в раннем доступе.Полный список моделей в раннем доступе, можно получить с помощью запроса GET /models по адресу https://gigachat-preview.devices.sberbank.ru/:curl -L -X GET \\'https://gigachat-preview.devices.sberbank.ru/api/v1/models\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\'Для обращения к таким моделям используйте адрес https://gigachat-preview.devices.sberbank.ru/, а к названию модели, которое передается в поле model, добавьте постфикс -preview.Например, запрос на генерацию будет выглядеть следующим образом:curl -L -X POST \\'https://gigachat-preview.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat-Pro-preview\",  \"messages\": [    {      \"role\": \"system\",      \"content\": \"Ты профессиональный переводчик на английский язык. Переведи точно сообщение пользователя.\"    },    {      \"role\": \"user\",      \"content\": \"GigaChat — это сервис, который умеет взаимодействовать с пользователем в формате диалога, писать код, создавать тексты и картинки по запросу пользователя.\"    }  ],  \"stream\": false,  \"update_interval\": 0}\\'После запуска обновленных моделей в промышленном контуре, все модели начинают вести себя одинаково, независимо от того по какому адресу вы передаете запросы.Модели GigaChatОбновления моделей'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/models/updates', 'title': 'Обновления моделей | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/models/updates', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Обновления моделей | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Обновления моделейОбновлено 18 ноября 2024В этом разделе вы найдете информацию о качестве работы и возможностях новых версий моделей GigaChat.Качество работы каждой новой версии модели проверяется с помощью нескольких бенчмарков:MMLU (Multimodal Language Understanding) и его русскоязычная версия ruMMLU. Метрика MMLU оценивает общие способности моделей понимать и отвечать на вопросы из различных областей знаний.GSM8K — метрика, которая позволяет оценить знания LLM на уровне школьной математики.MATH — метрика, которая представляет более широкий набор задач, в том числе по алгебре, геометрии и даже математическому анализу – вплоть до университетского уровня.  MT-Bench — метрика из 160 вопросов для оценки генеративных способностей LLM, включая фактологию, способность следовать инструкциям, поддерживать диалог с контекстом, использовать форматирование и решать иные задачи. В качестве судьи используется сильная LLM (gpt-4o), которая оценивает качество ответов по шкале от 0 до 10.Arena-Hard - бенчмарк также оценивающий генеративные способности LLM в диалогах. Содержит 500 вопросов в основном по техническим тематикам, включая математику и программирование. Особенностью оценки является ELO-рейтинг, который формируется на основе сравнения ответа оцениваемой моделей с базовой (gpt-4). Судья (gpt-4o) в таком случае не проставляет оценку от 0 до 10, а выбирает ответ какой модели лучше - базовой или оцениваемой. На основе таких сравнений рассчитывается итоговый рейтинг оцениваемой модели.Human Eval — метрика используется для оценки способности моделей производить результаты, которые соответствуют человеческому восприятию.Версия: 26.20 Дата релиза: 31.10.2024 Статус: ДоступнаВ версии 26.20 добавлена новая модель GigaChat Max.Для запросов к модели используйте адрес https://gigachat-preview.devices.sberbank.ru/api/v1/, а в поле model передавайте GigaChat-Max-preview.\\nДля работы с моделью нужны оплаченные токены.В таблице представлены основные характеристики и возможности новой версии моделей.ХарактеристикиGigaChat LiteGigaChat ProGigaChat MaxРазмер контекста в токенах32K32K32KПоддержка функций✅✅✅Генерация изображений✅✅✅Обработка изображений❌✅✅В таблице представлены результаты проверки моделей с помощью разных бенчмарков.МетрикаGigaChat LiteGigaChat ProGigaChat MaxMMLU (5-shot)0.650.690.8ruMMLU (5-shot)0.60.650.75GSM8K (5-shot)0.660.780.93MATH (4-shot)0.340.450.53MT-Bench (average)(с\\xa0фильтром\\xa0безопасности)7.17.458.2MT-Bench (average)(без\\xa0фильтра\\xa0безопасности)6.937.598.3Arena-Hard EN(с\\xa0фильтром\\xa0безопасности)50.7Arena-Hard EN(без\\xa0фильтра\\xa0безопасности)11.018.051.9Arena-Hard RU(с\\xa0фильтром\\xa0безопасности)70.7Arena-Hard RU(без\\xa0фильтра\\xa0безопасности)25.945.573.3Human Eval (0-shot)0.370.440.64Версия: 26.15 Дата релиза: 01.10.2024 Статус: ДоступнаВ версии 26.15:Теперь в запросах к модели GigaChat Pro можно передавать изображения.В моделях GigaChat Lite и Pro увеличен размер контекста с 8192 до 32768 токенов.Расширены возможности по стилизации и форматированию ответов. Теперь модели активнее используют markdown-разметку: добавляют заголовки, списки, параграфы и блоки кода.В таблице представлены основные характеристики и возможности новой версии моделей.ХарактеристикиGigaChat LiteGigaChat ProРазмер контекста в токенах32K32KПоддержка функций✅✅Генерация изображений✅✅Обработка изображений❌✅В таблице представлены результаты проверки моделей с помощью разных бенчмарков.МетрикаGigaChat LiteGigaChat ProMMLU (5-shot)0.640.69ruMMLU (5-shot)0.590.62GSM8K (5-shot)0.610.77MATH (4-shot)0.270.31MT-Bench (average)7.217.7Arena-Hard EN16.621.4Arena-Hard RU20.228.2Human Eval (0-shot)0.380.4Ранний доступ к моделямТарифы GigaChat API'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/playground', 'title': 'Работа в песочнице промптов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/playground', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Работа в песочнице промптов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Работа в песочнице промптовОбновлено 7 ноября 2024В личном кабинете Studio вы можете проверить, как ваши промпты работают с различными моделями и их параметрами.\\nЭто позволит отладить промпт перед его использованием в приложении.Для отладки промптов используйте песочницу (раздел Playground), доступную в личном кабинете.\\nЧтобы открыть песочницу:Авторизуйтесь в Studio.Откройте проект GigaChat API.В левой панели выберите раздел Playground.Откроется интерфейс песочницы.При работе с промптами в разделе Playground расходуются ваши токены.Подготовка промпта\\ufeffЧтобы подготовить промпт:Нажмите кнопку Создать и укажите название промпта в поле Новый промптПонятное название поможет быстро найти промпт среди сохраненных в вашей библиотеке.Укажите системный промпт. Для этого:Нажмите Задайте системные инструкции.В открывшемся поле укажите системный промпт.Нажмите Сохранить.Системный промпт — описание поведения модели, которое она будет придерживаться при генерации ответов. Например, «Ты профессиональный переводчик на английский язык. Переведи точно сообщение пользователя.»Если нужно отправьте несколько сообщений с разными ролями с помощью кнопки +. Модель будет учитывать предварительно переданные сообщения при генерации ответа.Добавить несколько сообщений можно только до запуска диалога.Настройка среды\\ufeffВ разделе Настройки вы можете подготовить среду, в которой должен работать промпт.Для этого:В блоке Основные, в раскрывающемся списке Стенд выберите версию стенда, к которому будут выполняться запросы.На выбор доступны два вида стендов:Основной. При выборе этого стенда запросы будут передаваться в актуальные версии моделей.Ранний доступ. При выборе этого стенда запросы будут передаваться в версии моделей, которые работают в режиме раннего доступа.В блоке Основные, в раскрывающемся списке Модель выберите модель, которая будет обрабатывать запросы.Список моделей отличается в зависимости от выбранного стенда.Подробное описание моделей — в разделе Модели GigaChat.В блоке Дополнительные задайте параметры выбранной модели.В процессе настройки вы можете:изменить температуру;Чем выше значение температуры, тем более случайным будет ответ модели.\\nПри значении больше двух, набор токенов в ответе модели может отличаться избыточной случайностью.Значение по умолчанию зависит от выбранной модели и может изменяться с обновлениями модели.ограничить максимальное число токенов в ответе модели;отключить фильтр безопасности. Отключение фильтра позволит проверять запросы, которые содержат тематические ограничения. Использовать параметры могут только юридические лица. Более подробную информацию вы можете получить по почте.Чтобы вернуть настройки по умолчанию нажмите Сбросить.После запуска проверка промпта вы можете посмотреть расход токенов на отправленные сообщения и системный промпт.\\nДля этого в блоке Основные нажмите кнопку Обновить рядом с полем Токены.Проверка промпта\\ufeffПосле создания промпта и подготовки среды, напишите сообщение для модели и нажмите Отправить и запустить (или  Запустить, если вы подготовили историю сообщений при создании промпта).После запуска модель вернет результат генерации с учетом системного промпта и переданной истории сообщений.Если результат работы промпта вас устроил, вы можете сохранить его в библиотеке и просмотреть код запроса с промптом на одном из доступных языков: JavaScript, Python, Kotlin и Swift.Вы можете в любой момент менять любые сообщения в диалоге с моделью.\\nДля этого выберите сообщение, которое нужно изменить, нажмите кнопку Редактировать и укажите нужный текст.Создание промптовПримеры промптов для API и SDK'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompt-design', 'title': 'Создание промптов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompt-design', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Создание промптов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Создание промптовОбновлено 23 мая 2024GigaChat решает самые разные задачи: от обработки текстов и создания изображений, до написания кода на разных языках. Точность ответа сервиса напрямую зависит от точности запроса пользователя — промпта. Промпты (от англ. prompt — «подсказка») имеют вид вопросов, текстовых заданий или инструкций, которые описывают какой именно результат ожидается от модели. Промпты могут быть и простыми репликами, и детальными указаниями с примерами ожидаемых результатов.Пройдите курс, чтобы научиться составлять наиболее эффективные промпты.Вы также можете использовать базу знаний, чтобы изучить подробное руководство по работе с промптами и ознакомиться с тематическими примерами.Способы улучшения промптов\\ufeffИз-за архитектурных особенностей нейросетевые модели создают ответы, которые не точно удовлетворяют запросы, а только с наибольшей вероятностью. Создавайте промпты с учетом приведенных рекомендаций и вы значительно повысите вероятность получить подходящий ответ.Детализация указаний\\ufeffЧем более подробную инструкцию вы дадите сервису, тем выше вероятность получить ожидаемый результат. Убедитесь в этом на примере арифметической задачи.В силу архитектурных особенностей модели часто плохо разбираются в математике.Так, если вы попросите GigaChat умножить 10 на 10, он скорее всего даст неверный ответ.Промпт:10*10? Ответ GigaChat:10Предоставьте модели больше данных о том, как решить задачу и вы с большей вероятностью получите удовлетворительный результат.Промпт:Используй десятичную систему исчисления.Убедись, что ответ математически верен.10*10 Ответ GigaChat:10 × 10 = 100Присвоение роли\\ufeffЕсли вы хотите изменить стиль или формулировку ответов сервиса, то добавьте в промпт ролевую модель. Так, ответы модели с ролью академика и пятилетнего ребенка будут заметно отличаться. Роли помогут модели вести разговор в заданном ключе или получить ответ, предназначенный для определенной аудитории.Промпт:Ты кандидат физикоматематических наук. Расскажи первый закон термодинамики своими словами Ответ GigaChat:Первый закон термодинамики утверждает, что энергия не может быть создана или уничтожена, она может только переходить из одной формы в другую. Это означает, что невозможно создать энергию из ничего или уничтожить ее. Промпт:Ты первоклассник. Расскажи первый закон термодинамики своими словами Ответ GigaChat:Первый закон термодинамики говорит о том, что теплота не может быть создана или уничтожена, она может только переходить от одного тела к другому. Это означает, что тепло всегда передается от более теплого тела к менее теплому.Примеры в промпте\\ufeffПримеры показывают модели, какой результат вы ожидаете.Промпт без примера ответа: Какой город является столицей России?Ответ GigaChat: Столицей России является МоскваПромпт с примерами ответов: Какой город является столицей России?МоскваКакой город является столицей Венгрии?Будапешт Какой город является столицей Пакистана?Ответ GigaChat:Исламаба́дСтруктурированный промпт\\ufeffИспользуйте советы по улучшению ответов модели и вместе, и по отдельности.В общем случае промпт, который использует сразу все советы, будет выглядеть так:Смотрите также\\ufeffПримеры удачных промптов для GigaChatКак формулировать запросы к GigaChatОписание ошибокРабота в песочнице промптов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/product-description', 'title': 'Генерация описания товаров | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/product-description', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация описания товаров | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация описания товаровОбновлено 14 ноября 2024Пример промпта для генерации рекламного описания товара для размещения в интернет-магазине.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты — профессиональный маркетолог с опытом написания высококонверсионной рекламы. Для генерации описания товара ты изучаешь потенциальную целевую аудиторию и оптимизируешь рекламный текст так, чтобы он обращался именно к этой целевой аудитории. Создай текст объявления с привлекающим внимание заголовком и убедительным призывом к действию, который побуждает пользователей к целевому действию.\"        },        {            \"role\": \"user\",            \"content\": \"Название товара: SberBoom. Категория: умные колонки. Ключевые слова: умная колонка, салют, умный дом.\"        }    ]}Промпт работает с помощью библиотеки gigachain_core, начиная с версии 0.1.9.1.Для обновления библиотеки выполните команду:pip install -U gigachain_coreinput_variables: [product_name, category, key_words]output_parser: nullmessages:  - role: system    prompt:      template: \\'Ты — профессиональный маркетолог с опытом написания высококонверсионной рекламы.        Для генерации описания товара ты изучаешь потенциальную целевую аудиторию и оптимизируешь рекламный текст так, чтобы он обращался именно к этой целевой аудитории.        Создай текст объявления с привлекающим внимание заголовком и убедительным призывом к действию, который побуждает пользователей к целевому действию.\\'  - role: user    prompt:      template: \\'Название товара: {product_name}. Категория: {category}. Ключевые слова: {key_words}.\\'template_format: f-string_type: chatШаблон содержит переменные:product_name — название товара. Обязательное поле;category — категория, к которой относится товар. Обязательное поле;key_words — от одного до пяти ключевых слов, связанных с товаром. Необязательное поле.Пример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",  \"temperature\": 1.0,  \"top_p\": 0.1,  \"n\": 1,  \"max_tokens\": 512,  \"repetition_penalty\": 1.0,  \"stream\": false,  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты — профессиональный маркетолог с опытом написания высококонверсионной рекламы. Для генерации описания товара ты изучаешь потенциальную целевую аудиторию и оптимизируешь рекламный текст так, чтобы он обращался именно к этой целевой аудитории. Создай текст объявления с привлекающим внимание заголовком и убедительным призывом к действию, который побуждает пользователей к целевому действию.\"        },        {            \"role\": \"user\", // запрос пользователя            \"content\": \"Название товара: SberBoom. Категория: умные колонки. Ключевые слова: умная колонка, салют, умный дом.\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")prompt = load_from_giga_hub(\"lc://prompts/content/product_description.yaml\")chain = prompt | gigachain.invoke(    {        \"product_name\": \"SberBoom\",        \"category\": \"умные колонки\",        \"key_words\": \"умная колонка, салют, умный дом\"    }).contentСтилизация текстаГенерация таблиц'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/spelling-correction', 'title': 'Исправление ошибок | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/spelling-correction', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Исправление ошибок | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Исправление ошибокОбновлено 14 ноября 2024Пример промпта для исправления ошибок в тексте.В демонстрационных целях пример сообщения пользователя (\"role\": \"user\") специально содержит ошибки.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Перепиши текст, исправив грамматические, орфографические и пунктуационные ошибки в тексте.\"        },        {            \"role\": \"user\",            \"content\": \"искуственый - интилектможет исправить все ошибки в даном тексте вне зависимости от длинны\"        },    ],  \"temperature\": 0.7}input_variables: [text]output_parser: nulltemplate: \\'Перепиши текст, исправив грамматические, орфографические и пунктуационные ошибки в тексте.Текст:{text}\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 1.0,   \"top_p\": 0.1,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.0,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Перепиши текст, исправив грамматические, орфографические и пунктуационные ошибки в тексте.\"        },        {            \"role\": \"user\",            \"content\": \"искуственый - интилектможет исправить все ошибки в даном тексте вне зависимости от длинны\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")prompt = load_from_giga_hub(\\'lc://prompts/content/spell_correction.yaml\\')chain = prompt | gigatext = chain.invoke({\"text\": \"искуственый - интилектможет исправить все ошибки в даном тексте вне зависимости от длинны\"})Jupyter-блокнот с шаблоном промпта для исправления текстаПеревод текстаСтилизация текста'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/table-generation', 'title': 'Генерация таблиц | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/table-generation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация таблиц | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация таблицОбновлено 14 ноября 2024Пример промпта для генерации таблиц.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat-Pro\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Заполни таблицу в формате markdown с указанными названиями строк или столбцов на основе сообщения пользователя.\"        },        {            \"role\": \"user\",            \"content\": \"Столбцы: Предмет мебели, Краткое описание. В обычной квартире могут быть представлены самые разные предметы мебели. Например столы, стулья или кресла. Стол — предмет мебели, имеющий приподнятую горизонтальную или наклонную поверхность и предназначенный для размещения предметов, выполнения работ, принятия пищи, игр, рисования, обучения и другой деятельности. Стул — предмет мебели для сидения одного человека, с опорой для спины с подлокотниками или без них. Кресло — предмет мебели для комфортного продолжительного сидения, со спинкой, c подлокотниками или без них.\"        }    ]}Промпт работает с помощью библиотеки gigachain_core, начиная с версии 0.1.9.1.Для обновления библиотеки выполните команду:pip install -U gigachain_coreinput_variables: [text]output_parser: nullmessages:  - role: system    prompt:      template: \\'Заполни таблицу в формате markdown с указанными названиями строк или столбцов на основе сообщения пользователя.\\'  - role: user    prompt:      template: \\'{text}\\'template_format: f-string_type: chatШаблон содержит переменные:text — текст обращения пользователя. Обязательное поле;Пример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat-Pro\",  \"temperature\": 1.0,  \"top_p\": 0.1,  \"n\": 1,  \"max_tokens\": 1000,  \"repetition_penalty\": 1.0,  \"stream\": false,  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Создай таблицу в формате markdown с указанными названиями столбцов и строк на основе текста сообщения пользователя. Количество строк и столбцов должно !строго соответствовать заданному в сообщении. Оформление таблицы должно быть консистентным.\"        },        {            \"role\": \"user\",            \"content\": \"Столбцы: Предмет мебели, Краткое описание. В обычной квартире могут быть представлены самые разные предметы мебели. Например столы, стулья или кресла. Стол — предмет мебели, имеющий приподнятую горизонтальную или наклонную поверхность и предназначенный для размещения предметов, выполнения работ, принятия пищи, игр, рисования, обучения и другой деятельности. Стул — предмет мебели для сидения одного человека, с опорой для спины с подлокотниками или без них. Кресло — предмет мебели для комфортного продолжительного сидения, со спинкой, c подлокотниками или без них.\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\", model=\"GigaChat-Pro\")prompt = load_from_giga_hub(\"lc://prompts/content/table_generation.yaml\")chain = prompt | gigachain.invoke(    {        \"text\": \"Столбцы: Предмет мебели, Краткое описание. В обычной квартире могут быть представлены самые разные предметы мебели. Например столы, стулья или кресла. Стол — предмет мебели, имеющий приподнятую горизонтальную или наклонную поверхность и предназначенный для размещения предметов, выполнения работ, принятия пищи, игр, рисования, обучения и другой деятельности. Стул — предмет мебели для сидения одного человека, с опорой для спины с подлокотниками или без них. Кресло — предмет мебели для комфортного продолжительного сидения, со спинкой, c подлокотниками или без них.\"    }).contentГенерация описания товаровКлассификация обращений'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/text-rewrite', 'title': 'Стилизация текста | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/text-rewrite', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Стилизация текста | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Стилизация текстаОбновлено 14 ноября 2024Пример промпта для переписывания текста с учетом заданного стиля.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты — опытный копирайтер. Перепиши маркетинговый текст с учетом вида текста и выбранного стиля.\"        },        {            \"role\": \"user\",            \"content\": \"Перепиши текст как научную статью. Текст: Благодаря новой LLM GigaChat лучше следует инструкциям и может выполнять более сложные задания: улучшилось качество суммаризации, рерайтинга и редактирования текстов, а ответы на вопросы стали точнее.\\\\nПо результатам тестов новый GigaChat уже превзошел схожие по количеству параметров иностранные аналоги в бенчмарке MMLU.\\\\nДостичь таких результатов получилось за счет множества экспериментов по улучшению модели и повышению эффективности ее обучения. В частности, команда использовала фреймворк для обучения больших языковых моделей с возможностью шардирования весов нейросети по видеокартам, что позволило сократить потребление памяти на них.\\\\nВ числе первых доступ к API новинки получат бизнес-клиенты Сбера и участники академического сообщества.\"        }    ]}Промпт работает с помощью библиотеки gigachain_core, начиная с версии 0.1.9.1.Для обновления библиотеки выполните команду:pip install -U gigachain_coreinput_variables: [text, style]output_parser: nullmessages:  - role: system    prompt:      template: \\'Ты — опытный копирайтер. Перепиши маркетинговый текст с учетом вида текста и выбранного стиля.\\'  - role: user    prompt:      template: \\'Текст: {text}. Стиль: {style}.\\'template_format: f-string_type: chatШаблон содержит переменные:text — текст, который нужно переписать. Обязательное поле;style — стиль итогового текста. Обязательное поле.Пример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",  \"temperature\": 1.0,  \"top_p\": 0.1,  \"n\": 1,  \"max_tokens\": 512,  \"repetition_penalty\": 1.0,  \"stream\": false,  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты — опытный копирайтер. Перепиши маркетинговый текст с учетом вида текста и выбранного стиля.\"        },        {            \"role\": \"user\",            \"content\": \"Перепиши текст как научную статью. Текст: Благодаря новой LLM GigaChat лучше следует инструкциям и может выполнять более сложные задания: улучшилось качество суммаризации, рерайтинга и редактирования текстов, а ответы на вопросы стали точнее.\\\\nПо результатам тестов новый GigaChat уже превзошел схожие по количеству параметров иностранные аналоги в бенчмарке MMLU.\\\\nДостичь таких результатов получилось за счет множества экспериментов по улучшению модели и повышению эффективности ее обучения. В частности, команда использовала фреймворк для обучения больших языковых моделей с возможностью шардирования весов нейросети по видеокартам, что позволило сократить потребление памяти на них.\\\\nВ числе первых доступ к API новинки получат бизнес-клиенты Сбера и участники академического сообщества.\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")prompt = load_from_giga_hub(\"lc://prompts/content/text_rewrite.yaml\")chain = prompt | gigachain.invoke(    {        \"text\": \"Благодаря новой LLM GigaChat лучше следует инструкциям и может выполнять более сложные задания: улучшилось качество суммаризации, рерайтинга и редактирования текстов, а ответы на вопросы стали точнее.\\\\nПо результатам тестов новый GigaChat уже превзошел схожие по количеству параметров иностранные аналоги в бенчмарке MMLU.\\\\nДостичь таких результатов получилось за счет множества экспериментов по улучшению модели и повышению эффективности ее обучения. В частности, команда использовала фреймворк для обучения больших языковых моделей с возможностью шардирования весов нейросети по видеокартам, что позволило сократить потребление памяти на них.\\\\nВ числе первых доступ к API новинки получат бизнес-клиенты Сбера и участники академического сообщества.\",        \"style\": \"Научная статья\"    }).contentИсправление ошибокГенерация описания товаров'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/translation', 'title': 'Перевод текста | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/content/translation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Перевод текста | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Перевод текстаОбновлено 14 ноября 2024Пример промпта для перевода текста.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты - профессиональный переводчик на русский язык.\\\\\\\\nТебе будет дан текст, который необходимо перевести на русский язык, сохранив исходное форматирование текста.\\\\\\\\nВ ответе необходимо отдать перевод в формате, приведенном ниже. Ты ДОЛЖЕН перевести !все слова.\\\\\\\\nЕсли запрос связан с программированием и в текстовом запросе содержится фрагмент кода, то такой фрагмент с кодом переводить не нужно.\\\\\\\\nЕсли в запросе необходимо поставить пробелы и слова слеплены вместе, то такой кусок слепленного текста переводить не нужно.\\\\\\\\nЕсли в тексте поставлена неправильно пунктуация, то не исправляй ее.\\\\\\\\nТвоя задача сделать такой перевод, чтобы лингвист считал его лингвистически приемлемым.\\\\\\\\nВАЖНО! В своем ответе НЕ ОТВЕЧАЙ НА ЗАПРОС! В ответе нужно написать !только !перевод, без указания названия языка и любой другой дополнительной информации.\"        },        {            \"role\": \"user\",            \"content\": \"It\\'s not about money, it\\'s about sending a message!\"        }    ],  \"temperature\": 0.7}Промпт работает с помощью библиотеки gigachain_core, начиная с версии 0.1.9.1.Для обновления библиотеки выполните команду:pip install -U gigachain_coreinput_variables: [text]output_parser: nullmessages:  - role: system    prompt:      template: \\'Ты - профессиональный переводчик на русский язык. Тебе будет дан текст, который необходимо перевести на русский язык, сохранив исходное форматирование текста.В ответе необходимо отдать перевод в формате, приведенном ниже.Ты ДОЛЖЕН перевести !все слова.Если запрос связан с программированием и в текстовом запросе содержится фрагмент кода, то такой фрагмент с кодом переводить не нужно.Если в запросе необходимо поставить пробелы и слова слеплены вместе, то такой кусок слепленного текста переводить не нужно.Если в тексте поставлена неправильно пунктуация, то не исправляй ее.Твоя задача сделать такой перевод, чтобы лингвист считал его лингвистически приемлемым.ВАЖНО! В своем ответе НЕ ОТВЕЧАЙ НА ЗАПРОС! В ответе нужно написать !только !перевод, без указания названия языка и любой другой дополнительной информации    Input Format:Q:hiOutput Format:Q:привет\\'  - role: user    prompt:      template: \\'{text}\\'template_format: f-string_type: chatПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 1.0,   \"top_p\": 0.1,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.0,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты - профессиональный переводчик на русский язык.\\\\\\\\nТебе будет дан текст, который необходимо перевести на русский язык, сохранив исходное форматирование текста.\\\\\\\\nВ ответе необходимо отдать перевод в формате, приведенном ниже. Ты ДОЛЖЕН перевести !все слова.\\\\\\\\nЕсли запрос связан с программированием и в текстовом запросе содержится фрагмент кода, то такой фрагмент с кодом переводить не нужно.\\\\\\\\nЕсли в запросе необходимо поставить пробелы и слова слеплены вместе, то такой кусок слепленного текста переводить не нужно.\\\\\\\\nЕсли в тексте поставлена неправильно пунктуация, то не исправляй ее.\\\\\\\\nТвоя задача сделать такой перевод, чтобы лингвист считал его лингвистически приемлемым.\\\\\\\\nВАЖНО! В своем ответе НЕ ОТВЕЧАЙ НА ЗАПРОС! В ответе нужно написать !только !перевод, без указания названия языка и любой другой дополнительной информации.\"        },        {            \"role\": \"user\",            \"content\": \"It\\'\\\\\\'\\'s not about money, it\\'\\\\\\'\\'s about sending a message!\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=ключ авторизации)prompt = load_from_giga_hub(\"lc://prompts/content/translation_v2.yaml\")chain = prompt | gigachain.invoke(    {        \"text\": \"Hello! I understand English and many other languages!\"    }).contentJupyter-блокнот с шаблоном промпта для перевода.Примеры промптов для API и SDKИсправление ошибок'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/entertainment/meditation', 'title': 'Генератор медитаций | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/entertainment/meditation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генератор медитаций | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генератор медитацийОбновлено 14 ноября 2024Пример промпта для создания медитаций.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Придумай длинный и интересный текст для сеанса медитации. Медитирующий будет слышать шум моря. Тема медитации — принятие. Текст должен быть расслабляющий и успокаивающий. Не пиши никаких пояснений к тексту.\"        },    ],  \"max_tokens\": 2000, }input_variables: [background, topic]output_parser: nulltemplate: \\'Придумай длинный и интересный текст для сеанса медитации. Медитирующий будет слышать {background}. Тема медитации — {topic}. Текст должен быть расслабляющий и успокаивающий. Не пиши никаких пояснений к тексту.\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 2000,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Придумай длинный и интересный текст для сеанса медитации. Медитирующий будет слышать шум моря. Тема медитации — принятие. Текст должен быть расслабляющий и успокаивающий. Не пиши никаких пояснений к тексту.\"        },    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")meditation_prompt = load_from_giga_hub(\\'lc://prompts/entertainment/meditation.yaml\\')text = meditation_prompt.format(background=\"шум моря\", topic=\"принятие\")Генерация вопросов к заданному текстуМодели GigaChat'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/classification', 'title': 'Классификация обращений | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/classification', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Классификация обращений | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Классификация обращенийОбновлено 14 ноября 2024Пример промпта для классификации обращений.Промпт лучше работает с моделью GigaChat-Pro.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Классифицируй обращения пользователя в подходящую категорию. Категории: Статус заказа, Возврат и обмен товаров, Характеристики продукта, Технические проблемы, Другое. В ответе укажи только категорию.\"        },        {            \"role\": \"user\",            \"content\": \"При оформлении заказа возник вопрос о возможностях устройства. Поможете, пожалуйста, уточнить информацию?\"        }    ]}Промпт работает с помощью библиотеки gigachain_core, начиная с версии 0.1.9.1.Для обновления библиотеки выполните команду:pip install -U gigachain_coreinput_variables: [text]output_parser: nullmessages:  - role: system    prompt:      template: \\'Классифицируй обращения пользователя в подходящую категорию. Категории: Статус заказа, Возврат и обмен товаров, Характеристики продукта, Технические проблемы, Другое. В ответе укажи только категорию.\\'  - role: user    prompt:      template: \\'{text}\\'template_format: f-string_type: chatШаблон содержит переменные:text — текст обращения пользователя. Обязательное поле;Пример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",  \"temperature\": 1.0,  \"top_p\": 0.1,  \"n\": 1,  \"max_tokens\": 512,  \"repetition_penalty\": 1.0,  \"stream\": false,  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Классифицируй обращения пользователя в подходящую категорию. Категории: Статус заказа, Возврат и обмен товаров, Характеристики продукта, Технические проблемы, Другое. В ответе укажи только категорию.\"        },        {            \"role\": \"user\",            \"content\": \"При оформлении заказа возник вопрос о возможностях устройства. Помогите уточнить информацию, пожалуйста?\"        }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")prompt = load_from_giga_hub(\"lc://prompts/content/classification.yaml\")chain = prompt | gigachain.invoke(    {        \"text\": \"При оформлении заказа возник вопрос о возможностях устройства. Помогите уточнить информацию, пожалуйста?\"    }).contentГенерация таблицГенерация сущностей'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/entities', 'title': 'Генерация сущностей | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/entities', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация сущностей | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация сущностейОбновлено 14 ноября 2024Пример промпта для генерации сущностей.\\nПромпт содержит инструкцию по количеству синонимов сущности и формату ответа.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 объектов для сущности \\\\\"автомобиль\\\\\" для каждого объекта сгенерируй до 10 синонимов. Придерживайся следующих правил: объекты и синонимы должны быть уникальны, не придумывай несуществующие слова и выражения, если у тебя закончились варианты, то не генерируй ничего. Результат верни в формате JSON-массива без каких-либо пояснений, например, [{\\\\\"entity\\\\\": \\\\\"название объекта\\\\\", \\\\\"synonyms\\\\\": [\\\\\"синоним1\\\\\", \\\\\"синоним2\\\\\"]}].\"        },    ],}input_variables: [dataset_size_min, dataset_size_max, subject]output_parser: nulltemplate: \\'Сгенерируй от {dataset_size_min} до {dataset_size_max} объектов для сущности \"{subject}\" для каждого объекта сгенерируй до 10 синонимов. Придерживайся следующих правил: объекты и синонимы должны быть уникальны, не придумывай несуществующие слова и выражения, если у тебя закончились варианты, то не генерируй ничего. Результат верни в формате JSON-массива без каких-либо пояснений, например, [{\"entity\": \"название объекта\", \"synonyms\": [\"синоним1\", \"синоним2\"]}].\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 объектов для сущности \\\\\"автомобиль\\\\\" для каждого объекта сгенерируй до 10 синонимов. Придерживайся следующих правил: объекты и синонимы должны быть уникальны, не придумывай несуществующие слова и выражения, если у тебя закончились варианты, то не генерируй ничего. Результат верни в формате JSON-массива без каких-либо пояснений, например, [{\\\\\"entity\\\\\": \\\\\"название объекта\\\\\", \\\\\"synonyms\\\\\": [\\\\\"синоним1\\\\\", \\\\\"синоним2\\\\\"]}].\"        },    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")synonyms_with_examples = load_from_giga_hub(\\'lc://prompts/synonyms/entity_generation.yaml\\')text = prompt.format(dataset_size_min=5,                        dataset_size_max=10,                        subject=\"автомобиль\")Классификация обращенийГенерация интентов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/intents', 'title': 'Генерация интентов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/intents', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация интентов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация интентовОбновлено 14 ноября 2024Пример промпта для генерации интентов.\\nПромпт содержит инструкцию по количеству синонимов интента и формату ответа.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 фраз для интента \\\\\"Сделай посветлее\\\\\". Результат верни в формате JSON-списка без каких-либо пояснений, например, [\\\\\"фраза1\\\\\", \\\\\"фраза2\\\\\", \\\\\"фраза3\\\\\", \\\\\"фраза4\\\\\"]. Не дублируй фразы.\"        },    ],}input_variables: [dataset_size_min, dataset_size_max, subject]output_parser: nulltemplate: \\'Сгенерируй от {dataset_size_min} до {dataset_size_max} фраз для интента \"{subject}\". Результат верни в формате JSON-списка без каких-либо пояснений, например, [\"фраза1\", \"фраза2\", \"фраза3\", \"фраза4\"]. Не дублируй фразы.\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 фраз для интента \\\\\"Сделай посветлее\\\\\". Результат верни в формате JSON-списка без каких-либо пояснений, например, [\\\\\"фраза1\\\\\", \\\\\"фраза2\\\\\", \\\\\"фраза3\\\\\", \\\\\"фраза4\\\\\"]. Не дублируй фразы.\"        },    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")synonyms_with_examples = load_from_giga_hub(\\'lc://prompts/synonyms/intents_generation.yaml\\')text = synonyms_with_examples.format(dataset_size_min=5,                        dataset_size_max=10,                        subject=\"Сделай посветлее\")Генерация сущностейГенерация синонимов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/synonyms', 'title': 'Генерация синонимов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/nlp/synonyms', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация синонимов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация синонимовОбновлено 14 ноября 2024Пример промпта для генерации синонимов.\\nПромпт содержит инструкцию по количеству синонимов и формату ответа, а также примеры синонимов.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 синонимов для слова \\\\\"кошка\\\\\". Примеры синонимов: \\\\\"кот\\\\\", \\\\\"котенок\\\\\". Результат верни в формате JSON-списка без каких-либо пояснений, например, [\\\\\"синоним1\\\\\", \\\\\"синоним2\\\\\", \\\\\"синоним3\\\\\", \\\\\"синоним4\\\\\"]. Не повторяй фразы из примера и не дублируй фразы.\"        },    ],}input_variables: [dataset_size_min, dataset_size_max, subject, examples]output_parser: nulltemplate: \\'Сгенерируй от {dataset_size_min} до {dataset_size_max} синонимов для слова \"{subject}\". Примеры фраз: {examples}. Результат верни в формате JSON-списка без каких-либо пояснений, например, [\"синоним1\", \"синоним2\", \"синоним3\", \"синоним4\"]. Не повторяй фразы из примера и не дублируй фразы.\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {            \"role\": \"system\",            \"content\": \"Сгенерируй от 5 до 10 синонимов для слова \\\\\"кошка\\\\\". Примеры синонимов: \\\\\"кот\\\\\", \\\\\"котенок\\\\\". Результат верни в формате JSON-списка без каких-либо пояснений, например, [\\\\\"синоним1\\\\\", \\\\\"синоним2\\\\\", \\\\\"синоним3\\\\\", \\\\\"синоним4\\\\\"]. Не повторяй фразы из примера и не дублируй фразы.\"        },    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")synonyms_with_examples = load_from_giga_hub(\\'lc://prompts/synonyms/synonyms_generation_with_examples.yaml\\')text = synonyms_with_examples.format(dataset_size_min=5,                        dataset_size_max=10,                        subject=\"кошка\",                        examples=\\'[\"кот\", \"котенок\"]\\')Генерация интентовСуммаризация'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/overview', 'title': 'Примеры промптов для API и SDK | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Примеры промптов для API и SDK | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Примеры промптов для API и SDKОбновлено 24 мая 2024При работе с GigaChat API промпты передаются в запросах POST /chat/completions, а при работе с GigaChat SDK — в виде шаблонов (полный каталог промптов GigaChain доступен в github).ФильтрыАнализ и рассужденияГенерацияГенерация кодаКлассификацияМозговой штурмОбобщениеПеревод текстаПереписываниеРедактирование текстаСброситьПеревод текстаПромпт для повышения качества перевода с английского языка на русскийПеревод текстаРедактирование текстаИсправление ошибокПромпт для исправления грамматических и орфографических ошибок в письмах, статьях и постахПереписываниеРедактирование текстаСтилизация текстаПромпт для переписывания текста в заданном стилеРедактирование текстаГенерация описания товаровПромпт для создания рекламного описания продукта для маркетплейсаГенерацияМозговой штурмГенерация таблицПромпт для генерации таблиц в разметке MarkdownГенерацияГенерация кодаКлассификация обращенийПромпт для операторов поддержки по классификации отзывов и обращенийАнализ и рассужденияКлассификацияОбобщениеГенерация сущностейПромпт для генерации объектов и синонимов по какой-то сущности с выдачей результата в JSONГенерацияГенерация интентовПромпт для генерации синонимов к конкретному запросуГенерацияГенерация синонимовПромпт для генерации синонимов к конкретному слову с примерамиГенерацияСуммаризацияПромпт для выделения из текста основных мыслейОбобщениеСуммаризация больших текстов с помощью GigaChainПромпт и руководство для краткого пересказа больших текстов с помощью GigaChainОбобщениеГенерация разных вариантов вопросовПромпт для генерации профильных вопросов на примере страхового агентаГенерацияМозговой штурмГенерация вопросов к заданному текстуПромпт для генерации трех вопросов к заданному текстуАнализ и рассужденияГенерацияМозговой штурмГенератор медитацийПромпт для генерации медитаций для отдыхаГенерацияМозговой штурмРабота в песочнице промптовПеревод текста'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/qna/question-generation', 'title': 'Генерация вопросов к заданному тексту | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/qna/question-generation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация вопросов к заданному тексту | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация вопросов к заданному текстуОбновлено 14 ноября 2024Пример промпта для генерации различных вопросов к переданному тексту.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Перед тобой некоторая часть целостного документа.\\\\nПридумай и напиши 3 УНИКАЛЬНЫХ КОРОТКИХ ВОПРОСА, которые человек может задать к данному документу.\\\\nИспользуй информацию ТОЛЬКО из приведенной части документа.\\\\nИспользуй непредвзятый и журналистский тон. Не повторяй текст.\\\\nФормат ответ должен выглядеть вот так:\\\\n\\\\n\\\\\"Вопрос\\\\n\\\\n...\\\\n...\\\\nВопрос\\\\n\\\\n\\\\\"\"        },        {            \"role\": \"user\",            \"content\": \"<Текст>\"        }    ],}input_variables: [text]output_parser: nulltemplate: \\'Перед тобой некоторая часть целостного документа. Придумай и напиши 3 УНИКАЛЬНЫХ КОРОТКИХ ВОПРОСА, которые человек может задать к данному документу.Используй информацию ТОЛЬКО из приведенной части документа.Используй непредвзятый и журналистский тон. Не повторяй текст.Формат ответ должен выглядеть вот так:\"Вопрос......Вопрос\"Текст документа:{text}3 вопроса к документу на русском языке:\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {           \"model\": \"GigaChat\",           \"messages\": [                 {                     \"role\": \"system\",                     \"content\": \"Перед тобой некоторая часть целостного документа.\\\\nПридумай и напиши 3 УНИКАЛЬНЫХ КОРОТКИХ ВОПРОСА, которые человек может задать к данному документу.\\\\nИспользуй информацию ТОЛЬКО из приведенной части документа.\\\\nИспользуй непредвзятый и журналистский тон. Не повторяй текст.\\\\nФормат ответ должен выглядеть вот так:\\\\n\\\\n\\\\\"Вопрос\\\\n\\\\n...\\\\n...\\\\nВопрос\\\\n\\\\n\\\\\"\"                 },                 {                     \"role\": \"user\",                     \"content\": \"<Текст>\"                 }             ],         }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")generate_question_prompt = load_from_giga_hub(\\'lc://prompts/qna/generate_question_prompt.yaml\\')text = generate_question_prompt.format(text=\"... text of your documents ...\")Генерация разных вариантов вопросовГенератор медитаций'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/retrivers/multi-query', 'title': 'Генерация разных вариантов вопросов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/retrivers/multi-query', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерация разных вариантов вопросов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерация разных вариантов вопросовОбновлено 14 ноября 2024Пример промпта для генерации различных вариаций вопроса.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Ты эксперт по страхованию.\\\\nТвоя задача — сгенерировать 3 разных сокращенных версий вопроса, для поиска по векторной базе данных.\\\\nГенерируя разные версии вопроса пользователя,твоя цель — помочь найти его в страховом договоре.\\\\nИспользуй юридический лексикон для этого.\\\\nПредоставь вопросы в виде списка JSON.\\\\n\\\\nПример:\\\\n[\\\\\"Вопрос1\\\\\", \\\\\"Вопрос2\\\\\"]\"        },        {            \"role\": \"user\",            \"content\": \"<Текст вопроса>\"        }    ],}input_variables: [question]output_parser: nulltemplate: \\'Ты эксперт по страхованию.Твоя задача — сгенерировать 3 разных сокращенных версий вопроса, для поиска по векторной базе данных.Генерируя разные версии вопроса пользователя, твоя цель — помочь найти его в страховом договоре.Используй для этого юридический лексикон.Предоставь вопросы в виде списка JSON.Пример:[\"Вопрос1\", \"Вопрос2\"]Вопрос: [{question}]AI:\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {           \"model\": \"GigaChat\",           \"messages\": [                 {                     \"role\": \"system\",                     \"content\": \"Ты эксперт по страхованию.\\\\nТвоя задача — сгенерировать 3 разных сокращенных версий вопроса, для поиска по векторной базе данных.\\\\nГенерируя разные версии вопроса пользователя,твоя цель — помочь найти его в страховом договоре.\\\\nИспользуй юридический лексикон для этого.\\\\nПредоставь вопросы в виде списка JSON.\\\\n\\\\nПример:\\\\n[\\\\\"Вопрос1\\\\\", \\\\\"Вопрос2\\\\\"]\"                 },                 {                     \"role\": \"user\",                     \"content\": \"<Текст вопроса>\"                 }             ],         }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains import LLMChainfrom langchain_gigachat.chat_models import GigaChatfrom langchain.retrievers.multi_query import JSONLineListOutputParsergiga = GigaChat(credentials=\"ключ авторизации\")insurance_prompt = load_from_giga_hub(    \\'lc://prompts/retrievers/multi_query/insurance_agent.yaml\\')llm_chain = LLMChain(    llm=giga,    prompt=insurance_prompt,    output_parser=JSONLineListOutputParser(),)print(llm_chain.run(question=\"Страхуются ли музыкальные инструменты?\"))Суммаризация больших текстов с помощью GigaChainГенерация вопросов к заданному тексту'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/summarization/large-texts', 'title': 'Суммаризация больших текстов с помощью GigaChain | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/summarization/large-texts', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Суммаризация больших текстов с помощью GigaChain | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Суммаризация больших текстов с помощью GigaChainОбновлено 14 ноября 2024Раздел содержит пример суммаризации первых двух глав «Мастера и Маргариты» с помощью GigaChain и нескольких шаблонов промптов, доступных в репозитории.Используйте для суммаризации модель с большим размером контектса.Пример:from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains.summarize import load_summarize_chainfrom langchain.chat_models import GigaChatfrom langchain.document_loaders import TextLoaderfrom langchain.text_splitter import RecursiveCharacterTextSplittergiga = GigaChat(credentials=\"ключ авторизации\", model=\"GigaChat-Pro\")loader = TextLoader(\"../../../../docs/docs/use_cases/мастер_и_маргарита.txt\")documents = loader.load()text_splitter = RecursiveCharacterTextSplitter(    chunk_size = 7000,    chunk_overlap  = 0,    length_function = len,    is_separator_regex = False,)documents = text_splitter.split_documents(documents)print(f\"Количество частей книги: {len(documents)}\")book_map_prompt = load_from_giga_hub(\"lc://prompts/summarize/map_reduce/summarize_book_map.yaml\")book_combine_prompt = load_from_giga_hub(\"lc://prompts/summarize/map_reduce/summarize_book_combine.yaml\")chain = load_summarize_chain(giga, chain_type=\"map_reduce\",                              map_prompt=book_map_prompt,                             combine_prompt=book_combine_prompt,                             verbose=False)res = chain.invoke({\"input_documents\": documents})print(res[\"output_text\"].replace(\". \", \".\\\\n\"))Используйте дополнительные параметры функции chain.invoke(), для управления объемом текста и изменения количества предложений:res = chain.invoke({    \"input_documents\": documents,    \"map_size\": \"одно предложение\",     \"combine_size\": \"три предложения\"    })print(res[\"output_text\"].replace(\". \", \".\\\\n\"))Смотрите также\\ufeffJupyter-блокнот с примером в репозиторииСуммаризацияГенерация разных вариантов вопросов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/summarization/map', 'title': 'Суммаризация | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/prompts-hub/summarization/map', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Суммаризация | Документация для разработчиковЭто полезныйматериал?Это полезный материал?СуммаризацияОбновлено 14 ноября 2024Пример промпта для выделения из текста основных мыслей.Структура промпта\\ufeffGigaChat APIGigaChain{  \"model\": \"GigaChat\",  \"messages\": [        {            \"role\": \"system\",            \"content\": \"Выдели 5 главных фактов и мыслей из этого текста. Сформулируй каждый факт в виде одной строки.\"        },        {            \"role\": \"user\",            \"content\": \"<Текст>\"        }    ],}input_variables: [text]output_parser: nulltemplate: \\'Выдели 5 главных фактов и мыслей из этого текста. Сформулируй каждый факт в виде одной строки.    \"{text}\"Основные 5 фактов:\\'template_format: f-string_type: promptПример запроса\\ufeffGigaChat APIGigaChaincurl --location \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\--header \\'Content-Type: application/json\\' \\\\--header \\'Authorization: <токен_доступа>\\' \\\\--data \\'{  \"model\": \"GigaChat\",   \"temperature\": 0.87,   \"top_p\": 0.47,   \"n\": 1,   \"max_tokens\": 512,   \"repetition_penalty\": 1.07,   \"stream\": false,   \"update_interval\": 0,     \"messages\": [        {           \"model\": \"GigaChat\",           \"messages\": [                 {                     \"role\": \"system\",                     \"content\": \"Выдели 5 главных фактов и мыслей из этого текста. Сформулируй каждый факт в виде одной строки.\"                 },                 {                     \"role\": \"user\",                     \"content\": \"<Текст>\"                 }             ],         }    ]}\\'from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain.chains.summarize import load_summarize_chainfrom langchain_gigachat.chat_models import GigaChatgiga = GigaChat(credentials=\"ключ авторизации\")map_prompt = load_from_giga_hub(\\'lc://prompts/summarize/map_reduce/map.yaml\\')chain = load_summarize_chain(giga, chain_type=\"map_reduce\", map_prompt=map_prompt)Генерация синонимовСуммаризация больших текстов с помощью GigaChain'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-create-project', 'title': 'Регистрация в личном кабинете | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-create-project', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Регистрация в личном кабинете | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Регистрация в личном кабинетеОбновлено 24 октября 2024Для работы с GigaChat API нужно зарегистрироваться в личном кабинете Studio и создать проект GigaChat API, где вы сможете приобретать пакеты с токенами, сгенерировать ключ авторизации и отслеживать статистику потребления. С помощью ключа авторизации вы можете получить токен доступа Access token для авторизации запросов к API.\\nПодробнее — в разделе Начало работы с API.Для этого:Зарегистрируйтесь в личном кабинете, используя свой аккаунт Сбер ID.Нажмите кнопку Создать проект в левом меню.Выберите GigaChat API в разделе AI-модели.В открывшемся окне:Введите название проекта.Ознакомьтесь и примите условия пользовательского соглашения.В интерфейсе проекта можно:Сгенерировать ключ авторизации (Authorization key).Ознакомиться с условиями действующего тарифа. Каждому новому пользователю по умолчанию подключается тариф Freemium. Об условиях тарифа и доступных тарифных планах читайте в разделе Тарифы и оплата.Изучить статистику потребления токенов.Приобрести дополнительные пакеты токенов.Узнать версию API, к которой предоставляется доступ. Версия указана в поле Scope в панели справа. Для физических лиц значение поля — GIGACHAT_API_PERS.Быстрый старт для физических лицПокупка токенов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-tokens-purchase', 'title': 'Покупка токенов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-tokens-purchase', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Покупка токенов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Покупка токеновОбновлено 10 октября 2024Физическим лицам доступен freemium-режим и платные пакеты токенов.\\nПодробнее о тарифах — в разделе Тарифы GigaChat API.Стоимость генерации текста зависит от того, к какой модели выполняется запрос.\\nМодель задается в поле model запроса POST /chat/completions.\\nПодробнее — в разделе Модели GigaChat.Freemium-режим доступен только в личном пространстве в Studio. Как приобрести платные пакеты токенов\\ufeffФизическим лицам доступно несколько пакетов на выбор. Они отличаются количеством токенов и используемыми моделями.\\nОплатить выбранные пакеты можно только по банковской карте.Независимо от наличия оплаченного пакета сначала будут использованы бесплатные токены из freemium-режима.\\nНеиспользованные токены пропадают по истечении срока действия пакета.Для покупки пакетов с токенами:Авторизуйтесь в личном кабинете Studio по СберID.Откройте проект GigaChat API. Вам станет доступна информация о текущих токенах и о платных пакетах.О создании проекта — в разделе Регистрация в личном кабинете.Нажмите Выбрать пакеты токенов.Откроется раздел Магазин.Выберите дополнительный пакет → нажмите Купить → проверьте корзину и нажмите Перейти к оплате.Для оплаты будет доступна только банковская карта.После успешной оплаты обновленный баланс токенов будет отображаться на главной странице проекта, в разделе Пакеты токенов, на вкладке Активные.\\nТокены будут действительны от трех до шести месяцев в зависимости от выбранного пакета.Регистрация в личном кабинетеНачало работы с API'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-using-api', 'title': 'Начало работы с API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/ind-using-api', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Начало работы с API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Начало работы с APIОбновлено 11 ноября 2024В этом разделе вы узнаете как получить токен доступа и начать использовать GigaChat API.Получение ключа авторизации\\ufeffПеред началом работы нужно сгенерировать ключ авторизации в проекте GigaChat API.Подробнее об Authorization keyКлюч авторизации (англ. Authorization key) — строка, полученная в результате кодирования в Base64 клиентского идентификатора (Client ID) и ключа (Client Secret) API. Вы можете использовать готовый ключ из личного кабинета или самостоятельно закодировать Client ID и Client Secret.Авторизационный ключ нужен для получения токена доступа Access token с помощью запроса POST /api/v2/oauth, который использует по Basic-схему аутентификации.Для этого:Откройте проект GigaChat API в личном кабинете Studio.В левой панели выберите раздел Настройки API.Нажмите кнопку Получить ключ.Ключ авторизации могут получить только пользователи с ролями Владелец и Администратор — для остальных ролей кнопка Получить ключ будет неактивна.Подробнее о ролях и их возможностях — в разделе Создание команды и управление доступами.\\nВ открывшемся окне скопируйте и сохраните значение поля Authorization Key.\\nКлюч авторизации, отображается только один раз и не хранятся в личном кабинете.\\nПри компрометации или утере ключа авторизации вы можете сгенерировать его повторно.В разделе Настройка API вы также можете сохранить Client ID и Client Secret, чтобы создать ключ авторизации самостоятельно.Получение токена доступа\\ufeffТокен доступа Access token нужен для авторизации запросов к GigaChat API по Bearer-схеме.\\nТокен получается в обмен на ключ авторизации с помощью запроса POST /api/v2/oauth.\\nТокен действителен в течение 30 минут.Пример запроса для получения токена доступа:cURLPythoncurl -L -X POST \\'https://ngw.devices.sberbank.ru:9443/api/v2/oauth\\' \\\\-H \\'Content-Type: application/x-www-form-urlencoded\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'RqUID: <уникальный_идетификатор_запроса>\\' \\\\-H \\'Authorization: Basic authorization_key\\' \\\\--data-urlencode \\'scope=GIGACHAT_API_PERS\\'import requestsurl = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"payload=\\'scope=GIGACHAT_API_PERS\\'headers = {  \\'Content-Type\\': \\'application/x-www-form-urlencoded\\',  \\'Accept\\': \\'application/json\\',  \\'RqUID\\': \\'<уникальный_идетификатор_запроса>\\',  \\'Authorization\\': \\'Basic authorization_key\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)RqUID — уникальный идентификатор запроса. Соответствует формату uuid4.Параметр для журналирования входящих вызовов и разбора инцидентов.\\nДля создания уникального идентификатора можно использовать стандартные библиотеки и классы для генерации UUID и GUID.Пример ответа:{  \"access_token\": \"<токен_доступа>\",  \"expires_at\": 1706026848841}В справочной документации вы найдете подробное описание параметров запроса и ответа.Также с помощью консоли вы сможете сгенерировать Access token.Используйте полученный токен доступа для авторизации запросов к GigaChat API.Запросы к GigaChat API\\ufeffЗапросы к GigaChat API передаются по адресу https://gigachat.devices.sberbank.ru/ и авторизуются с помощью токена доступа Access token, который передан в заголовке Authorization.\\nПодробное описание всех запросов к API — в справочной документации.Вы также можете передавать запросы к моделям в раннем доступе.\\nИх возможности могут отличаться от моделей, доступных в промышленном контуре.Для обращения к моделям в раннем доступе передавайте запросы по адресу https://gigachat-preview.devices.sberbank.ru/.Пример запроса на получение списка моделей:cURLPythoncurl https://gigachat.devices.sberbank.ru/api/v1/models \\\\  -H \\'Authorization: Bearer <токен_доступа>\\' \\\\import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/models\"payload={}headers = {  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"GET\", url, headers=headers, data=payload)print(response.text)Запрос возвращает список моделей GigaChat:{    \"object\": \"list\",    \"data\": [        {            \"id\": \"GigaChat\",            \"object\": \"model\",            \"owned_by\": \"salutedevices\"        },        {            \"id\": \"GigaChat-Pro\",            \"object\": \"model\",            \"owned_by\": \"salutedevices\"        },    ]}Модели GigaChat обладают разными возможностями и тарифицируются по-разному.Генерация текста и изображений\\ufeffЗа генерацию текста и изображений отвечает запрос POST /chat/completions.\\nС помощью запросов на генерацию вы можете решать самые разные задачи: переводить, исправлять и стилизовать текст, генерировать краткое содержание статей и выделять из них основные идеи, создавать изображения и многое другое.Запросы на генерацию тратят токены.Токен — единица тарификации.\\nТокен может быть символом, несколькими символами, фрагментом слова или словом целиком.\\nВ среднем в одном токене 3—4 символа, включая пробелы, знаки препинания и специальные символы.Токены расходуются как на запрос, так и на ответ модели.\\nВы можете заранее оценить количество токенов в запросе с помощью запроса POST /tokens/count.\\nРазные модели считают токены по-разному.\\nКоличество оставшихся токенов отображается в личном кабинете проекта GigaChat API.\\nЕсли вы используете API как юридическое лицо или ИП, в вашем личном кабинете также будет доступен мониторинг потребления токенов.Пример запроса на генерацию текста:cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Привет! Как дела?\"    }  ],  \"stream\": false,  \"repetition_penalty\": 1}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\"payload = json.dumps({  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Привет! Как дела?\"    }  ],  \"stream\": False,  \"repetition_penalty\": 1})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Пример ответа:{  \"choices\": [    {      \"finish_reason\": \"stop\",      \"index\": 0,      \"message\": {        \"content\": \"Все отлично, спасибо. А как ваши дела?\",        \"role\": \"assistant\"      }    }  ],  \"created\": 1706096547,  \"model\": \"GigaChat\",  \"object\": \"chat.completion\",  \"usage\": {    \"completion_tokens\": 12,    \"prompt_tokens\": 173,    \"system_tokens\": 0,    \"total_tokens\": 185  }}Если вы хотите получить наиболее сбалансированный ответ, не передавайте параметры temperature и top_p.\\nВ таком случае модель применит значения по умолчанию.Подробное описание параметров — в справке API.Создание эмбеддинга\\ufeffДля создания эмбеддингов используется запрос POST /embeddings.\\nЭмбеддинги нужны для определения смыслового сходства текстов, что позволяет решать задачи вроде поиска, извлечения данных из текстов и других.При создании эмбеддинга расходуются токены, также как и при генерации контента.\\nЗапросы на создание эмбеддингов передаются в модель Embeddings.Подробнее о создании эмбеддингов читайте в разделе Векторное представление текста.Пример запроса:cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/embeddings\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"Embeddings\",  \"input\": [    \"Расскажи о современных технологиях\"  ]}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/embeddings\"payload = json.dumps({  \"model\": \"Embeddings\",  \"input\": [    \"Расскажи о современных технологиях\"  ]})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Смотрите также\\ufeffБыстрый старт GigaChainПокупка токеновБыстрый старт для ИП и юридических лиц'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/legal-tokens-purchase', 'title': 'Регистрация и покупка токенов | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/legal-tokens-purchase', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Регистрация и покупка токенов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Регистрация и покупка токеновОбновлено 14 октября 2024Индивидуальные предприниматели и юридические лица могут использовать GigaChat API только после оплаты.В этом разделе вы узнаете как зарегистрироваться в личном кабинете, создать подходящий проект GigaChat API и оплатить токены для работы с API.Покупка пакетов\\ufeffПокупка пакетов — это тарификация токенов, при которой доступ к GigaChat API предоставляется после полной оплаты счета. Оплатить пакеты токенов можно по счету-оферте или по договору.Единица тарификации — один токен. Токен может быть символом, несколькими символами, фрагментом слова или словом целиком. В среднем в одном токене 3—4 символа, включая пробелы, знаки препинания и специальные символы.При генерации текста тарификации подлежат как символы запроса, так и символы ответа модели, в том числе системный промпт.Оплата по счету-оферте\\ufeffДля покупки пакетов с токенами по счету-оферте:Авторизуйтесь в личном кабинете Studio.Нажмите кнопку Новое пространство и выберите Корпоративное.Перейдите в созданное Корпоративное пространство → нажмите кнопку Создать проект → выберите GigaChat API Business. Откройте созданный проект GigaChat API Business. Вам станет доступна информация о текущих токенах и о платных пакетах.В левом боковом меню выберите раздел Магазин → выберите пакеты с токенами → нажмите Купить и проверьте корзину.Выберите способ оплаты Счет-оферта → ознакомьтесь с офертой → нажмите Перейти к оплате.Заполните форму для выставления счета. В поле Почта укажите email, куда необходимо направить счет на оплату.После успешной оплаты вы увидите обновленный баланс токенов в карточке GigaChat API в разделе с активным тарифом. Токены будут действительны 12 месяцев с момента оплаты. Оплата по договору\\ufeffДля покупки пакетов с токенами по договору выполните три основных шага.Шаг 1. Настройка личного кабинетаЗарегистрируйтесь или авторизуйтесь в личном кабинете Studio.Нажмите кнопку Новое пространство и выберите Корпоративное.Перейдите в созданное Корпоративное пространство → нажмите кнопку Создать проект → выберите GigaChat API Business. Шаг 2. Отправка заявки на оплату по договоруОткройте в личном кабинете созданный проект GigaChat API Business. Вам станет доступна информация о текущих токенах и о платных пакетах.В левом боковом меню выберите раздел Магазин → выберите пакеты с токенами → нажмите Купить и проверьте корзину.Выберите способ оплаты Договор → нажмите Перейти к оплате.В открывшемся окне заполните заявку на заключение договора.Шаг 3. Подписание договораВ течение двух рабочих дней с вами свяжется менеджер и пришлет на почту шаблон договора. После получения этого шаблона:Заполните договор и вставьте в него ID Лицевого счета. Его можно найти в письме про подключение GigaChat API или в личном кабинете.Отправьте нам заполненный договор в формате doc/docx по ЭДО.Дождитесь подписания договора с нашей стороны.Вы также можете дополнительно отправить письмо с запросом на подписание договора на электронную почту.После заключения договора вы сможете получить в личном кабинете ключ авторизации для работы с GigaChat API.\\nПодробнее — в Начало работы с API.Оплата pay-as-you-go\\ufeffPay-as-you-go — это тарификация по факту потребления с оплатой только по договору. Доступ к GigaChat API предоставляется сразу после заключения договора. Стоимость работы рассчитывается от объема услуг, потребленных в течение платежного периода. Платежный период — один календарный месяц.В конце расчетного периода вы получаете счет на оплату и универсальный передаточный документ (УПД).Стоимость генерации текста зависит от того, к какой модели выполняется запрос: GigaChat Lite, GigaChat Lite+ или GigaChat Pro. Модель задается в поле model запроса POST /chat/completions.Заключение договора\\ufeffДля заключения договора по pay-as-you-go выполните три основных шага:Шаг 1. Настройка личного кабинетаЗарегистрируйтесь или авторизуйтесь в личном кабинете Studio.Нажмите кнопку Новое пространство и выберите Корпоративное Плюс.Перейдите в созданное пространство Корпоративное Плюс → нажмите кнопку Запросить доступ в блоке GigaChat API Enterprise. Шаг 2. Отправка заявки на оплату по договоруПри переходе в карточку GigaChat API Enterprise заполните заявку на получение доступа к GigaChat API.Ознакомьтесь с условиями использования и нажмите кнопку Отправить заявку.Шаг 3. Подписание договораВ течение двух рабочих дней с вами свяжется менеджер и пришлет на почту шаблон договора. После получения этого шаблона:Заполните договор и вставьте в него ID Лицевого счета. Его можно найти в письме про подключение GigaChat API или в личном кабинете. Отправьте нам заполненный договор в формате doc/docx по ЭДО.Дождитесь подписание договора с нашей стороны. Вы также можете дополнительно отправить письмо с запросом на подписание договора на электронную почту.После заключения договора вы сможете получить в личном кабинете ключ авторизации для работы с GigaChat API.\\nПодробнее — в Начало работы с API.Примеры расчета стоимости\\ufeffНиже приведен расчет стоимости на примере работы с моделью GigaChat Lite (0,2 ₽ за 1000 токенов, включая НДС). Стоимость использования округляется до целых копеек в большую сторону.Пример:Если на вход модели был передан запрос длиной 20 токенов и модель сформировала ответ длиной 30 токенов, общее использование будет составлять 50 токенов.Пример:Если вы использовали за месяц 876 835 токенов, использование сервиса будет стоить 175,37 рубля (876 835 x 0,0002 = 175,367, с округлением до целого значения).\\nНо учитывая минимальную стоимость, вам нужно будет заплатить 600 рублей.Пример:Если вы использовали за месяц 4 686 830 токенов, использование сервиса будет стоить 937,37 рубля (4 686 830 x 0,0002 = 937,366, с округлением до целых копеек).Быстрый старт для ИП и юридических лицНачало работы с API'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/legal-using-api', 'title': 'Начало работы с API | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachat/quickstart/legal-using-api', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Начало работы с API | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Начало работы с APIОбновлено 20 ноября 2024В этом разделе вы узнаете как получить токен доступа и начать использовать GigaChat API.Перед использованием API как ИП или юридическое лицо убедитесь, что вы оплатили доступ.Получение ключа авторизации\\ufeffПеред началом работы нужно сгенерировать ключ авторизации и Client Secret в проекте GigaChat API.Подробнее об Authorization keyКлюч авторизации (англ. Authorization key) — строка, полученная в результате кодирования в Base64 клиентского идентификатора (Client ID) и ключа (Client Secret) API. Вы можете использовать готовый ключ из личного кабинета или самостоятельно закодировать Client ID и Client Secret.Авторизационный ключ нужен для получения токена доступа Access token с помощью запроса POST /api/v2/oauth, который использует по Basic-схему аутентификации.Для этого:Откройте проект GigaChat API в личном кабинете Studio.В левой панели выберите раздел Настройки API.Нажмите кнопку Получить ключ.Ключ авторизации могут получить только пользователи с ролями Владелец и Администратор — для остальных ролей кнопка Получить ключ будет неактивна.Подробнее о ролях и их возможностях — в разделе Создание команды и управление доступами.\\nВ открывшемся окне скопируйте и сохраните значение полей Client Secret и Ключ авторизации.Ключ авторизации, как и Client Secret, отображаются только один раз и не хранятся в личном кабинете.При компрометации или утере ключа авторизации или Client Secret вы можете сгенерировать новое значение.Получите токен доступа\\ufeffТокен доступа Access token нужен для авторизации запросов к GigaChat API по Bearer-схеме.\\nТокен получается в обмен на ключ авторизации с помощью запроса POST /api/v2/oauth.Токен действителен в течение 30 минут.При отправке запроса на получение токена доступа нужно указать версию АПИ, к которой будут выполняться запросы:GIGACHAT_API_B2B — доступ для ИП и юридических лиц по платным пакетам.GIGACHAT_API_CORP — доступ для ИП и юридических лиц по схеме pay-as-you-go.Пример запроса для получения токена доступа:cURLPythoncurl -L -X POST \\'https://ngw.devices.sberbank.ru:9443/api/v2/oauth\\' \\\\-H \\'Content-Type: application/x-www-form-urlencoded\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'RqUID: <уникальный_идетификатор_запроса>\\' \\\\-H \\'Authorization: Basic authorization_key\\' \\\\--data-urlencode \\'scope=GIGACHAT_API_B2B\\'import requestsurl = \"https://ngw.devices.sberbank.ru:9443/api/v2/oauth\"payload=\\'scope=GIGACHAT_API_B2B\\'headers = {  \\'Content-Type\\': \\'application/x-www-form-urlencoded\\',  \\'Accept\\': \\'application/json\\',  \\'RqUID\\': \\'<уникальный_идетификатор_запроса>\\',  \\'Authorization\\': \\'Basic authorization_key\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)RqUID — уникальный идентификатор запроса. Соответствует формату uuid4.Параметр для журналирования входящих вызовов и разбора инцидентов.\\nДля создания уникального идентификатора можно использовать стандартные библиотеки и классы для генерации UUID и GUID.Пример ответа:{  \"access_token\": \"<токен_доступа>\",  \"expires_at\": 1706026848841}В справочной документации вы найдете подробное описание параметров запроса и ответа.\\nТакже сможете сгенерировать токен доступа с помощью своего идентификатора (Client ID) и клиентского ключа (Client Secret).Используйте полученный токен доступа для авторизации запросов к GigaChat API.Запросы к GigaChat API\\ufeffПеред работой с API в личном кабинете нужно приобрести пакеты токенов на минимальную сумму.Запросы к GigaChat API передаются по адресу https://gigachat.devices.sberbank.ru/ и авторизуются с помощью токена доступа Access token, который передан в заголовке Authorization.\\nПодробное описание всех запросов к API — в справочной документации.Вы также можете передавать запросы к моделям в раннем доступе.\\nИх возможности могут отличаться от моделей, доступных в промышленном контуре.Для обращения к моделям в раннем доступе передавайте запросы по адресу https://gigachat-preview.devices.sberbank.ru/.Пример запроса на получение списка моделей:cURLPythoncurl https://gigachat.devices.sberbank.ru/api/v1/models \\\\  -H \\'Authorization: Bearer <токен_доступа>\\' \\\\import requestsurl = \"https://gigachat.devices.sberbank.ru/api/v1/models\"payload={}headers = {  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"GET\", url, headers=headers, data=payload)print(response.text)Запрос возвращает список моделей GigaChat:{    \"object\": \"list\",    \"data\": [        {            \"id\": \"GigaChat\",            \"object\": \"model\",            \"owned_by\": \"salutedevices\"        },        {            \"id\": \"GigaChat-Pro\",            \"object\": \"model\",            \"owned_by\": \"salutedevices\"        },    ]}Модели GigaChat обладают разными возможностями и тарифицируются по-разному.Генерация текста\\ufeffЗа генерацию текста и изображений отвечает запрос POST /chat/completions.\\nС помощью запросов на генерацию вы можете решать самые разные задачи: переводить, исправлять и стилизовать текст, генерировать краткое содержание статей и выделять из них основные идеи, создавать изображения и многое другое.Запросы на генерацию тратят токены.Токен — единица тарификации.\\nТокен может быть символом, несколькими символами, фрагментом слова или словом целиком.\\nВ среднем в одном токене 3—4 символа, включая пробелы, знаки препинания и специальные символы.Токены расходуются как на запрос, так и на ответ модели.\\nВы можете заранее оценить количество токенов в запросе с помощью запроса POST /tokens/count.\\nРазные модели считают токены по-разному.\\nКоличество оставшихся токенов отображается в личном кабинете проекта GigaChat API.\\nЕсли вы используете API как юридическое лицо или ИП, в вашем личном кабинете также будет доступен мониторинг потребления токенов.Пример запроса на генерацию текста:cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/chat/completions\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Привет! Как дела?\"    }  ],  \"stream\": false,  \"repetition_penalty\": 1}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/chat/completions\"payload = json.dumps({  \"model\": \"GigaChat\",  \"messages\": [    {      \"role\": \"user\",      \"content\": \"Привет! Как дела?\"    }  ],  \"stream\": False,  \"repetition_penalty\": 1})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Пример ответа:{  \"choices\": [    {      \"finish_reason\": \"stop\",      \"index\": 0,      \"message\": {        \"content\": \"Все отлично, спасибо. А как ваши дела?\",        \"role\": \"assistant\"      }    }  ],  \"created\": 1706096547,  \"model\": \"GigaChat\",  \"object\": \"chat.completion\",  \"usage\": {    \"completion_tokens\": 12,    \"prompt_tokens\": 173,    \"system_tokens\": 0,    \"total_tokens\": 185  }}Если вы хотите получить наиболее сбалансированный ответ, не передавайте параметры temperature и top_p.\\nВ таком случае модель применит значения по умолчанию.Подробное описание параметров — в справке API.Создание эмбеддинга\\ufeffДля создания эмбеддингов используется запрос POST /embeddings.\\nЭмбеддинги нужны для определения смыслового сходства текстов, что позволяет решать задачи вроде поиска, извлечения данных из текстов и других.При создании эмбеддинга расходуются токены, также как и при генерации контента.\\nЗапросы на создание эмбеддингов передаются в модель Embeddings.Подробнее о создании эмбеддингов читайте в разделе Векторное представление текста.Пример запроса:cURLPythoncurl -L -X POST \\'https://gigachat.devices.sberbank.ru/api/v1/embeddings\\' \\\\-H \\'Content-Type: application/json\\' \\\\-H \\'Accept: application/json\\' \\\\-H \\'Authorization: Bearer <токен_доступа>\\' \\\\--data-raw \\'{  \"model\": \"Embeddings\",  \"input\": [    \"Расскажи о современных технологиях\"  ]}\\'import requestsimport jsonurl = \"https://gigachat.devices.sberbank.ru/api/v1/embeddings\"payload = json.dumps({  \"model\": \"Embeddings\",  \"input\": [    \"Расскажи о современных технологиях\"  ]})headers = {  \\'Content-Type\\': \\'application/json\\',  \\'Accept\\': \\'application/json\\',  \\'Authorization\\': \\'Bearer <токен_доступа>\\'}response = requests.request(\"POST\", url, headers=headers, data=payload)print(response.text)Смотрите также\\ufeffБыстрый старт GigaChainРегистрация и покупка токеновВыбор модели для генерации'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/salutebotvoice/gigachat/answer-generation', 'title': 'Генерируем ответ с помощью GigaChat | Документация для разработчиков | GigaChat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/salutebotvoice/gigachat/answer-generation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Генерируем ответ с помощью GigaChat | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Генерируем ответ с помощью GigaChatОбновлено 12 февраля 2024SaluteBot VoiceGraphCodeДля генерации ответа клиенту голосового робота через GigaChat используйте блок Генерация ответа.Блок выполняет запрос в GigaChat. Генерация ответа в GigaChat выполняется по параметрам, заданным в настройках блока. После получения ответа выполняется переход по сценарию.Подключение блока в сценарий\\ufeffДля подключения блока в сценарий:Откройте проект сценария Graph для вашего голосового робота.Выберите в сценарии шаг, на котором вы хотите добавить обращение в GigaChat.Добавьте блок Генерация ответа.Заполните параметры блока.Сохраните и соберите сценарий.С рекомендациями по созданию промптов вы можете ознакомиться в разделе Создание промптов.Параметры блокаПараметрОписаниеПримерСистемный промптТекстовое поле, многострочное. Не более 1500 символов. Позволяет задать промпт для настройки контекста обработки основного промпта. Поддерживает использование переменных сценарияОтвечай в стиле Винни ПухаЗапросТекстовое поле, многострочное. Не более 1500 символов. Текст вопроса к GigaChat. Поддерживает использование переменных сценария$queryText содержит вопрос пользователя из диалога с голосовым роботом, например, Где купить гречишный мед?. В блоке можно вручную заполнить переменную с историей, указав ее в нужном месте текста промптаОтвет от GigaChatТекстовое поле для указания названия переменной, в которую должен сохраниться ответ от GigaChat. Не более 30 символовВыводить результат пользователюОтметка об отправке сообщения пользователюtrue: отправлять сообщение клиенту голосового робота при выполнении блока, в случае успешного выполнения и получения ответа от GigaChat  false: не отправлять сообщение. Результат будет сохранен в указанную переменнуюУчитывать контекст диалогаОтметка о включении отправки истории диалогаtrue: история диалога отправляется  false: история диалога не добавляется в запрос в GigaChat. Отправка истории отключена вручнуюВсе параметры блока, кроме параметра Системный промпт, являются обязательными.Выходы из блока в сценарии\\ufeffУспешно - успешное выполнение запроса в GigaChat и получение ответа.Ошибка - при выполнении запроса в GigaChat возникла ошибка.Обратите внимание: клиенту не будут переданы дополнительные сообщения или уведомления, пока не будет получен ответ от GigaChat.Обработка ошибок\\ufeffПри возникновении ошибки выход из блока произойдет по переходу Ошибка. Для подробной обработки ошибки необходимо сохранять ответ со статусом ошибки в системные переменные:НазваниеОписаниеКомментарий$gigaChatResponseStatusКод ошибки, возникшей при выполнении запросаПример значения: 408 (Таймаут при выполнении запроса)  В сценарии можно использовать в блоке Условия, добавив кастомное условие, например, $gigaChatResponseStatus==408 и сделать переход из блока для случаев таймаута$gigaChatResponseErrorТекст ошибки, возникшей при выполнении запросаПример значения: Read timed outСписок возвращаемых статусов ошибокКейсКод ошибкиОписание ошибкиОграничение тарифа403Restricted for the current tariffТаймаут выполнения запроса (выполнение запроса не выполнено в указанный таймаут)408Read timed outПревышены лимиты по размеру полей Запрос или Системный промпт413Content is too largeОшибка при выполнении запроса в GigaChat500Request failedДостигнуто максимальное количество запросов в GigaChat на одного клиента503.1The limit of requests for the user per dayДостигнуто максимальное количество обращений для тестового виджета503.2The limit of requests for test per projectЗапросы ограничены для текущей интеграции503.3Restricted for the channelTypeНастраиваем диалог с пользователемОбрабатываем незнакомые фразы пользователя')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gigachat_docs = load_gigachat_docs()\n",
    "gigachat_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching pages: 100%|##########| 22/22 [00:09<00:00,  2.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/concepts/architecture', 'title': 'Архитектура | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/concepts/architecture', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Архитектура | Документация для разработчиковЭто полезныйматериал?Это полезный материал?АрхитектураОбновлено 4 сентября 2024Фреймворк GigaChain состоит из нескольких пакетов.gigachain-core\\ufeffПакет содержит базовые абстракции различных компонентов и способы их объединения.\\nЗдесь определены интерфейсы для основных компонентов: LLM, векторных хранилищ, ретриверов и других.\\nВ пакете нет интеграций со сторонними продуктами.\\nЗависимости намеренно сведены к минимуму.Связанные пакеты\\ufeffПолный список интеграций содержится в gigachain-community, тогда как интеграции с популярными сервисами выделены в собственные пакеты. Например, gigachain-openai, gigachain-chroma и другие.gigachain\\ufeffОсновной пакет gigachain содержит цепочки, агентов и поисковые стратегии, которые составляют когнитивную архитектуру приложения.\\nВсе компоненты пакета универсальны и не зависят от конкретных интеграций.gigachain-community\\ufeffУстановка этого пакета достаточна для быстрого начала работы с GigaChain.Подробнее — в разделе Установка.Пакет необходим для работы с моделями GigaChat.Он содержит интеграции со сторонними сервисами, которые поддерживаются сообществом GigaChain и LangChain.\\nПопулярные сервисы вынесены в отдельные пакеты.\\nПакет содержит интеграции для различных компонентов: LLM, векторных хранилищ, ретриверов.\\nЗависимости пакета необязательны, чтобы сделать его как можно легче.gigagraph\\ufeffGigaGraph — это расширение gigachain, которое использует LLM для создания надежных, многоакторных приложений с сохранением состояния. Для этого GigaGraph моделирует шаги работы приложения как ребра и узлы в графе. GigaGraph предоставляет высокоуровневые интерфейсы для создания распространенных типов агентов, а также низкоуровневое API для построения более сложных цепочек.gigaserve\\ufeffПакет для развертывания цепочек GigaChain в виде REST API. Позволяет легко запустить API, готовый к эксплуатации.Основные понятияЯзык выражений LangChain (LCEL)'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/concepts/components', 'title': 'Компоненты | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/concepts/components', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Компоненты | Документация для разработчиковЭто полезныйматериал?Это полезный материал?КомпонентыОбновлено 30 сентября 2024GigaChain предоставляет стандартные расширяемые интерфейсы и внешние интеграции для различных компонентов, полезных при работе с LLM.\\nОдни компоненты реализованы в GigaChain, для некоторых используются сторонние интеграции, а какие-то применяют и то, и другое.Чат-модели\\ufeffЯзыковые модели, которые используют последовательность сообщений в качестве входных данных и возвращают чат-сообщения в качестве выходных данных (в отличие от использования обычного текста).\\nТакой подход характерен для более новых моделей. Более старые модели это, как правило, LLM.\\nЧат-модели поддерживают назначение различных ролей для сообщений, что помогает различать сообщения от ИИ, пользователей и инструкции, такие как системные сообщения.Хотя базовые модели работают по принципу «сообщение на входе, сообщение на выходе», обертки GigaChain также позволяют этим моделям принимать строку в качестве входных данных. Это позволяет использовать чат-модели вместо LLM.Когда строка передается в качестве входных данных, она преобразуется в HumanMessage, который затем передается базовой модели.GigaChain не предоставляет ChatModel, а использует интеграции со сторонними сервисами.При создании экземпляра ChatModel используется стандартный параметр:model — имя модели.Объекты ChatModel также принимают другие параметры, специфичные для выбранной интеграции.\\nТак, при работе с GigaChat, вы можете передать параметры credentials и scope, которые содержат ключ авторизации и версию API, к которой нужно обратиться.Некоторые чат-модели подготовлены для вызова инструментов и предоставляют для этого специальный API.\\nТакие модели рекомендуется использовать, если ваши задачи требуют вызова инструментов.\\nПодробности — в разделе Вызов инструментов.LLM\\ufeffТе языковые модели, которые в качестве входных данных принимают строку, на выходе также возвращают строку.Хотя базовые модели работают по принципу «строка на входе, строка на выходе», обертки GigaChain также позволяют этим моделям принимать сообщения в качестве входных данных.\\nЭто делает их взаимозаменяемыми с ChatModels.\\nКогда сообщения передаются в качестве входных данных, они форматируются в строку перед передачей базовой модели.Для работы с LLM GigaChain использует интеграции со сторонними сервисами.Сообщения\\ufeffНекоторые языковые модели принимают список сообщений в качестве входных данных и на выходе возвращают сообщение.\\nСуществует несколько различных типов сообщений.\\nВсе сообщения имеют свойства role, content и response_metadata.Свойство role описывает автора сообщения.\\nGigaChain предоставляет разные классы сообщений для различных ролей.Свойство content описывает содержание сообщения.\\nСодержание может быть представлено:строковыми данными — большинство моделей работает именно с такими данными;списком словарей — используется для мультимодального ввода, где словарь содержит данные о типе ввода и месте, из которого он был получен.HumanMessage\\ufeffСообщение от пользователя.AIMessage\\ufeffСообщение от модели. Кроме content, сообщения модели имеют свойства:response_metadata — дополнительные метаданные ответа. Эти данные, как правило, зависят от модели, которую вы используете.\\nНапример, данные могут содержать логарифм вероятности и информацию об использовании токенов.tool_calls — данные о решении языковой модели вызвать инструмент. Они являются частью вывода AIMessage и доступны с помощью свойства .tool_calls.Это свойство возвращает список словарей. Каждый словарь содержит ключи:name — имя инструмента, который нужно вызвать;args — аргументы вызываемого инструмента;id — идентификатор вызова инструмента.SystemMessage\\ufeffСистемное сообщение, которое сообщает модели, как себя вести. Некоторые модели могут не поддерживать системное сообщение.FunctionMessage\\ufeffРезультат вызова функции. Кроме role и content, FunctionMessage содержит свойство name.\\nОно указывает имя функции, вызов которой привел к данному результату.ToolMessage\\ufeffДанное сообщение представляет результат вызова инструмента. Оно отличается от FunctionMessage тем, что соответствует типам сообщений OpenAI function и tool.\\nКроме role и content, это сообщение содержит свойство tool_call_id, которое передает идентификатор вызова инструмента,Шаблоны промптов\\ufeffШаблоны промптов помогают преобразовывать ввод пользователя и параметры в инструкции для языковой модели.\\nИх можно использовать для управления ответом модели, помогая ей понимать контекст задачи и поэтому генерировать более релевантный и связный текст.Шаблоны принимают на вход словарь, где каждый ключ представляет переменную шаблона, которую нужно заполнить.Шаблоны промптов возвращают значение промпта (PromptValue). Это значение можно передать в LLM или чат-модель, а также можно преобразовать в строку или список сообщений.\\nPromptValue упрощает переключение между строковыми данными и сообщениями.Существует несколько различных типов шаблонов промптов.String PromptTemplates\\ufeffШаблоны промптов, которые используются для форматирования одной строки и, как правило, применяются для более простых входных данных.\\nПример распространенного способа создания и использования PromptTemplate:from langchain_core.prompts import PromptTemplateprompt_template = PromptTemplate.from_template(\"Расскажи мне шутку про {topic}\")prompt_template.invoke({\"topic\": \"коты\"})ChatPromptTemplates\\ufeffШаблоны промптов, которые используются для форматирования списка сообщений. Эти «шаблоны» сами по себе состоят из списка шаблонов.\\nПример распространенного способа создания и использования ChatPromptTemplate:from langchain_core.prompts import ChatPromptTemplateprompt_template = ChatPromptTemplate.from_messages([    (\"system\", \"Ты полезный ассистент\"),    (\"user\", \"Расскажи мне шутку про {topic}\")])prompt_template.invoke({\"topic\": \"коты\"})В примере ChatPromptTemplate создаст два сообщения при вызове:первое — системное сообщение, которое не содержит переменных для форматирования;второе — сообщение от пользователя (HumanMessage). Оно может изменяться с помощью переменной topic, которую задает пользователь.MessagesPlaceholder\\ufeffШаблон промптов, который отвечает за добавление списка сообщений в определенное место.\\nТак, пример работы с ChatPromptTemplate показывает, как можно форматировать два сообщения, каждое из которых представляет собой строку.\\nВ свою очередь MessagesPlaceholder используется если нужно, чтобы пользователь передал список сообщений, которые требуется поместить в определенное место.from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderfrom langchain_core.messages import HumanMessageprompt_template = ChatPromptTemplate.from_messages([    (\"system\", \"Ты полезный ассистент\"),    MessagesPlaceholder(\"msgs\")])prompt_template.invoke({\"msgs\": [HumanMessage(content=\"привет!\")]})При выполнении примера создается список из двух сообщений:первое — системное сообщение;второе — сообщение HumanMessage, которое передал пользователь.Если передать пять сообщений, то в результате получится список из шести сообщений: системное сообщение и пять переданных.\\nЭто полезно, когда нужно поместить список сообщений в определенное место.Того же результата можно достигнуть без MessagesPlaceholder следующим образом:prompt_template = ChatPromptTemplate.from_messages([    (\"system\", \"Вы полезный ассистент\"),    (\"placeholder\", \"{msgs}\")  # <-- Измененный код])Селекторы образцов\\ufeffОдин из распространенных приемов для повышения качества работы модели — включение образцов желаемого результата в промпт.\\nТак модели будет проще понять, как себя вести.\\nОбразцы можно прописать непосредственно в промпте, но для более сложных ситуаций может быть полезно выбирать их динамически.\\nСелекторы образцов — это классы, ответственные за выбор и оформление образцов желаемого результата в промпты.Парсеры вывода\\ufeffЗдесь описаны парсеры, которые получают текстовый вывод модели и пробуют преобразовать и представить его в более структурированном виде.\\nВсе больше моделей поддерживают вызов функций/инструментов, которые делают это автоматически.\\nПо возможности, вместо парсинга вывода рекомендуется использовать именно вызов функций/инструментов.Парсеры отвечают за получение вывода модели и его преобразование в формат, более подходящий для дальнейших задач.\\nОни полезны при использовании LLM для генерации структурированных данных или для нормализации вывода чат-моделей и LLM.GigaChain поддерживает парсеры вывода различных типов. Список поддерживаемых парсеров представлен в таблице, которая содержит поля:Название — название парсера вывода.Поддержка потоковой передачи — поддерживает ли парсер потоковую передачу токенов.Инструкции по формату — есть ли у парсера инструкции по формату данных. Как правило, это доступно для всех парсеров, кроме случаев, когда требуемая схема не указана в промпте, а задается другими параметрами (например, при вызове функций OpenAI), или когда OutputParser оборачивает другой OutputParser.Вызов LLM — может ли парсер вывода самостоятельно вызывать LLM. Как правило, к вызову LLM обращаются только те парсеры, которые хотят исправить формат выходных данных.Тип выходных данных — ожидаемый тип входных данных. Большинство парсеров вывода работают как со строками, так и с сообщениями. Но некоторые, например, функции OpenAI, требуют сообщения с конкретными kwargs.Тип выходных данных — тип выходных данных объекта, возвращаемого парсером.Описание — комментарий, описывающий парсер и ситуации, когда он может быть полезен.НазваниеПоддержка потоковой передачуИнструкции по форматуВызов LLMТип входных данныхТип выходных данныхОписаниеJSON✅✅str | MessageОбъект JSONВозвращает JSON-объект. Можно указать модель Pydantic, в соответствии с которой парсер вернет JSON. Наиболее надежный парсер для получения структурированных данных, который не использует вызов функцийXML✅✅str | MessagedictВозвращает словарь тегов. Используйте, когда нужен XML-вывод. Используйте с моделями, которые хорошо работают с XML (например, Anthropic)CSV✅✅str | MessageList[str]Возвращает список значений, разделенных запятымиOutputFixing✅str | MessageОборачивает другой парсер вывода. Если обернутый парсер вывода выдаст ошибку, то OutputFixing передаст сообщение об ошибке и неправильный вывод в LLM и попросит модель исправить выводRetryWithError✅str | MessageОборачивает другой парсер вывода. Если обернутый парсер вывода выдаст ошибку, то RetryWithError передаст оригинальные входные данные, неправильный вывод и сообщение об ошибке в LLM и попросит модель внести исправления. В отличие от OutputFixingParser, также передает исходные инструкцииPydantic✅str | Messagepydantic.BaseModelПринимает пользовательскую модель Pydantic и возвращает данные, оформленные соответствующим образомYAML✅str | Messagepydantic.BaseModelПринимает пользовательскую модель Pydantic и возвращает данные, оформленные соответствующим образом. Для кодирования использует YAMLPandasDataFrame✅str | MessagedictПолезен для выполнения операций с DataFrame библиотеки pandasEnum✅str | MessageEnumПреобразует ответ в одно из заданных значений перечисления (enum)Datetime✅str | Messagedatetime.datetimeПреобразует ответ в строку даты и времени (datetime)Structured✅str | MessageDict[str, str]Возвращает структурированную информацию. Менее развитый, чем другие парсеры вывода, так как позволяет полям быть только строками. Это может быть полезно при работе с небольшими LLMИстория чата\\ufeffБольшинство LLM-приложений имеют интерфейс для ведения диалога.\\nДля них важно иметь возможность ссылаться на информацию, ранее представленную в беседе.\\nВ самом простом случае диалоговая система должна иметь возможность получать доступ к некоторому набору предыдущих сообщений.Концепция ChatHistory относится к классу в GigaChain, который можно использовать для обертывания произвольной цепочки.\\nЭкземпляр ChatHistory будет отслеживать входные и выходные данные основной цепочки и добавлять их в виде сообщений в базу данных сообщений.\\nПоследующие обращения загружают эти сообщения и передают их в цепочку в качестве части входных данных.Документы\\ufeffОбъект Document в GigaChain содержит информацию о некоторых данных. Он имеет два атрибута:page_content: str — содержимое документа, представленное в виде строки;metadata: dict — связанные с документом произвольные метаданные. Могут содержать идентификатор документа, имя файла и другие данные.Загрузчики документов\\ufeffКлассы, которые загружают объекты Document. GigaChain поддерживает интеграции с теми же сервисами, что и LangChain, например, Slack, Notion, Google Drive и другие. Подробнее об интеграциях с источниками данных — в официальной документации LangChain.Каждый DocumentLoader имеет свои специфические параметры, но любой из них можно вызвать одинаково с помощью метода .load.\\nПример использования:from langchain_community.document_loaders.csv_loader import CSVLoaderloader = CSVLoader(    ...  # <-- Специфические параметры интеграции)data = loader.load()Разделители текста\\ufeffПосле загрузки документов часто возникает необходимость преобразовать их для более удобной обработки. Например, разбить длинный документ на более мелкие фрагменты, которые могут поместиться в окно контекста вашей модели. GigaChain предоставляет ряд встроенных преобразователей документов, которые позволяют разделять, объединять, фильтровать и выполнять другие манипуляции с документами.Общее описание работы разделителей текста:Разделение текста на небольшие, семантически значимые части. Как правило, на предложения.Объединение этих небольших частей в более крупные до достижения определенного размера. Требуемый размер определяется собственной функцией.Чтобы сохранить контекст между разными фрагментам, после достижения нужного размера, создается отдельный фрагмент текста. Затем начинается создание нового фрагмента текста с некоторым перекрытием.Таким образом, при настройке разделителя текста следует учитывать:Как текст делится.Как измеряется размер фрагмента.Модели эмбеддингов\\ufeffКласс Embeddings предназначен для взаимодействия с моделями, которые создают векторное представление текста (эмбеддинги). При работе с GigaChat для эмбеддингов используется модель Embeddings. Вы также можете использовать подходящие модели других сервисов. Класс Embeddings предоставляет стандартный интерфейс для работы с моделями разных сервисов.Эмбеддинги позволяют работать с текстом в векторном пространстве и выполнять такие задачи, как семантический поиск, при котором ищутся текстовые фрагменты, наиболее схожие в векторном пространстве.Базовый класс Embeddings в GigaChain предоставляет два метода: один для эмбеддинга документов и один для эмбеддинга запроса. Первый принимает на вход несколько текстов, тогда как второй — один текст. Разделение на два метода обусловлено тем, что некоторые модели эмбеддингов имеют разные методы для эмбеддинга документов (для поиска) и запросов (сам поисковый запрос).Векторные хранилища\\ufeffОдин из наиболее распространенных способов хранения и поиска по неструктурированным данным — это их векторное преобразование и сохранение полученного эмбеддинга. При выполнении запроса он преобразуется в набор векторов, после чего из ранее сохраненного эмбеддинга извлекаются векторы, которые наиболее схожи с векторами эмбеддинга запроса. Векторное хранилище позволяет хранить эмбеддинги и выполнять векторный поиск.Векторные хранилища можно преобразовать в интерфейс ретривера следующим образом:vectorstore = MyVectorStore()retriever = vectorstore.as_retriever()Ретриверы\\ufeffРетривер — это интерфейс, который возвращает документы по неструктурированному запросу.\\nВ отличие от векторных хранилищ, ретриверы применяются для решения задач более общего характера.\\nРетривер необязательно должен уметь хранить документы, его задача — возвращать (извлекать) их.Ретриверы принимают строковый запрос на вход и возвращают список объектов Document на выходе.Инструменты\\ufeffИнструменты — это интерфейсы, которые агент, цепочка или чат-модель/LLM могут использовать для взаимодействия с внешним миром.Инструмент состоит из:названия;описания того, что делает инструмент;JSON-схемы входных данных инструмента;функции, которую вызывает инструмент;указания на то следует ли возвращать результат работы инструмента непосредственно пользователю. Это актуально только для агентов.Название, описание и JSON-схема предоставляются в качестве контекста для LLM, позволяя модели правильно использовать инструмент.\\nПосле получения списка доступных инструментов и промпта с инструкциями, LLM может запросить выполнение одного или нескольких инструментов с соответствующими аргументами.tools = [...] # Определение списка инструментовllm_with_tools = llm.bind_tools(tools)ai_msg = llm_with_tools.invoke(\"Сделай 1, 2, 3...\")  # AIMessage(tool_calls=[ToolCall(...), ...], ...)В общем случае, при разработке инструментов для использования в чат-моделях или LLM важно учитывать:Чат-модели, специально обученные для вызова инструментов, справляются с этим лучше.Неподготовленные модели могут в принципе не уметь работать с инструментами. Особенно, если инструменты сложные или требуют многократных вызовов.Модели будут работать лучше, если у инструментов тщательно подобраны названия, описания и JSON-схемы.Моделям легче работать с более простыми инструментами.Наборы инструментов\\ufeffНаборы инструментов — это коллекции инструментов, которые используются вместе в конкретных задачах. Наборы предоставляют удобные методы загрузки.Все наборы инструментов реализуют метод get_tools, который возвращает список инструментов:# Инициализация набора инструментовtoolkit = ExampleToolkit(...)# Получение списка инструментовtools = toolkit.get_tools()Агенты\\ufeffЯзыковые модели не совершают действия сами — они просто генерируют текст.\\nОдним из основных случаев использования GigaChain является создание агентов.Агенты — это системы, которые используют LLM для рассуждений и определения, какие действия выполнить и какие входные данные для этих действий использовать.\\nРезультаты выполнения можно затем передать обратно агенту, который определит, нужно ли делать что-то еще или можно завершить работу.GigaGraph — это расширение GigaChain, которое предназначено для создания управляемых и настраиваемых агентов.\\nПодробнее о концепции агентов — в документации GigaGraph.Для работы с агентами в GigaChain также существует класс AgentExecutor — среда выполнения для агентов.\\nВ документации вы найдете раздел посвященный работе с AgentExecutor, но для создания агентов рекомендуется использовать GigaGraph.Колбэки\\ufeffGigaChain предоставляет систему колбэков, которая позволяет вам подключаться к различным этапам работы вашего LLM-приложения. Это полезно для логирования, мониторинга, потоковой передачи и других задач. На эти события можно подписаться с помощью аргумента callbacks, доступного в API.\\nЭтот аргумент представляет список объектов-обработчиков, которые должны реализовать один или несколько методов, описанных ниже.Обработчики колбэков\\ufeffCallbackHandlers — это объекты, которые реализуют интерфейс CallbackHandler. Интерфейс содержит метод для каждого события, на которое можно подписаться.\\nПри получении события объект CallbackManager вызывает соответствующий метод каждого обработчика.class BaseCallbackHandler:    \"\"\"Базовый обработчик колбэков, который можно использовать для обработки колбэков в gigachain.\"\"\"    def on_llm_start(        self, serialized: Dict[str, Any], prompts: List[str], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при запуске LLM.\"\"\"    def on_chat_model_start(        self, serialized: Dict[str, Any], messages: List[List[BaseMessage]], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при запуске чат-модели.\"\"\"    def on_llm_new_token(self, token: str, **kwargs: Any) -> Any:        \"\"\"Выполняется при получении нового токена LLM. Доступно только при включенной потоковой передаче.\"\"\"    def on_llm_end(self, response: LLMResult, **kwargs: Any) -> Any:        \"\"\"Выполняется при завершении работы LLM.\"\"\"    def on_llm_error(        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при ошибке LLM.\"\"\"    def on_chain_start(        self, serialized: Dict[str, Any], inputs: Dict[str, Any], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при запуске цепочки.\"\"\"    def on_chain_end(self, outputs: Dict[str, Any], **kwargs: Any) -> Any:        \"\"\"Выполняется при завершении работы цепочки.\"\"\"    def on_chain_error(        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при ошибке цепочки.\"\"\"    def on_tool_start(        self, serialized: Dict[str, Any], input_str: str, **kwargs: Any    ) -> Any:        \"\"\"Выполняется при запуске инструмента.\"\"\"    def on_tool_end(self, output: Any, **kwargs: Any) -> Any:        \"\"\"Выполняется при завершении работы инструмента.\"\"\"    def on_tool_error(        self, error: Union[Exception, KeyboardInterrupt], **kwargs: Any    ) -> Any:        \"\"\"Выполняется при ошибке инструмента.\"\"\"    def on_text(self, text: str, **kwargs: Any) -> Any:        \"\"\"Выполняется при обработке произвольного текста.\"\"\"    def on_agent_action(self, action: AgentAction, **kwargs: Any) -> Any:        \"\"\"Выполняется при действии агента.\"\"\"    def on_agent_finish(self, finish: AgentFinish, **kwargs: Any) -> Any:        \"\"\"Выполняется при завершении работы агента.\"\"\"Передача колбэков\\ufeffСвойство callbacks доступно на большинстве объектов в API (моделях, инструментах, агентах и т.д.) в двух разных местах:Колбэки конструктора определяются в конструкторе, например, ChatAnthropic(callbacks=[handler], tags=[\\'a-tag\\']). В этом случае колбэки используются для всех вызовов, сделанных с этим объектом, и будут применяться только к этому объекту.\\nНапример, если вы инициализируете чат-модель с колбэками конструктора, а затем используете ее в цепочке, колбэки будут вызываться только при обращении к этой модели.Колбэки запроса передаются в метод invoke, который используется для выполнения запроса. В этом случае колбэки используются только для этого конкретного запроса и всех подзапросов, которые он содержит. Например, вызов последовательности, которая вызывает модель, используя тот же обработчик, переданный в методе invoke().\\nВ методе invoke() колбэки передаются в параметре config.Язык выражений LangChain (LCEL)Техники использования больших языковых моделей'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/concepts/lcel', 'title': 'Язык выражений LangChain (LCEL) | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/concepts/lcel', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Язык выражений LangChain (LCEL) | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Язык выражений LangChain (LCEL)Обновлено 10 октября 2024Язык выражений LangChain, или LCEL — это декларативный способ объединения компонентов LangChain.\\nВ основе LCEL лежит возможность поддержки внедрения прототипов в эксплуатацию без изменений в коде.\\nЭто касается как самых простых цепочек «промпт + LLM», так и самых сложных цепочек (есть примеры успешного запуска цепочек LCEL с сотнями шагов в производственном контуре).Преимущества LCEL\\ufeffПервоклассная поддержка потоковой передачиДля некоторых цепочек это означает, что токены передаются напрямую из LLM в потоковый парсер вывода. Вы получаете обратно проанализированные, инкрементальные фрагменты вывода с той же скоростью, с которой LLM передает необработанные токены.Поддержка асинхронностиЛюбую цепочку, созданную с помощью LCEL, можно вызвать как с синхронным API (например, с помощью Jupyter-блокнота для прототипирования), так и с асинхронным API (например, на сервере GigaServe).\\nЭто позволяет использовать один и тот же код для прототипов и в эксплуатации, с отличной производительностью и возможностью обработки множества одновременных запросов на одном сервере.Оптимизированное параллельное выполнениеЧтобы задержка была минимальной, шаги цепочки LCEL автоматически выполняются параллельно, если это допустимо (например, для извлечения документов из нескольких ретриверов). Это работает как в синхронных, так и в асинхронных интерфейсах.Повторы и альтернативные путиНастройка повторов и альтернативных путей для любой части цепочки LCEL. Это отличный способ для повышения надежности при масштабировании цепочек.Доступ к промежуточным результатамДля более сложных цепочек полезно иметь доступ к результатам промежуточных шагов до получения окончательного результата.\\nПромежуточные результаты поддерживают потоковую передачи и работают на любом сервере GigaServe.Схемы входных и выходных данныхСхемы входных и выходных данных предоставляют каждой LCEL-цепочке схемы Pydantic и JSONSchema, выведенные из структуры вашей цепочки. Схемы можно использовать для валидации входных и выходных данных. Схемы — это неотъемлемая часть GigaServe.Бесшовная трассировка с LangSmithПо мере усложнения ваших цепочек становится все более важным понимать, что именно происходит на каждом шаге. С LCEL все шаги автоматически записываются в LangSmith для максимальной читаемости и отладки.Бесшовное развертывание GigaServeЛюбую цепочку, созданную с помощью LCEL, можно легко развернуть с помощью GigaServe.Интерфейс Runnable\\ufeffЧтобы упростить создание пользовательских цепочек, мы реализовали протокол \"Runnable\". Многие компоненты GigaChain реализуют протокол Runnable, включая чат-модели, LLM, парсеры вывода, ретриверы, шаблоны промптов и многое другое. Существуют также несколько полезных примитивов для работы с Runnable, которые описаны ниже.Runnable — это стандартный интерфейс, который упрощает определение пользовательских цепочек, а также их вызов стандартным способом.\\nСтандартный интерфейс включает:stream — потоковая передача фрагментов ответа;invoke — вызов цепочки с входными данными;batch — вызов цепочки со списком входных данных.Эти методы также имеют соответствующие асинхронные версии, которые для параллельного выполнения следует использовать с синтаксисом await библиотеки asyncio :astream — потоковая передача блоков ответа асинхронно;ainvoke — вызов цепочки с входными данными асинхронно;abatch — вызов цепочки со списком входных данных асинхронно;astream_log — потоковая передача промежуточных шагов по мере их выполнения, в дополнение к окончательному ответу;astream_events — beta потоковая передача событий по мере их выполнения в цепочке (введено в gigachain-core версии 0.1.14).Типы входных и выходных данных варьируются в зависимости от компонента:КомпонентТип входных данныхТип выходных данныхПромптСловарьPromptValueЧат-модельОдна строка, список сообщений чата или PromptValueChatMessageLLMОдна строка, список сообщений чата или PromptValueСтрокаПарсер выводаВывод LLM или чат-моделиЗависит от парсераРетриверОдна строкаСписок документовИнструментОдна строка или словарь, в зависимости от инструментаЗависит от инструментаВсе Runnable предоставляют схемы данных для анализа входов и выходов:input_schema — входная модель Pydantic, автоматически сгенерированная из структуры Runnable;output_schema — выходная модель Pydantic, автоматически сгенерированная из структуры Runnable.АрхитектураКомпоненты'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/concepts/overview', 'title': 'Основные понятия | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/concepts/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Основные понятия | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Основные понятияОбновлено 6 августа 2024В этом разделе:Общее описание архитектуры Gigachain.Краткое описание предметно-ориентированного языка LCEL, который используется для создания цепочек GigaChain.Описание основных компонентов.Описание распространенных техник использования языковых моделей, которые можно реализовать с помощью GigaChain.Агент «Продавец телефонов»Архитектура'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/concepts/techniques', 'title': 'Техники использования больших языковых моделей | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/concepts/techniques', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Техники использования больших языковых моделей | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Техники использования больших языковых моделейОбновлено 6 августа 2024Вызов функций/инструментов\\ufeffВ контексте GigaChain термины «вызов инструментов» и «вызов функций» взаимозаменяемы.\\nХотя вызов функций иногда подразумевает выполнение одной функции, при работе с GigaChain подразумевается, что все модели работают так, как будто они могут возвращать несколько вызовов инструментов или функций в каждом сообщении.Вызов инструментов позволяет модели отвечать на заданный запрос, генерируя вывод, который соответствует заданной пользователем схеме.\\nПри этом модель не выполняет каких-то действий.\\nОна генерирует аргументы для инструмента, а решение выполнять инструмент или нет остается за пользователем.\\nНапример, если вы хотите извлечь выходные данные, соответствующий определенной схеме из неструктурированного текста, вы можете предоставить модели инструмент для выполнения этой задачи.\\nТакой инструмент будет принимать параметры, соответствующие нужной схеме, а результат его работы вы сможете рассматривать как итоговый.Вызов инструмента включает название, словарь аргументов и необязательный идентификатор.\\nСловарь аргументов имеет структуру {argument_name: argument_value}.Функциональность вызова функций может отличаться в зависимости от используемой модели.\\nКак правило, она позволяет запросам к LLM включать доступные инструменты и их схемы, а ответы могут включать вызовы этих инструментов.\\nНапример, если у модели есть доступ к инструменту поисковой системы, LLM может обработать запрос пользователя, сначала обратившись к поисковой системе.GigaChain предоставляет стандартизированный интерфейс для вызова инструментов, который не зависит от используемой модели.Стандартный интерфейс включает:ChatModel.bind_tools() — метод, который указывает, какие инструменты доступны модели для вызова.AIMessage.tool_calls — атрибут в сообщении AIMessage, которое возвращает модель. Атрибут используется для доступа к вызовам инструментов, которые запрашивает модель.Извлечение данных\\ufeffВ таблице представлены способы извлечения данных, которые поддерживает GigaChain.\\nТаблица содержит столбцы:Название — название алгоритма извлечения.Тип индекса — тип индекса (если есть), на котором он основан.Использует LLM — использует ли этот метод извлечения LLM.Когда использовать — комментарии о том, когда можно использовать этот метода извлечения.Описание — описание того, что делает этот алгоритм извлечения.НазваниеТип индексаИспользует LLMКогда использоватьОписаниеVectorstoreВекторное хранилищеНетЕсли вы только начинаете и ищете что-то быстрое и простое.Самый простой метод и наиболее подходящий для начала работы. Он включает создание эмбеддингов для каждого фрагмента текстаParentDocumentВекторное хранилище + Хранилище документовНетЕсли ваши страницы содержат много мелких фрагментов разной информации, которые лучше индексируются по отдельности, но лучше извлекаются вместе.Метод включает индексирование нескольких фрагментов для каждого документа. После чего вы ищете фрагменты, которые наиболее похожи в пространстве эмбеддинга, но извлекаете и возвращаете весь родительский документ вместо отдельных фрагментовMulti VectorВекторное хранилище + Хранилище документовИногда во время индексированияЕсли вы можете извлечь из документов информацию, которую считаете более релевантной для индексирования, чем сам текст.Метод включает создание нескольких векторов для каждого документа. Каждый вектор может быть создан множеством способов — примеры включают суммаризацию текста и гипотетические вопросыSelf QueryВекторное хранилищеДаЕсли пользователи задают вопросы, на которые лучше отвечать, извлекая документы на основе метаданных, а не на основе схожести с текстом.Метод использует LLM для преобразования ввода пользователя в: (1) строку для семантического поиска, (2) фильтр по метаданным. Это полезно, так как часто вопросы касаются именно метаданных документов, а не самого их содержанияContextual CompressionЛюбойИногдаЕсли вы обнаруживаете, что извлеченные документы содержат слишком много нерелевантной информации и отвлекают LLM.Метод добавляет этап постобработки поверх другого ретривера и извлекает только наиболее релевантную информацию из документов, которые вернул ретривер. Это можно сделать с помощью эмбеддингов или LLMTime-Weighted VectorstoreВекторное хранилищеНетЕсли у вас есть временные метки, связанные с вашими документами, и вы хотите извлекать самые последние из них.Метод извлекает документы на основе комбинации семантической схожести (как в обычном векторном извлечении) и актуальности (учитывая временные метки индексированных документов)Multi-Query RetrieverЛюбойДаЕсли пользователи задают сложные вопросы, требующие нескольких отдельных фрагментов информации для ответа.Метод использует LLM для генерации нескольких запросов из исходного. Это полезно, когда исходный запрос требует фрагментов информации по нескольким темам для правильного ответа. Генерируя несколько запросов, можно затем извлечь документы для каждой из темEnsembleЛюбойНетЕсли у вас есть несколько методов извлечения и вы хотите попробовать их комбинацию.Метод извлекает документы из нескольких ретриверов и затем комбинирует ихРазделение текста\\ufeffGigaChain предлагает множество различных типов разделителей текста.\\nВсе они содержатся в пакете gigachain-text-splitters.Колонки таблицы:Название — название разделителя текста.Классы — классы, которые реализуют разделитель.Разделяет по — как разделитель делит текст.Добавляет метаданные — добавляет ли этот разделитель метаданные о том, откуда взят каждый фрагмент.Описание — описание разделителя, включая рекомендации по его использованию.НазваниеКлассыРазделяет поДобавляет метаданныеОписаниеРекурсивныйRecursiveCharacterTextSplitter, RecursiveJsonSplitterСписок символов, заданных пользователемРекурсивно разделяет текст, стараясь сохранить связанные части текста рядом друг с другом. Рекомендуется начинать разделение текста с этого способаHTMLHTMLHeaderTextSplitter, HTMLSectionSplitterHTML-специфические символы✅Разделяет текст на основе специфических для HTML символов. В частности, на основе HTML добавляет данные о том, откуда взят каждый фрагментMarkdownMarkdownHeaderTextSplitterСимволы, специфические для Markdown✅Разделяет текст на основе символов, специфических для Markdown. В частности, на основе Markdown добавляет данные о том, откуда взят каждый фрагментКодмножество языковСимволы, специфические для языков программирования (Python, JS)Разделяет текст на основе символов, специфичных для языков программирования. Доступно 15 языковТокенымножество классовТокеныРазделяет текст на основе токенов. Существует несколько различных способов измерения количества токеновСимволыCharacterTextSplitterСимвол, заданный пользователемРазделяет текст на основе символа, заданного пользователем. Один из простейших методовСемантический Chunker (экспериментальный)SemanticChunkerПредложенияСначала разделяет по предложениям. Затем объединяет соседние предложения, если они достаточно семантически похожи. Взято из Greg KamradtИнтеграция: AI21 SemanticAI21SemanticTextSplitterОпределяет различные темы, формирующие цельные фрагменты текста, и разделяет по ним✅КомпонентыМиграция и устранение проблем'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/get-started/installation', 'title': 'Установка | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/get-started/installation', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Установка | Документация для разработчиковЭто полезныйматериал?Это полезный материал?УстановкаОбновлено 20 ноября 2024С 30.10.2024 для работы с GigaChain нужно установить партнерский пакет langchain_gigachat.Если вы уже работали с GigaChain (v0.2.x) или LangChain, ознакомьтесь с разделом Миграция и устранение проблем.\\nИнструкции из раздела помогут подготовить среду для работы с примерами из документации и избежать возможных проблем.В этом разделе описана установка пакета langchain-gigachat.Установка GigaChain\\ufeffДля работы вам понадобится Python версии 3.9 и выше.Для установки GigaChain используйте менеджер пакетов pip:pip install langchain-gigachatПри установке пакета langchain-gigachat автоматически устанавливаются фреймворк LangChain, а также библиотека gigachat, которая позволяет отправлять запросы к разным моделям GigaChat.GigaChainБыстрый старт'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/get-started/quickstart', 'title': 'Быстрый старт | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/get-started/quickstart', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Быстрый старт | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Быстрый стартОбновлено 20 ноября 2024Для работы начала работы:Установите пакет langchain-gigachat.Установите сертификаты минцифры.Настройте авторизацию запросов к GigaChat API.Установка\\ufeffДля установки пакета langchain-gigachat используйте менеджер пакетов pip:pip install langchain-gigachatПосле выполнения команды автоматически устанавливаются фреймворк LangChain и библиотека gigachat, которая позволяет отправлять запросы к разным моделям GigaChat.Настройка авторизации запросов к GigaChat API\\ufeffДля авторизации запросов к GigaChat вам понадобится получить ключ авторизации для работы с GigaChat API.О том как это сделать — в разделах Быстрый старт для физических лиц и Быстрый старт для ИП и юридических лиц.Подробнее о ключе авторизацииКлюч авторизации — строка, полученная в результате кодирования в Base64 клиентского идентификатора (Client ID) и ключа (Client Secret) API. Вы можете использовать готовые данные из личного кабинета или самостоятельно закодировать идентификатор и ключ.Ключ авторизации нужен для получения токена доступа Access token с помощью запроса POST /api/v2/oauth.При этом, если вы хотите протестировать API с помощью консоли в документации, для получения токена доступа потребуются именно идентификатор и ключ, которые используются в качестве логина и пароля соответственно.\\nКонсоль автоматически кодирует их в Base64.Это связано с тем, что запрос POST /api/v2/oauth работает по Basic-схеме аутентификации.Передайте ключ авторизации в параметре credentials объекта GigaChat.model = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat\",    streaming=False,    verify_ssl_certs=False,)Объект GigaChat принимает параметры:credentials — ключ авторизации для обмена сообщениями с GigaChat API. О том как получить ключ авторизации — в разделе Быстрый старт.scope — версия API, к которой будет выполнен запрос. Необязательный параметр. Возможные значения:GIGACHAT_API_PERS — версия API для физических лиц;GIGACHAT_API_B2B — версия API для ИП и юрлиц при работе по предоплате.GIGACHAT_API_CORP — версия API для ИП и юрлиц при работе по постоплате.По умолчанию запросы передаются в версию для физических лиц.model — необязательный параметр, в котором можно явно задать модель GigaChat.По умолчанию запросы передаются в модель GigaChat Lite.streaming — необязательный параметр, который включает потоковую передачу токенов.verify_ssl_certs — необязательный параметр, с помощью которого можно отключить проверку сертификатов НУЦ Минцифры.Подробнее о параметрах GigaChat — в репозитории.Ключ авторизации и другие параметры GigaChat можно задать с помощью переменных среды.\\nДля этого используйте переменные с префиксом GIGACHAT:export GIGACHAT_CREDENTIALS=...export GIGACHAT_SCOPE=...export GIGACHAT_VERIFY_SSL_CERTS=FalseУстановка сертификатов минцифры\\ufeffДля обращения к GigaChat в вашем приложении или в вашей операционной системе должны быть установлены сертификаты минцифры.Если нужно вы можете отключить проверку сертификатов с помощью параметра verify_ssl_certs=False.Пример работы\\ufeffПростой пример работы с чатом с помощью модуля GigaChat:\"\"\"Пример обращения к GigaChat с помощью GigaChain\"\"\"from langchain_core.messages import HumanMessage, SystemMessagefrom langchain_gigachat.chat_models import GigaChat# Авторизация в GigaChatmodel = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat\",    # Отключает проверку наличия сертификатов НУЦ Минцифры    verify_ssl_certs=False,)messages = [    SystemMessage(        content=\"Ты эмпатичный бот-психолог, который помогает пользователю решить его проблемы.\"    )]while(True):    user_input = input(\"Пользователь: \")    if user_input == \"пока\":      break    messages.append(HumanMessage(content=user_input))    res = model.invoke(messages)    messages.append(res)    print(\"GigaChat: \", res.content)Смотрите также\\ufeffПотоковая генерация токеновВекторное представление текста (эмбеддинги)УстановкаОбучающие материалы'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/gigagraph/overview', 'title': 'GigaGraph | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/gigagraph/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='GigaGraph | Документация для разработчиковЭто полезныйматериал?Это полезный материал?GigaGraphОбновлено 20 ноября 2024GigaGraph — это библиотека, которая дает возможность работать с большими языковыми моделями (LLM) для создания приложений, которые используют множество взаимодействующих цепочек (акторов) и сохраняют данные о состоянии.\\nТак как в основе GigaGraph лежит GigaChain, предполагается совместное использование обеих библиотек.Основной сценарий использования GigaGraph — добавление циклов в приложения с LLM. Для этого библиотека добавляет в LangChain Expression Language возможность работать с множеством цепочек на каждой из итераций вычислительного цикла.\\nИспользование циклов позволяет реализовать поведение агента, при котором приложению нужно многократно вызывать LLM и спрашивать, какое действие нужно выполнить следующим.Следует отметить, что GigaGraph не предназначена для создания ориентированных ациклических графов (DAG).\\nДля решения этой задачи используйте стандартные возможности LangChain Expression Language.Установка\\ufeffДля установки используйте менеджер пакетов pip:pip install gigagraphБыстрый старт\\ufeffНиже приводится пример разработки агента, использующего вызов функций и несколько моделей.\\nАгент отображает каждое свое состояние в виде отдельных сообщений в списке.В качестве демонстрации работы агента используется поисковый сервис Tavily. Для его работу нужно установить пакет tavily-python.pip install -U gigachain-community gigagraph tavily-pythonТакже для доступа Tavily API нужно задать переменные среды:export TAVILY_API_KEY=tvly-...Для работы с LangSmith задайте переменные:export LANGCHAIN_TRACING_V2=\"true\"export LANGCHAIN_API_KEY=ls__...Подготовьте инструменты\\ufeffВ первую очередь определите инструменты (tools), которые будет использовать приложение.\\nВ качестве примера в этом разделе используется поиск, встроенный в Tavily, но вы также можете использовать собственные инструменты.from langchain_community.tools.tavily_search import TavilySearchResultstools = [TavilySearchResults(max_results=1)]Оберните инструменты в GigaGraph ToolExecutor — класс, который принимает объекты запуска инструмента ToolInvocation, вызывает инструмент и возвращает ответ.\\nОбъект ToolInvocation — произвольный класс с атрибутами tool и tool_input.from langgraph.prebuilt import ToolExecutortool_executor = ToolExecutor(tools)Задайте модель\\ufeffПодключите модель, которую будет использовать приложение.\\nДля демонстрации в описываемом примере модель должна:поддерживать списки сообщений. Каждое свое состояние агент будет возвращать в виде сообщений, поэтому модель должна хорошо работать со списками сообщений;предоставлять интерфейсы вызова функций, аналогичные моделям OpenAI.from langchain_gigachat.chat_models import GigaChat# Параметр streaming=True включает потоковую передачу токенов.# Подробнее в разделе Потоковая передача.model = ChatOpenAI(temperature=0, streaming=True)model = GigaChat(    credentials=\"<ключ_авторизации>\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,    streaming=True,)После подключения убедитесь, что модель знает, какие инструменты доступны ей.\\nДля этого преобразуйте инструменты GigaGraph в формат OpenAI-функций и привяжите их к классу модели.from langchain.tools.render import format_tool_to_openai_functionfunctions = [format_tool_to_openai_function(t) for t in tools]model = model.bind_functions(functions)Определите состояние агента\\ufeffОсновным графом gigagraph является StatefulGraph.\\nЭтот граф параметризован объектом состояния, который он передает каждой вершине.\\nВ свою очередь каждая вершина возвращает операции для обновления состояния.\\nОперации могут либо задавать (SET) определенные атрибуты состояния (например, переписывать существующие значения), либо добавлять (ADD) данные к существующим атрибутам.\\nБудет операция задавать или добавлять данные, определяется аннотациями объекта состояния, который используется для создания графа.В приведенном примере отслеживаемое состояние представлено в виде списка сообщений.\\nПоэтому нужно, чтобы каждая вершина добавляла сообщения в список.Для этого используйте TypedDict с одним ключом (messages) и аннотацией, указывающей на то, что в атрибут messages можно только добавлять данные.from typing import TypedDict, Annotated, Sequenceimport operatorfrom langchain_core.messages import BaseMessageclass AgentState(TypedDict):    messages: Annotated[Sequence[BaseMessage], operator.add]Определите вершины графа\\ufeffТеперь нужно определить несколько разных вершин графа.\\nВ langgraph вершина может быть представлена в виде функции или исполняемого интерфейса.\\nДля описываемого примера понадобятся две основных вершины:Агент, который принимает решения, когда и какие действия нужно выполнять.Функция для вызова инструментов. Если агент решает совершить действие, эта вершина его выполнит.Также нужно определить ребра графа.\\nЧасть ребер могут зависеть от условий (условные ребра).\\nЭто связанно с тем, что, в зависимости от вывода вершины, могут быть реализованы различные пути развития событий.\\nПри этом неизвестно, какой путь будет выбран до момента обращения к вершине.\\nКакой путь выбрать, LLM решает самостоятельно.Разница между обычным и условным ребром графа:В случае условного ребра, после вызова агента:если агент решает предпринять действие, нужно вызвать функцию для обращения к инструментам;если агент решает, что действие завершено, операции должны быть прекращены.В случае обычного ребра после обращения к инструментам, нужно всегда возвращаться к агенту, чтобы он определил дальнейшие действия.Определите вершины и функцию, которая будет решать, какое из условных ребер выполнять.from langgraph.prebuilt import ToolInvocationimport jsonfrom langchain_core.messages import FunctionMessage# Задайте функцию, которая определяет, нужно продолжать или нет.def should_continue(state):    messages = state[\\'messages\\']    last_message = messages[-1]    # Приложение останавливается, если нет вызова функции.    if \"function_call\" not in last_message.additional_kwargs:        return \"end\"    # В противном случае выполнение продолжается.    else:        return \"continue\"# Задайте функцию, которая будет обращаться к модели.def call_model(state):    messages = state[\\'messages\\']    response = model.invoke(messages)    # Возвращается список, который будет добавлен к существующему списку сообщений.    return {\"messages\": [response]}# Задайте функцию, которая будет вызывать инструменты.def call_tool(state):    messages = state[\\'messages\\']    # Благодаря условию continue    # приложение знает, что последнее сообщение содержит вызов функции.    last_message = messages[-1]    # Создание ToolInvocation из function_call.    action = ToolInvocation(        tool=last_message.additional_kwargs[\"function_call\"][\"name\"],        tool_input=json.loads(last_message.additional_kwargs[\"function_call\"][\"arguments\"]),    )    # Вызов tool_executor и получение ответа.    response = tool_executor.invoke(action)    # Использование ответа для создания сообщения FunctionMessage.    function_message = FunctionMessage(content=str(response), name=action.tool)    # Возвращение списка, который будет добавлен к существующему списку сообщений.    return {\"messages\": [function_message]}Определите граф\\ufefffrom langgraph.graph import StateGraph, END# Задайте новый граф.workflow = StateGraph(AgentState)# Задайте две вершины, которые будут работать в цикле.workflow.add_node(\"agent\", call_model)workflow.add_node(\"action\", call_tool)# Задайте точку входа `agent`.# Точка входа указывает вершину, которая будет вызвана в первую очередь.workflow.set_entry_point(\"agent\")# Создайте условное ребро.workflow.add_conditional_edges(    # Определите начальную вершину. В этом примере используется вершина `agent`.    # Это задает ребра, которые будут использованы после вызова вершины `agent`.    \"agent\",    # Передайте функцию, которая определяет какую вершину вызвать дальше.    should_continue,    # Передайте структуру (map), в которой ключами будут строки, а значениями другие вершины.    # END — зарезервированная вершина, указываящая на то, что граф должен завершиться.    # После вызова `should_continue` вывод функции сравнивается с ключами в структуре.    # После чего вызывается соответствующая выводу вершина.    {        # If `tools`, then we call the tool node.        # Если значение `tools`, вызывается вершина, ответственная за обращение к инструментам.        \"continue\": \"action\",        # В противном случае граф заканчивается.        \"end\": END    })# Добавьте обычное ребро, соединяющее вершины `tools` и `agent`.# Ребро задает путь, при котором после вызова вершины `tools`, вызывается вершина `agent`.workflow.add_edge(\\'action\\', \\'agent\\')# Скомпилируйте все предыдущие этапы в исполняемый интерфейс GigaChain.# Теперь граф можно использовать также, как и другие исполняемые интерфейсы.app = workflow.compile()Использование\\ufeffСкомпилированный исполняемый интерфейс принимает на вход список сообщений:from langchain_core.messages import HumanMessageinputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}app.invoke(inputs)Работа интерфейса занимает некоторое время.\\nЧтобы наблюдать за результатом работы в прямом эфире, включите потоковую передачу.Потоковая передача\\ufeffGigaGraph поддерживает несколько разных способов потоковой передачи.Потоковая передача вывода вершины\\ufeffGigaGraph предоставляет возможность потоковой передачи результата вызова каждой из вершин графа по мере обращения к ним.inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}for output in app.stream(inputs):    # stream() возвращает словари с парами `Вершина графа — вывод`.    for key, value in output.items():        print(f\"Output from node \\'{key}\\':\")        print(\"---\")        print(value)    print(\"\\\\n---\\\\n\")Output from node \\'agent\\':---{\\'messages\\': [AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'{\\\\n  \"query\": \"weather in San Francisco\"\\\\n}\\', \\'name\\': \\'tavily_search_results_json\\'}})]}---Output from node \\'action\\':---{\\'messages\\': [FunctionMessage(content=\"[{\\'url\\': \\'https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States\\', \\'content\\': \\'January 2024 Weather History in San Francisco California, United States  Daily Precipitation in January 2024 in San Francisco Observed Weather in January 2024 in San Francisco  San Francisco Temperature History January 2024 Hourly Temperature in January 2024 in San Francisco  Hours of Daylight and Twilight in January 2024 in San FranciscoThis report shows the past weather for San Francisco, providing a weather history for January 2024. It features all historical weather data series we have available, including the San Francisco temperature history for January 2024. You can drill down from year to month and even day level reports by clicking on the graphs.\\'}]\", name=\\'tavily_search_results_json\\')]}---Output from node \\'agent\\':---{\\'messages\\': [AIMessage(content=\"I couldn\\'t find the current weather in San Francisco. However, you can visit [WeatherSpark](https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States) to check the historical weather data for January 2024 in San Francisco.\")]}---Output from node \\'__end__\\':---{\\'messages\\': [HumanMessage(content=\\'what is the weather in sf\\'), AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'{\\\\n  \"query\": \"weather in San Francisco\"\\\\n}\\', \\'name\\': \\'tavily_search_results_json\\'}}), FunctionMessage(content=\"[{\\'url\\': \\'https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States\\', \\'content\\': \\'January 2024 Weather History in San Francisco California, United States  Daily Precipitation in January 2024 in San Francisco Observed Weather in January 2024 in San Francisco  San Francisco Temperature History January 2024 Hourly Temperature in January 2024 in San Francisco  Hours of Daylight and Twilight in January 2024 in San FranciscoThis report shows the past weather for San Francisco, providing a weather history for January 2024. It features all historical weather data series we have available, including the San Francisco temperature history for January 2024. You can drill down from year to month and even day level reports by clicking on the graphs.\\'}]\", name=\\'tavily_search_results_json\\'), AIMessage(content=\"I couldn\\'t find the current weather in San Francisco. However, you can visit [WeatherSpark](https://weatherspark.com/h/m/557/2024/1/Historical-Weather-in-January-2024-in-San-Francisco-California-United-States) to check the historical weather data for January 2024 in San Francisco.\")]}---Потоковая передача токенов\\ufeffБиблиотека дает доступ к потоковой передаче токенов модели по мере их возникновения на каждой из вершин.\\nВ приведенном примере только вершина agent может возвращать токены модели.Функциональность доступна при работе с моделями, которые поддерживают потоковую передачу.inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}async for output in app.astream_log(inputs, include_types=[\"model\"]):    # astream_log() возвращает логи в формате JSONPatch.    for op in output.ops:        if op[\"path\"] == \"/streamed_output/-\":            # Вывод .stream()            ...        elif op[\"path\"].startswith(\"/logs/\") and op[\"path\"].endswith(            \"/streamed_output/-\"        ):            # Токены LLM            print(op[\"value\"])content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'\\', \\'name\\': \\'tavily_search_results_json\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'{\\\\n\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' \\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' \"\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'query\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'\":\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' \"\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'weather\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' in\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' San\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\' Francisco\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'\"\\\\n\\', \\'name\\': \\'\\'}}content=\\'\\' additional_kwargs={\\'function_call\\': {\\'arguments\\': \\'}\\', \\'name\\': \\'\\'}}content=\\'\\'content=\\'\\'content=\\'I\\'content=\"\\'m\"content=\\' sorry\\'content=\\',\\'content=\\' but\\'content=\\' I\\'content=\\' couldn\\'content=\"\\'t\"content=\\' find\\'content=\\' the\\'content=\\' current\\'content=\\' weather\\'content=\\' in\\'content=\\' San\\'content=\\' Francisco\\'content=\\'.\\'content=\\' However\\'content=\\',\\'content=\\' you\\'content=\\' can\\'content=\\' check\\'content=\\' the\\'content=\\' historical\\'content=\\' weather\\'content=\\' data\\'content=\\' for\\'content=\\' January\\'content=\\' \\'content=\\'202\\'content=\\'4\\'content=\\' in\\'content=\\' San\\'content=\\' Francisco\\'content=\\' [\\'content=\\'here\\'content=\\'](\\'content=\\'https\\'content=\\'://\\'content=\\'we\\'content=\\'athers\\'content=\\'park\\'content=\\'.com\\'content=\\'/h\\'content=\\'/m\\'content=\\'/\\'content=\\'557\\'content=\\'/\\'content=\\'202\\'content=\\'4\\'content=\\'/\\'content=\\'1\\'content=\\'/H\\'content=\\'istorical\\'content=\\'-\\'content=\\'Weather\\'content=\\'-in\\'content=\\'-Jan\\'content=\\'uary\\'content=\\'-\\'content=\\'202\\'content=\\'4\\'content=\\'-in\\'content=\\'-S\\'content=\\'an\\'content=\\'-F\\'content=\\'r\\'content=\\'anc\\'content=\\'isco\\'content=\\'-Cal\\'content=\\'ifornia\\'content=\\'-\\'content=\\'United\\'content=\\'-\\'content=\\'States\\'content=\\').\\'content=\\'\\'Область применения\\ufeffИспользуйте библиотеку, когда вам нужна поддержка циклов.Если для решения ваших задач достаточно обычных цепочек, используйте основные возможности LangChain Expression Language.Руководства\\ufeffПриведенные руководства демонстрируют сценарии использования GigaGraph.Асинхронная работа\\ufeffПри работе с асинхронными процессами может потребоваться создание с помощью GigaGraph граф с вершинами, которые будут асинхронными по умолчанию.\\nПример.Потоковая передача токенов\\ufeffОтвет модели может занимать продолжительное время и вам может потребоваться в реальном времени отображать пользователям результат работы модели.\\nПример.Устойчивость\\ufeffGigaGraph позволяет сохранять состояние графа в определенный момент времени и потом возобновлять работу с этого состояния.\\nПример.Человек-в-цикле\\ufeffGigaGraph поддерживает процесс, при котором необходимо участие человека, проверяющего текущее состояние графа перед переходом к следующей вершине.\\nПример такого подхода — в документации.Примеры\\ufeffИсполнитель чат-агента с возможностью вызывать функции\\ufeffПример приложения-исполнителя принимает на вход список сообщений и возвращает список сообщений на выходе.\\nСостояние агента также представлено в виде списка сообщений.\\nПредставленный пример использует вызов функций OpenAI.Getting Started Notebook. Базовый пример, демонстрирующий пошаговое создание приложения исполнителя агентов.High Level Entrypoint. Пример демонстрирует, как можно использовать высокоуровневую точку входа для исполнителя чат-агента.Вариации примеровПримеры небольших изменений, которые можно сделать при разработке исполнителя чат-агента с возможностью вызвать функции.\\nПриведенные вариации основаны на примере Getting Started Notebook.Human-in-the-loop. Пример демонстрирует, как реализовать подход «человек-в-цикле».Принудительный вызов инструмента. Пример демонстрирует, как всегда вызывать определенный инструмент в первую очередь.Ответ в заданном формате. Пример демонстрирует, как принудительно получить ответ агента в заданном формате.Динамический вывод результата использования инструмента. Пример демонстрирует, как агент может самостоятельно решать возвращать результат использования инструмента пользователю или нет.Управление этапами работы агента. Пример демонстрирует, как можно более детально управлять промежуточными этапами работы агента.Исполнители агентов\\ufeffПримеры приложений-исполнителей, использующих агенты LangChain.Getting Started Notebook. Базовый пример, демонстрирующий пошаговое создание приложения исполнителя агентов.High Level Entrypoint. Пример демонстрирует, как можно использовать высокоуровневую точку входа для исполнителя чат-агента.Вариации примеровПримеры небольших изменений, которые можно сделать при разработке исполнителя чат-агента.\\nПриведенные вариации основаны на примере Getting Started Notebook.Human-in-the-loop. Пример демонстрирует, как реализовать подход «человек-в-цикле».Принудительный вызов инструмента. Пример демонстрирует, как всегда вызывать определенный инструмент в первую очередь.Управление этапами работы агента. Пример демонстрирует, как можно более детально управлять промежуточными этапами работы агента.Агент-планировщик\\ufeffБлокноты содержат примеры прототипов архитектуры «планируй и выполняй».\\nПри таком подходе LLM декомпозирует запрос пользователя в программу, после чего исполнитель выполняет ее и в завершении LLM, в зависимости от результата, собирает ответ и/или динамически изменяет план работы.Планирование и выполнение. Пример простого агента, состоящий из: планировщика, который создает многоэтапный список задач, исполнителя, который вызывает доступные инструменты согласно плану, и перепланирощика, который возвращает результат работы или обновляет план действий. Пример основан на работе Plan-and-solve, за авторством Wang, и других.Рассуждения без наблюдений. Пример планировщика, создающего список задач, наблюдения в котором сохраняются как переменные. Переменные могут быть использованы в последующих задачах, чтобы уменьшить необходимость в дальнейшем перепланировании. Пример основан на работе ReWOO, за авторством Xu и других.LLM-компилятор. Задачи передаются потоком и выполняются с целью уменьшения время выполнения инструмента. Пример планировщика, который создает ациклический граф (DAG) задач с переменными ответами. Пример основан на работе за авторством Kim и других.Размышления / самокритика\\ufeffДля повышения качества работы агента, как правило, используют сочетание «самокритики» или «размышлений» языковой модели, а также внешний контроль результатов работы системы. Представленные примеры демонстрируют исследования, которые реализуют такой подход в проектировании.Общие размышления. Пример показывает, как добавить в граф шаг простых «размышлений», подсказывающий системе пересмотреть результат работы.Рефлексия. Пример показывает, как критиковать недостающие и избыточные части ответа агента, чтобы направлять последующие шаги. Пример основан на работе Reflexion за авторством Shinn и других.Поиск по дереву с помощью языкового агента. Пример показывает параллельную работу нескольких агентов, с применением «размышлений» и внешнего положительного подкрепления для организации поиска по дереву Монте-Карло. Пример основан на работе LATS за авторством Zhou и других.Примеры с несколькими агентами\\ufeffСовместная работа нескольких агентов. Пример демонстрирует, как создать двух агентов, которые работают вместе для решения задачи.Несколько агентов с «руководителем». Пример демонстрирует, как организовать работу агентов используя LLM в роли «руководителя», который решает как распределять работу.Иерархичные команды агентов. Пример демонстрирует, как организовать «команды» агентов, которые будут взаимодействовать для решения задачи, в виде вложенных графов.Симуляция для оценки чат-бота\\ufeffОценка работы чат-бота в многоэтапных сценариях может вызывать трудности. Для решения таких задач вы можете использовать симуляции.Оценка чат-бота с помощью симуляции взаимодействия нескольких агентов. В примере показано, как симулировать диалог «виртуального пользователя» с чат-ботом.Справка\\ufeffGigaGraph предоставляет доступ к нескольким новым интерфейсам.StateGraph\\ufeffОсновная точка входа — класс StateGraph.from langgraph.graph import StateGraphКласс ответственный за создание графа.\\nЭтот граф параметризован объектом состояния, который он передает каждой вершине.init\\ufeff    def __init__(self, schema: Type[Any]) -> None:При создании графа нужно передать схему состояния.\\nКаждая вершина будет возвращать операции для обновления этого состояния.\\nОперации могут либо задавать (SET) определенные атрибуты состояния (например, переписывать существующие значения), либо добавлять (ADD) данные к существующим атрибутам.\\nБудет операция задавать или добавлять данные, определяется аннотациями объекта состояния, который используется для создания графа.Схему состояния рекомендуется задавать с помощью типизированного словаря: from typing import TypedDictПосле создания схемы вы можете аннотировать атрибуты с помощью from typing imoport Annotated.\\nСейчас поддерживается только одна аннотация — import operator; operator.add.\\nАннотация указывает, что каждая вершина, которая возвращает этот атрибут, добавляет новые данные к существующему значению.Пример состояния:from typing import TypedDict, Annotated, Unionfrom langchain_core.agents import AgentAction, AgentFinishimport operatorclass AgentState(TypedDict):   # Входная строка.   input: str   # Результат вызова агента.   # Должен принимать `None` в качестве валидного типа, так как это начальное значение.   agent_outcome: Union[AgentAction, AgentFinish, None]   # Список действий и соответствующих шагов.   # Аннотация `operator.add` указывает, что состояние должно дополняться (ADD) новыми данными,   # а не перезаписываться.   intermediate_steps: Annotated[list[tuple[AgentAction, str]], operator.add]Пример использования:# Инициализируйте StateGraph с помощью состояния AgentState.graph = StateGraph(AgentState)# Создайте вершины и ребра...# Скомпилируйте графapp = graph.compile()# На вход должен передаваться словарь, так как состояние создано как TypedDictinputs = {   # Пример входных данных   \"input\": \"hi\"   # Предположим, что `agent_outcome` задается графом как некоторая точка   # Передавать значение не нужно, по умолчанию оно будет None   # Предположим, что граф со временем наполняет `intermediate_steps`   # Передавать значение не нужно, по умолчанию список будет пустым   # Список `intermediate_steps` будет представлен в виде пустого списка, а не None потому,   # что он аннотирован с помощью `operator.add`}.add_node\\ufeff    def add_node(self, key: str, action: RunnableLike) -> None:Добавляет вершину графа.\\nПринимает два параметра:key — уникальная строка с названием вершины;action — действие, которое выполняется при вызове вершины. Выражается в виде функции или исполняемого интерфейса..add_edge\\ufeff    def add_edge(self, start_key: str, end_key: str) -> None:Создает ребро графа, соединяющее начальную и конечную вершины.\\nВывод начальной вершины передается в конечную.\\nПринимает два параметра:start_key — строка с названием начальной вершины. Название вершины должно быть зарегистрировано в графе;end_key — строка с названием конечной вершины. Название вершины должно быть зарегистрировано в графе..add_conditional_edges\\ufeff    def add_conditional_edges(        self,        start_key: str,        condition: Callable[..., str],        conditional_edge_mapping: Dict[str, str],    ) -> None:Создает условное ребро.\\nПозволяет задавать пути развития событий в зависимости от результата вызова начальной вершины.\\nПринимает три параметра:start_key — строка с названием начальной вершины. Название вершины должно быть зарегистрировано в графе;condition — функция, которая вызывается для определения пути развития событий. На вход принимает результат вызова начальной вершины. Возвращает строку, зарегистрированную в структуре conditional_edge_mapping, которая указывает в соответствии с каким ребром будут развиваться события;conditional_edge_mapping — структура (map) строка-строка. В качестве ключа задается название ребра, которое может вернуть condition. В качестве значения задается вершина, которые будет вызваны если condition вернет соответствующее название ребра..set_entry_point\\ufeff    def set_entry_point(self, key: str) -> None:Точка входа в граф.\\nЗадает вершину, которая будет вызвана в самом начале.\\nПринимает один параметр:key — название вершины, которую нужно вызывать в первую очередь..add_conditional_edges\\ufeff    def set_conditional_entry_point(        self,        condition: Callable[..., str],        conditional_edge_mapping: Optional[Dict[str, str]] = None,    ) -> None:Добавляет условную точку входа.\\nПри вызове графа метод проверяет условие (condition: Callable[..., str],), чтобы выбрать начальную вершину.condition. Функция, которую нужно вызвать, чтобы решить, что делать дальше. Входные данные функции используются при запуске графа. Функция должна возвращать строку из conditional_edge_mapping, указывающую на ребро, по которому пойдет выполнение графа.conditional_edge_mapping. Структура данных строка-строка. В качестве ключей задаются строки, которые может вернуть condition. В качестве значения задается вершина, которая будет вызвана при срабатывании условия..set_finish_point\\ufeff    def set_finish_point(self, key: str) -> None:Точка выхода из графа.\\nПри вызове заданной вершины, результат ее работы будет итоговым для графа.\\nПринимает один параметр:key — название вершины, результат вызова который будет считаться итоговым результатом работы графа.Вершину не нужно вызывать, если на предыдущих шагах графа было создано ребро (условное или обычное), ведущее к зарезервированной вершине END.Graph\\ufefffrom langgraph.graph import Graphgraph = Graph()Класс предоставляет доступ к интерфейсу StateGraph, но отличается тем, что объект состояния не обновляется со временем, а класс передает все состояние целиком на каждом этапе.\\nЭто означает, что данные, которые возвращаются в результате работы одной вершины, передаются на вход при вызове другой вершины в исходном состоянии.END\\ufefffrom langgraph.graph import ENDЗарезервированная вершина указывающая на завершение работы графа.\\nВсе данные, которые передаются вершине при вызове, будут считаться результатом работы графа.\\nВершину можно использовать в двух случая:В качестве ключа end_key в add_edge.В качестве значения в структуре conditional_edge_mapping, передаваемой add_conditional_edges.Готовые примеры\\ufeffПредставленные примеры содержат несколько методов, облегчающих работу с распространенными, готовыми графами и компонентами.ToolExecutor\\ufefffrom langgraph.prebuilt import ToolExecutorВспомогательный класс для вызова инструментов.\\nВ качестве параметров класс принимает список инструментов.tools = [...]tool_executor = ToolExecutor(tools)После инициализации класс дает доступ к Runnable-интерфейсу.\\nИспользуйте класс для вызова инструментов. Передайте AgentAction для автоматического определения подходящего инструмента и входных данных.chat_agent_executor.create_function_calling_executor\\ufefffrom langgraph.prebuilt import chat_agent_executorВспомогательная функция для создания графа, который работает с генеративной моделью и может вызывать функции.\\nДля использования функции передайте на вход модель и список инструментов.\\nМодель должна поддерживать интерфейс вызова функций аналогичный OpenAI.from langchain_openai import ChatOpenAIfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langgraph.prebuilt import chat_agent_executorfrom langchain_core.messages import HumanMessagetools = [TavilySearchResults(max_results=1)]model = ChatOpenAI()app = chat_agent_executor.create_function_calling_executor(model, tools)inputs = {\"messages\": [HumanMessage(content=\"какая погода в Саратове\")]}for s in app.stream(inputs):    print(list(s.values())[0])    print(\"----\")create_tool_calling_executor\\ufefffrom langgraph.prebuilt import chat_agent_executorВспомогательная функция для создания графа, который работает с моделью, способной вызывать инструменты.\\nПринимает на вход модель и список инструментов.\\nМодель должна поддерживать вызов инструментов OpenAI.from langchain_openai import ChatOpenAIfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langgraph.prebuilt import chat_agent_executorfrom langchain_core.messages import HumanMessagetools = [TavilySearchResults(max_results=1)]model = ChatOpenAI()app = chat_agent_executor.create_tool_calling_executor(model, tools)inputs = {\"messages\": [HumanMessage(content=\"what is the weather in sf\")]}for s in app.stream(inputs):    print(list(s.values())[0])    print(\"----\")create_agent_executor\\ufefffrom langgraph.prebuilt import create_agent_executorВспомогательная функция для работы с агентами LangChain.\\nДля использования функции передайте на вход агента и список инструментов.from langgraph.prebuilt import create_agent_executorfrom langchain_openai import ChatOpenAIfrom langchain import hubfrom langchain.agents import create_openai_functions_agentfrom langchain_community.tools.tavily_search import TavilySearchResultstools = [TavilySearchResults(max_results=1)]# Подключите шаблон промпта. Вы можете выбрать любой шаблонprompt = hub.pull(\"hwchase17/openai-functions-agent\")# Выберите модель, с которой будет работать агентmodel = ChatOpenAI(model=\"gpt-3.5-turbo-1106\")# Создайте агента OpenAI Functionsagent_runnable = create_openai_functions_agent(model, tools, prompt)app = create_agent_executor(agent_runnable, tools)inputs = {\"input\": \"what is the weather in sf\", \"chat_history\": []}for s in app.stream(inputs):    print(list(s.values())[0])    print(\"----\")GigaServeШаблоны промптов'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/gigaserve', 'title': 'GigaServe | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/gigaserve', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='GigaServe | Документация для разработчиковЭто полезныйматериал?Это полезный материал?GigaServeОбновлено 14 ноября 2024GigaServe — это python-библиотека, которая позволяет размещать цепочки и runnable-интерфейсы GigaChain с предоставлением к ним доступа через REST API.Библиотека GigaServe интегрирована с FastAPI и использует для валидации данных Pydantic.Возможности GigaServe\\ufeffБиблиотека дает следующие возможности:Автоматическое определение схем ввода и вывода основе объекта GigaChain. Схемы применяются для каждого запроса к API и обеспечивают подробные сообщения об ошибках.Страница API-документации с JSONSchema и Swagger.Эндпоинты с поддержкой множества одновременных запросов на одном сервере /invoke, /batch и /stream.Эндпоинт /stream_log для потоковой передачи всех или выбранных промежуточных шагов работы цепочки/агента.Интерактивная песочница /playground с потоковым отображением и демонстрацией промежуточных шагов.Использование проверенных open-source библиотек Python таких, как FastAPI, Pydantic, uvloop и asyncio.Клиентский SDK, который позволяет обращаться к серверу GigaServe также как к локальному runnable-интерфейсу или напрямую с помощью HTTP API.Ограничения\\ufeffКолбэки клиента не поддерживаются для событий, происходящих на сервере.OpenAPI-спецификация не генерируется, если вы используете Pydantic V2. Это связанно с тем, что Fast API не поддерживает смешивание пространств имен pydantic v1 и v2. Подробнее в разделе ниже.Установка\\ufeffДля одновременной установки клиента и сервера используйте команду:pip install \"gigaserve[all]\"Вы можете установить клиент и сервер по отдельности с помощью команд:# Команда установки клиентаpip install \"gigaserve[client]\"# Команда установки сервераpip gigaserve \"langserve[server]\"Примеры\\ufeffДля быстрого старта GigaServe используйте шаблоны GigaChain.Больше примеров шаблонов вы найдете в репозитории.Сервер\\ufeffПример ниже разворачивает чат-модели GigaChat и других LLM, а также цепочку, которая генерирует шутку по заданной теме (topic) с помощью модели Anthropic.#!/usr/bin/env pythonfrom fastapi import FastAPIfrom langchain.prompts import ChatPromptTemplatefrom langchain_gigachat.chat_models import GigaChat, ChatAnthropic, ChatOpenAIfrom langserve import add_routesapp = FastAPI(  title=\"GigaChain Server\",  version=\"1.0\",  description=\"Простой API-сервер, использующий runnable-интерфейсы GigaChain\",)add_routes(    app,    GigaChat(... креды ...),    path=\"/gigachat\",) add_routes(    app,    ChatOpenAI(),    path=\"/openai\",)add_routes(    app,    ChatAnthropic(),    path=\"/anthropic\",)model = ChatAnthropic()prompt = ChatPromptTemplate.from_template(\"расскажи шутку о {topic}\")add_routes(    app,    prompt | model,    path=\"/joke\",)if __name__ == \"__main__\":    import uvicorn    uvicorn.run(app, host=\"localhost\", port=8000)Документация\\ufeffСгенерированная OpenAPI-документация к серверу, развернутому с помощью предыдущего примера, доступна по адресу:curl localhost:8000/docsПри этом, адрес localhost:8000 будет возвращать ошибку 404, пока вы не определите @app.get(\"/\").При использовании pydantic v2 документация не генерируется для эндпоинтов /invoke, /batch, /stream и stream_log.Клиент\\ufeffПример клиента на основе Python SDK:from langchain.schema import SystemMessage, HumanMessagefrom langchain.prompts import ChatPromptTemplatefrom langchain.schema.runnable import RunnableMapfrom langserve import RemoteRunnableopenai = RemoteRunnable(\"http://localhost:8000/openai/\")anthropic = RemoteRunnable(\"http://localhost:8000/anthropic/\")joke_chain = RemoteRunnable(\"http://localhost:8000/joke/\")# Синхронный вызовjoke_chain.invoke({\"topic\": \"попугаи\"})# Асинхронный вызовawait joke_chain.ainvoke({\"topic\": \"попугаи\"})prompt = [    SystemMessage(content=\\'Веди себя как кошка или попугай.\\'),    HumanMessage(content=\\'Привет!\\')]# Поддержка astreamasync for msg in anthropic.astream(prompt):    print(msg, end=\"\", flush=True)prompt = ChatPromptTemplate.from_messages(    [(\"system\", \"Расскажи мне длинную историю о {topic}\")])# Определение собственных цепочекchain = prompt | RunnableMap({    \"openai\": openai,    \"anthropic\": anthropic,})chain.batch([{ \"topic\": \"попугаи\" }, { \"topic\": \"кошки\" }])Клиент, использующий Python-библиотеку requests:import requestsresponse = requests.post(    \"http://localhost:8000/joke/invoke/\",    json={\\'input\\': {\\'topic\\': \\'кошки\\'}})response.json()Использование cURL:curl --location --request POST \\'http://localhost:8000/joke/invoke\\' \\\\    --header \\'Content-Type: application/json\\' \\\\    --data-raw \\'{        \"input\": {            \"topic\": \"кошки\"        }    }\\'Эндпоинты\\ufeffС помощью примера ниже вы можете добавить на сервер заранее подготовленные эндпоинты для работы с runnable-интерфейсами:...add_routes(  app,  runnable,  path=\"/my_runnable\",)Список эндпоинтов:POST /my_runnable/invoke — вызвать runnable-интерфейс для единичных входных данных;POST /my_runnable/batch — вызвать runnable-интерфейс для набора входных данных;POST /my_runnable/stream — вызвать для единичных входных данных с потоковым выводом;POST /my_runnable/stream_log — вызвать для единичных входных данных с потоковым выводом, включая вывод промежуточных шагов по ходу генерации;GET /my_runnable/input_schema — получить JSON-схему входных данных runnable-интерфейса;GET /my_runnable/output_schema — получить JSON-схему выходных данных runnable-интерфейса;GET /my_runnable/config_schema — получить JSON-схему параметров конфигурации runnable-интерфейса;Эндпоинты работают в соответствии с LangChain Expression Language interface (LCEL) — DSL для создания цепочек.Песочница\\ufeffСтраница песочницы доступна по адресу /my_runnable/playground. На ней представлен простой интерфейс, который позволяет настроить параметры runnable-интерфейса и сделать запрос к нему с потоковым выводом и демонстрацией промежуточных шагов.Виджеты\\ufeffПесочница поддерживает виджеты и может использоваться для тестирования ваших цепочек с разными входными данными. Обмен конфигурацией цепочки\\ufeffКроме этого, если цепочка может настраиваться, песочница предоставляет задать параметры цепочки и поделиться ссылкой на полученную конфигурацию.Работа с классическими цепочками\\ufeffGigaServe работает как с runnable-интерфейсами (написанным с помощью LangChain Expression Language), так и с классическими цепочками (посредством наследования от Chain).При работе с классическими цепочками учитывайте, что некоторые входные схемы для таких цепочек могут вызывать ошибки, т.к. могут быть некорректными или неполными.\\nТакие ошибки можно предотвратить, если обновить атрибут input_schema таких цепочек в GigaChain.Развертывание\\ufeffНиже описаны способы развертывания на Google Cloud Platforms (GCP) и Azure.Развертывание на GCP\\ufeffДля развертывания на GCP Cloud Run используйте команду:gcloud run deploy [your-service-name] --source . --port 8001 --allow-unauthenticated --region us-central1 --set-env-vars=GIGACHAT_API_KEY=your_keyРазвертывание на Azure\\ufeffВы можете развернуть сервер на Azure с помощью Azure Container Apps:az containerapp up --name [container-app-name] --source . --resource-group [resource-group-name] --environment  [environment-name] --ingress external --target-port 8001 --env-vars=OPENAI_API_KEY=your_keyПодробная информация в официальной документации.Работа с Pydantic\\ufeffGigaServe поддерживает Pydantic 2 с некоторыми ограничениями:При использовании Pydantic V2 документация OpenAPI не генерируется. Это связанно с тем, что Fast API не поддерживает смешивание пространств имен pydantic v1 и v2.GigaChain использует пространство имен версии v1 в Pydantic v2.За исключением указанных ограничений, эндпоинты API, страница песочницы и другие функции должны работать корректно.Дополнительные возможности\\ufeffДобавление аутентификации\\ufeffО том, как добавить аутентификацию на свой сервер GigaServe — в разделах документации FastAPI, посвященных безопасности и использованию связующего ПО.Работа с файлами\\ufeffОбработка файлов — это типичная задача для больших языковых моделей.\\nСуществуют различные архитектурные подходы для решения этой задачи:Файл может быть загружен на сервер с помощью одного эндпоинта и обработан с помощью другого;Файл может быть представлен как в виде бинарного значения, так и в виде ссылки, например, на содержимое файла, размещенное в хранилище s3.Эндпоинт может быть блокирующим или неблокирующим.Сложную обработку можно выделить в отдельный пул процессов. Выбирайте подход в соответствии со своими задачами.GigaServe не поддерживает тип multipart/form-data.\\nДля загрузки бинарного значения файла в runnable-интерфейс используйте кодировку base64.Пример загрузки файла закодированного с помощью base64.Вы также можете загружать файлы с помощью ссылок (например, в хранилище s3) или загружать их на отдельный эндпоинт как multipart/form-data.Настраиваемые типы входных и выходных данных\\ufeffТипы входных и выходных данных определяются для всех runnable-интерфейсов. Они доступны в атрибутах input_schema и output_schema. GigaServe использует эти типы для валидации данных и генерации документации.Вы можете переопределить наследованные типы с помощью метода with_types.Общий пример работы с типами:from typing import Anyfrom fastapi import FastAPIfrom langchain.schema.runnable import RunnableLambdaapp = FastAPI()def func(x: Any) -> int:    \"\"\"Ошибочно заданная функция, которая принимает любые данные, хотя должна принимать int.\"\"\"    return x + 1runnable = RunnableLambda(func).with_types(    input_schema=int,)add_routes(app, runnable)Пользовательские типы\\ufeffДля десериализации данных в pydantic-модель, а не dict, унаследуйтесь от CustomUserType.\\nПри наследовании от этого типа сервер не будет преобразовывать данные в dict, а будет сохранять их как pydantic-модель.from fastapi import FastAPIfrom langchain.schema.runnable import RunnableLambdafrom langserve import add_routesfrom langserve.schema import CustomUserTypeapp = FastAPI()class Foo(CustomUserType):    bar: intdef func(foo: Foo) -> int:    \"\"\"Пример функции, которая ожидает тип Foo, представленный в виде моде pydantic model\"\"\"    assert isinstance(foo, Foo)    return foo.bar# Обратите внимание, что входные и выходные типы наследуются автоматически!# Вам не нужно их указывать# runnable = RunnableLambda(func).with_types( # <-- Не нужно в данном случае#     input_schema=Foo,#     output_schema=int,#add_routes(app, RunnableLambda(func), path=\"/foo\")Тип CustomUserType поддерживается только на стороне сервера и определяет поведение при декодировании данных.Виджеты песочницы\\ufeffНа странице песочницы вы можете создавать различные виджеты, демонстрирующие работу runnable-интерфейсов вашего бекенда.Виджет задается на уровне поля и поставляется как часть JSON-схемы вводного типа.Виджет должен содержать ключ type, значением которого является один из известного списка виджетов.Другие ключи виджета будут связаны со значениями, описывающими пути в JSON-объекте.Общая схема:type JsonPath = number | string | (number | string)[];type NameSpacedPath = { title: string; path: JsonPath }; // title используется для имитации JSON-схемы, но можно использовать namespacetype OneOfPath = { oneOf: JsonPath[] };type Widget = {    type: string // Какой-то хорошо известный тип, например, base64file, chat и др.    [key: string]: JsonPath | NameSpacedPath | OneOfPath;};Виджет загрузки файла\\ufeffВиджет позволяет загружать файлы в интерфейсе песочницы. Работает для файлов в виде base64-строки.Фрагмент примера:try:    from pydantic.v1 import Fieldexcept ImportError:    from pydantic import Fieldfrom langserve import CustomUserType# ВНИМАНИЕ: Наследуйтесь от CustomUserType, а не от BaseModel. В противном случае#            сервер декодирует данные в dict, а не модель pydantic.class FileProcessingRequest(CustomUserType):    \"\"\"Request including a base64 encoded file.\"\"\"    # Дополнительное поле используется, чтобы задать виджет в интерфейсе интерактивной страницы.    file: str = Field(..., extra={\"widget\": {\"type\": \"base64file\"}})    num_chars: int = 100Подробный пример загрузки файла.Виджет чата\\ufeffПример виджета в репозитории.Чтобы задать виджет чата передайте \"type\": \"chat\":Поле input — JSONPath к полю запроса, которое содержит новое входящее сообщение.Поле output — JSONPath к полю ответа, которое содержит одно или несколько сообщений.Не указывайте эти поля, если входящие и исходящие данные должны быть представлены в исходном виде.\\nНапример, если нужно представить исходящие данные в виде списка сообщений.Пример:class ChatHistory(CustomUserType):    chat_history: List[Tuple[str, str]] = Field(        ...,        examples=[[(\"human input\", \"ai response\")]],        extra={\"widget\": {\"type\": \"chat\", \"input\": \"question\", \"output\": \"answer\"}},    )    question: strdef _format_to_messages(input: ChatHistory) -> List[BaseMessage]:    \"\"\"Представление вводда в виде списка собщений.\"\"\"    history = input.chat_history    user_input = input.question    messages = []    for human, ai in history:        messages.append(HumanMessage(content=human))        messages.append(AIMessage(content=ai))    messages.append(HumanMessage(content=user_input))    return messagesmodel = ChatOpenAI()chat_model = RunnableParallel({\"answer\": (RunnableLambda(_format_to_messages) | model)})add_routes(    app,    chat_model.with_types(input_type=ChatHistory),    config_keys=[\"configurable\"],    path=\"/chat\",)Включение и отключение эндпоинтов\\ufeffНачиная с версии GigaServe 0.0.33, можно включать и отключать открытые эндпоинты.\\nИспользуйте атрибут enabled_endpoints, если вы хотите предотвратить перезапись эндпонтов при обновлении версии библиотеки.Пример ниже включает варианты эндпоинтов invoke, batch и config_hash.add_routes(app, chain, enabled_endpoints=[\"invoke\", \"batch\", \"config_hashes\"])Пример ниже отключает страницу песочницы для цепочки.add_routes(app, chain, disabled_endpoints=[\"playground\"])Безопасность\\ufeffВ версиях библиотеки 0.0.13—0.0.15 песочница, доступная по адресу /playground, позволяет получить доступ к произвольным файлам на сервере. Такое поведение исправлено в версии библиотеки 0.0.16 и выше.БезопасностьGigaGraph'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/guides/gigachat-phone-seller-agent', 'title': 'Агент «Продавец телефонов» | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/guides/gigachat-phone-seller-agent', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Агент «Продавец телефонов» | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Агент «Продавец телефонов»Обновлено 20 ноября 2024Раздел содержит пример разработки агента, который использует модель GigaChat, чтобы:Рассказывать о доступных моделях телефонов на основе заданной базы данных.Детально описывать характеристики выбранной модели телефона.Оформлять заказы на покупку телефонов.Установка зависимостей\\ufeffДля работы примера установите библиотеку langchain-gigachat:pip install langchain-gigachat langgraphДобавление базы данных и инструментов\\ufeffЧтобы агент мог рассказать пользователю о доступных телефонах, создайте массив с описанием каждой модели:stuff_database = [    {        \"name\": \"iPhone 8 mini\",        \"price\": 300,        \"memory\": 128,        \"ram\": 8,        \"camera\": 12,        \"description\": \"Самая дешевая модель iPhone\",    },    {        \"name\": \"iPhone 14\",        \"price\": 1000,        \"memory\": 128,        \"ram\": 8,        \"camera\": 12,        \"description\": \"Телефон будущего, уже сегодня!\",    },    {        \"name\": \"Samsung Galaxy S23\",        \"price\": 900,        \"memory\": 256,        \"ram\": 12,        \"camera\": 108,        \"description\": \"Камера такая острая, что сможет увидеть даже ваши ошибки\",    },    {        \"name\": \"Google Pixel 7\",        \"price\": 850,        \"memory\": 128,        \"ram\": 8,        \"camera\": 16,        \"description\": \"Для тех, кто хочет получить стоковый Android и хорошие фотки\",    },    {        \"name\": \"OnePlus 9T\",        \"price\": 700,        \"memory\": 128,        \"ram\": 8,        \"camera\": 48,        \"description\": \"Зарядка быстрее, чем ваш кофе\",    },    {        \"name\": \"Xiaomi Mi 12\",        \"price\": 600,        \"memory\": 128,        \"ram\": 6,        \"camera\": 64,        \"description\": \"Бюджетный флагман для ценителей вкуса\",    },    {        \"name\": \"Sony Xperia 3\",        \"price\": 1100,        \"memory\": 256,        \"ram\": 12,        \"camera\": 20,        \"description\": \"Телефон для тех, кто скучал по кнопке для камеры\",    },    {        \"name\": \"Huawei P60\",        \"price\": 800,        \"memory\": 128,        \"ram\": 8,        \"camera\": 50,        \"description\": \"Для любителей ночной съемки и без Google Play\",    },    {        \"name\": \"Nokia 10 PureView\",        \"price\": 750,        \"memory\": 128,        \"ram\": 6,        \"camera\": 48,        \"description\": \"Nokia вернулась, и у нее есть змейка!\",    },    {        \"name\": \"LG Velvet 2\",        \"price\": 650,        \"memory\": 128,        \"ram\": 8,        \"camera\": 32,        \"description\": \"Потому что жизнь хороша\",    },    {        \"name\": \"Asus ROG Phone 6\",        \"price\": 1000,        \"memory\": 512,        \"ram\": 16,        \"camera\": 64,        \"description\": \"Играй как профи, заряжай как новичок\",    },    {        \"name\": \"Motorola Edge Plus\",        \"price\": 700,        \"memory\": 128,        \"ram\": 8,        \"camera\": 108,        \"description\": \"Край к краю, пиксель к пикселю\",    },    {        \"name\": \"Realme X4 Pro\",        \"price\": 450,        \"memory\": 128,        \"ram\": 8,        \"camera\": 48,        \"description\": \"Экономия без потерь в качестве\",    },    {        \"name\": \"Oppo Find X4\",        \"price\": 900,        \"memory\": 256,        \"ram\": 12,        \"camera\": 50,        \"description\": \"Найди X, но без математики\",    },    {        \"name\": \"BlackBerry Secure\",        \"price\": 1200,        \"memory\": 128,        \"ram\": 8,        \"camera\": 12,        \"description\": \"Для тех, кто еще помнит, что такое физическая клавиатура\",    },    {        \"name\": \"Fairphone 4\",        \"price\": 500,        \"memory\": 64,        \"ram\": 4,        \"camera\": 12,        \"description\": \"Этичный выбор для заботливого потребителя\",    },]Добавьте функции, которые агент будет вызывать для работы с базой данных.Чтобы упросить создание функций из python-кода, используйте декоратор @tool.\\nОн преобразует любую функцию в инструмент, доступный модели для вызова.Модель ориентируется как на название и описание функции, так и на описание и типы аргументов возвращаемого значения.\\nЧтобы модель правильно понимала, как нужно использовать инструмент, все значения функции нужно явно указать.from typing import Dictfrom langchain.tools import tool@tooldef get_all_phone_names() -> str:    \"\"\"Возвращает названия моделей всех телефонов через запятую\"\"\"    # Подсвечивает вызов функции зеленым цветом    print(\"\\\\033[92m\" + \"Bot requested get_all_phone_names()\" + \"\\\\033[0m\")    return \", \".join([stuff[\"name\"] for stuff in stuff_database])@tooldef get_phone_data_by_name(name: str) -> Dict:    \"\"\"    Возвращает цену в долларах, характеристики и описание телефона по точному названию модели.    Args:        name (str): Точное название модели телефона.    Returns:        Dict: Словарь с информацией о телефоне (цена, характеристики и описание).    \"\"\"    # Подсвечивает вызов функции зеленым цветом    print(\"\\\\033[92m\" + f\"Bot requested get_phone_data_by_name({name})\" + \"\\\\033[0m\")    for stuff in stuff_database:        if stuff[\"name\"] == name.strip():            return stuff    return {\"error\": \"Телефон с таким названием не найден\"}Добавьте функцию, с помощью которой агент будет создавать заказы:@tooldef create_order(name: str, phone: str) -> None:    \"\"\"    Создает новый заказ на телефон.    Args:        name (str): Название телефона.        phone (str): Телефонный номер пользователя.    Returns:        str: Статус заказа.    \"\"\"    # Подсвечивает вызов функции зеленым цветом    print(\"\\\\033[92m\" + f\"Bot requested create_order({name}, {phone})\" + \"\\\\033[0m\")    print(f\"!!! NEW ORDER !!! {name} {phone}\")С помощью системного промпта опишите роль, которой должна следовать модель:system_prompt = \"Ты бот-продавец телефонов. Твоя задача продать телефон пользователю, получив от него заказ. Если тебе не хватает каких-то данных, запрашивай их у пользователя.\"Чтобы дать модели доступ ко всем инструментам, перечислите их в массиве:tools = [get_all_phone_names, get_phone_data_by_name, create_order]Создание агента\\ufeffПеред созданием агента инициализируйте GigaChat и укажите модель, поддерживающую работу с функциями:from langchain_gigachat.chat_models import GigaChatmodel = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,)Список и описание доступных моделей ищите в разделе Модели GigaChat.Подробнее о работе с функциями с помощью GigaChat API — в разделе Работа с функциями.Для авторизации запросов к GigaChat используйте данные, полученные при создании проекта GigaChat API.Инициализируйте агента и передайте ему экземпляр класса GigaChat, и массив доступных инструментов tools:from langgraph.prebuilt import create_react_agentfrom langgraph.checkpoint.memory import MemorySaveragent = create_react_agent(model,                           tools=tools,                           checkpointer=MemorySaver(),                           state_modifier=system_prompt)Пример разговора с агентом\\ufeffimport timedef chat(thread_id: str):    config = {\"configurable\": {\"thread_id\": thread_id}}    while(True):        rq = input(\"\\\\nHuman: \")        print(\"User: \", rq)        if rq == \"\":            break        resp = agent.invoke({\"messages\": [(\"user\", rq)]}, config=config)        print(\"Assistant: \", resp[\"messages\"][-1].content)        time.sleep(1) # For notebook capabilitychat(\"123\")        User:  Здравствуйте!    Assistant:  Добрый день! Я готов помочь Вам с выбором телефона или ответить на любые Ваши вопросы. Что Вас интересует?        User:  Хочу айфон купить    Assistant:  Отличный выбор! Какую модель iPhone Вы рассматриваете?        User:  А какие есть?    Bot requested get_all_phone_names()    Assistant:  Мы можем предложить следующие модели: iPhone 8 mini, iPhone 14, Samsung Galaxy S23, Google Pixel 7, OnePlus 9T, Xiaomi Mi 12, Sony Xperia 3, Huawei P60, Nokia 10 PureView, LG Velvet 2, Asus ROG Phone 6, Motorola Edge Plus, Realme X4 Pro, Oppo Find X4, BlackBerry Secure, Fairphone 4. Какая из них вас интересует?        User:  Сколько стоит 14?    Bot requested get_phone_data_by_name(iPhone 14)    Assistant:  iPhone 14 стоит 1000 долларов. Устройство оснащено памятью 128 Гб, оперативной памятью объемом 8 ГБ и камерой на 12 Мп. Это действительно впечатляющий смартфон!        User:  А 8 мини?    Bot requested get_phone_data_by_name(iPhone 8 mini)    Assistant:  iPhone 8 mini можно приобрести за 300 долларов. Он имеет память 128 Гб, оперативную память 8 ГБ и камеру на 12 Мп. Это самый доступный вариант среди iPhone.        User:  Я бы хотел 14 купить, но он слишком дорогой. Поэтому оформите мне заказ на 8    Bot requested create_order(iPhone 8 mini, ваш номер телефона)    !!! NEW ORDER !!! iPhone 8 mini ваш номер телефона    Assistant:  Ваш заказ на iPhone 8 mini успешно оформлен. Ожидайте доставку в ближайшее время.Создание агентаОсновные понятия'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/how-to/self-query', 'title': 'Работа самозапрашивающего ретривера | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/how-to/self-query', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Работа самозапрашивающего ретривера | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Работа самозапрашивающего ретривераОбновлено 20 ноября 2024Самозапрашивающий ретривер — это ретривер, способный обращаться к самому себе.\\nТакой ретривер принимает запрос на естественном языке, преобразует его в структурированный запрос с помощью LLM-цепочки, после чего применят полученный запрос к заданному векторному хранилищу.\\nЭто позволяет ретриверу как использовать запрос пользователя для семантического поиска по содержимому документов, так и применять извлеченные из запроса фильтры по метаданным хранимых документов.Начало работы\\ufeffДля демонстрации в разделе используется векторное хранилище Chromа и набор документов, которые содержат краткое описание фильмов.Для работы самозапрашивающего ретривера нужно установить пакет lark.Установите необходимые зависимости.pip install --upgrade --quiet lark gigachain-community gigachain-chromafrom langchain_chroma import Chromafrom langchain_gigachat.embeddings import GigaChatEmbeddingsfrom langchain_core.documents import Documentdocs = [    Document(        page_content=\"Трагедия войны глазами солдатской невесты\",        metadata={\"year\": 1957, \"rating\": 8.7, \"genre\": \"драма\"},    ),    Document(        page_content=\"Заурядный семьянин Василий Кузякин заводит роман с эффектной коллегой\",        metadata={\"year\": 1985, \"director\": \"Владимир Меньшов\", \"rating\": 8.2},    ),    Document(        page_content=\"Встреча Алисы и Коли становится началом ярких приключений, в которых они вступят в схватку с космическими пиратами\",        metadata={\"year\": 2024, \"director\": \"Александр Андрющенко\", \"rating\": 7.2},    ),    Document(        page_content=\"Легендарный советский шпионский сериал Татьяны Лиозновой о штандартенфюрере Штирлице\",        metadata={\"year\": 1973, \"director\": \"Татьяна Лиознова\", \"rating\": 8.3},    ),    Document(        page_content=\"Непутевый богатырь случайно упускает орду тугар со всем золотом Ростова и теперь спешит догнать и одолеть варваров\",        metadata={\"year\": 2004, \"genre\": \"мультфильм\"},    ),    Document(        page_content=\"Мистическое путешествие через Зону к комнате, где исполняются желания\",        metadata={            \"year\": 1979,            \"director\": \"Андрей Тарковский\",            \"genre\": \"фантастика\",            \"rating\": 9.9,        },    ),]embedding = GigaChatEmbeddings(    credentials=\"<ключ_авторизации>\",    scope=\"GIGACHAT_API_PERS\",    verify_ssl_certs=False,)vectorstore = Chroma.from_documents(docs, embedding)Создание самозапрашивающего ретривера\\ufeffДобавьте описание фильтров, которые поддерживают документы, и инициализируйте ретривер.from langchain.chains.query_constructor.base import AttributeInfofrom langchain_gigachat.chat_models import GigaChatfrom langchain.retrievers.self_query.base import SelfQueryRetrievermetadata_field_info = [    AttributeInfo(        name=\"genre\",        description=\"Жанр кино или мультфильма. Возможные значения [\\'фантастика\\', \\'комедия\\', \\'драма\\', \\'триллер\\', \\'мелодрама\\', \\'экшн\\', \\'мультфильм\\']\",        type=\"string\",    ),    AttributeInfo(        name=\"year\",        description=\"Год выпуска\",        type=\"integer\",    ),    AttributeInfo(        name=\"director\",        description=\"Имя режиссера\",        type=\"string\",    ),    AttributeInfo(        name=\"rating\",        description=\"Рейтинг кино или мультфильма от 1 до 10\",        type=\"float\",    ),]document_content_description = \"Краткое описание кино или мультфильма\"model = GigaChat(    credentials=\"<ключ_авторизации>\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,)retriever = SelfQueryRetriever.from_llm(    model,    vectorstore,    document_content_description,    metadata_field_info,)Использование ретривера\\ufeffТеперь вы можете проверить работу созданного ретривера.# Пример фильтраretriever.invoke(\"Хочу посмотреть фильм с рейтингом больше 8.5\")    [Document(page_content=\\'Трагедия войны глазами солдатской невесты\\', metadata={\\'genre\\': \\'драма\\', \\'rating\\': 8.7, \\'year\\': 1957}), Document(page_content=\\'Мистическое путешествие через Зону к комнате, где исполняются желания\\', metadata={\\'director\\': \\'Андрей Тарковский\\', \\'genre\\': \\'фантастика\\', \\'rating\\': 9.9, \\'year\\': 1979})]# Пример запроса и фильтраretriever.invoke(\"Фильм Татьяны Лиозновой про Штирлица\")    [Document(page_content=\\'Легендарный советский шпионский сериал Татьяны Лиозновой о штандартенфюрере Штирлице\\', metadata={\\'director\\': \\'Татьяна Лиознова\\', \\'rating\\': 8.3, \\'year\\': 1973})]# Пример составного фильтраretriever.invoke(    \"Есть какие-нибудь высокооцененные (с рейтингом выше 8.5) фантастические фильмы?\")    [Document(page_content=\\'Мистическое путешествие через Зону к комнате, где исполняются желания\\', metadata={\\'director\\': \\'Андрей Тарковский\\', \\'genre\\': \\'фантастика\\', \\'rating\\': 9.9, \\'year\\': 1979})]# Пример запроса и составного фильтраretriever.invoke(\"мультфильм про богатыря, который вышел с 1999 по 2007\")    [Document(page_content=\\'Непутевый богатырь случайно упускает орду тугар со всем золотом Ростова и теперь спешит догнать и одолеть варваров\\', metadata={\\'genre\\': \\'мультфильм\\', \\'year\\': 2004})]Ограничение количества запрашиваемых документов\\ufeffЧтобы задать количество документов, которые нужно получить, используйте параметр enable_limit=True.retriever = SelfQueryRetriever.from_llm(    model,    vectorstore,    document_content_description,    metadata_field_info,    enable_limit=True,)# Пример релевантного запросаretriever.invoke(\"Один фильм про войну\")    [Document(page_content=\\'Трагедия войны глазами солдатской невесты\\', metadata={\\'genre\\': \\'драма\\', \\'rating\\': 8.7, \\'year\\': 1957})]Создание ретривера с помощью LCEL\\ufeffВы можете переписать свой ретривер с использованием LCEL.\\nРеализация на LCEL даст больше контроля за работой ретривера и информации о том, что происходит «под капотом».Сначала создайте цепочку, которая будет отвечать за формирование запроса.\\nЭта цепочка будет преобразовывать запрос пользователя в структурированный запрос (объект StructuredQuery), который содержит заданные пользователем фильтры.Для создания промпта и парсера в примере используются вспомогательные функции get_query_constructor_prompt() и from_components() соответственно.from langchain.chains.query_constructor.base import (    StructuredQueryOutputParser,    get_query_constructor_prompt,)prompt = get_query_constructor_prompt(    document_content_description,    metadata_field_info,)output_parser = StructuredQueryOutputParser.from_components()query_constructor = prompt | model | output_parserТеперь вы можете посмотреть, какой промпт используется при вызове модели:print(prompt.format(query=\"заглушка\"))    Твоя задача — структурировать запрос пользователя, чтобы он соответствовал схеме запроса, представленной ниже.        << Схема структурированного запроса >>    При ответе используйте фрагмент кода markdown с объектом JSON, отформатированным по следующей схеме:        ```json    {        \"query\": string \\\\ текстовая строка для сравнения с содержимым документа        \"filter\": string \\\\ логическое условие для фильтрации документов    }    ```        Строка запроса должна содержать только текст, который ожидается в содержимом документов. Любые условия в фильтре не должны упоминаться в запросе.        Логическое условие состоит из одного или нескольких операторов сравнения и логических операций.        Оператор сравнения имеет форму: `comp(attr, val)`:    - `comp` (eq | ne | gt | gte | lt | lte | contain | like | in | nin): оператор сравнения;    - `attr` (string):  имя атрибута, к которому применяется сравнение;    - `val` (string): значение для сравнения.        Логическая операция имеет форму `op(statement1, statement2, ...)`:    - `op` (and | or | not): логический оператор;    - `statement1`, `statement2`, ... (операторы сравнения или логические операции): одно или несколько утверждений, к которым применяется операция.        Убедитесь, что вы используете только перечисленные выше операторы сравнения и логические операторы и никакие другие.    Убедитесь, что фильтры относятся только к атрибутам, которые существуют в источнике данных.    Убедитесь, что фильтры используют только имена атрибутов с их именами функций, если на них применяются функции.    Убедитесь, что фильтры используют только формат `YYYY-MM-DD` при обработке значений типа данных временной метки.    Убедитесь, что фильтры учитывают описания атрибутов и делают только те сравнения, которые возможны с учетом типа хранимых данных.    Убедитесь, что фильтры используются только по мере необходимости. Если нет фильтров, которые следует применить, верните \"NO_FILTER\" для значения фильтра.        << Пример 1. >>    Источник данных:    ```json    {        \"content\": \"Текст песни\",        \"attributes\": {            \"artist\": {                \"type\": \"string\",                \"description\": \"Имя исполнителя песни\"            },            \"length\": {                \"type\": \"integer\",                \"description\": \"Длительность песни в секундах\"            },            \"genre\": {                \"type\": \"string\",                \"description\": \"Жанр песни, один из \"pop\", \"rock\" или \"rap\"\"            }        }    }    ```        Запрос пользователя:    Какие песни Тейлор Свифт или Кэти Перри о подростковой любви длительностью менее 3 минут в жанре поп?        Структурированный запрос:    ```json    {        \"query\": \"teenager love\",        \"filter\": \"and(or(eq(\\\\\"artist\\\\\", \\\\\"Taylor Swift\\\\\"), eq(\\\\\"artist\\\\\", \\\\\"Katy Perry\\\\\")), lt(\\\\\"length\\\\\", 180), eq(\\\\\"genre\\\\\", \\\\\"pop\\\\\"))\"    }    ```            << Пример 2. >>    Источник данных:    ```json    {        \"content\": \"Текст песни\",        \"attributes\": {            \"artist\": {                \"type\": \"string\",                \"description\": \"Имя исполнителя песни\"            },            \"length\": {                \"type\": \"integer\",                \"description\": \"Длительность песни в секундах\"            },            \"genre\": {                \"type\": \"string\",                \"description\": \"Жанр песни, один из \"pop\", \"rock\" или \"rap\"\"            }        }    }    ```        Запрос пользователя:    Какие песни не были опубликованы на Spotify        Структурированный запрос:    ```json    {        \"query\": \"\",        \"filter\": \"NO_FILTER\"    }    ```            << Пример 3. >>    Источник данных:    ```json    {        \"content\": \"Краткое описание кино или мультфильма\",        \"attributes\": {        \"genre\": {            \"description\": \"Жанр кино или мультфильма. Возможные значения [\\'фантастика\\', \\'комедия\\', \\'драма\\', \\'триллер\\', \\'мелодрама\\', \\'экшн\\', \\'мультфильм\\']\",            \"type\": \"string\"        },        \"year\": {            \"description\": \"Год выпуска\",            \"type\": \"integer\"        },        \"director\": {            \"description\": \"Имя режиссера\",            \"type\": \"string\"        },        \"rating\": {            \"description\": \"Рейтинг кино или мультфильма от 1 до 10\",            \"type\": \"float\"        }    }    }    ```        Запрос пользователя:    заглушка        Структурированный запрос:    Результат работы цепочки:query_constructor.invoke(    {\"query\": \"Научно-фантастические фильмы Андрея Тарковского снятые в семидесятых\"})    StructuredQuery(query=\\'научно-фантастический фильм\\', filter=Operation(operator=<Operator.AND: \\'and\\'>, arguments=[Comparison(comparator=<Comparator.EQ: \\'eq\\'>, attribute=\\'genre\\', value=\\'фантастика\\'), Comparison(comparator=<Comparator.EQ: \\'eq\\'>, attribute=\\'director\\', value=\\'Андрей Тарковский\\'), Comparison(comparator=<Comparator.GTE: \\'gte\\'>, attribute=\\'year\\', value=1970), Comparison(comparator=<Comparator.LTE: \\'lte\\'>, attribute=\\'year\\', value=1979)]), limit=None)Конструктор запросов — ключевой элемент самозапрашивающего ретривера.\\nЧтобы добиться хорошей работы конструктора, зачастую требуется настройка промпта, использование образцов в промпте и описание атрибутов.Другим важным элементом является преобразователь структурированного запроса (транслятор).\\nОн преобразует объект StructuredQuery в фильтр метаданных согласно синтаксису векторного хранилища, которое вы используете.\\nGigaChain предоставляет доступ к преобразователям, встроенным в LangChain.\\nПодробнее о них можно прочитать в официальной документации.from langchain.retrievers.self_query.chroma import ChromaTranslatorretriever = SelfQueryRetriever(    query_constructor=query_constructor,    vectorstore=vectorstore,    structured_query_translator=ChromaTranslator(),)retriever.invoke(    \"Есть какие-нибудь высокооцененные (с рейтингом выше 8.5) фантастические фильмы?\")    [Document(page_content=\\'Мистическое путешествие через Зону к комнате, где исполняются желания\\', metadata={\\'director\\': \\'Андрей Тарковский\\', \\'genre\\': \\'фантастика\\', \\'rating\\': 9.9, \\'year\\': 1979})]'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/integrations', 'title': 'Интеграции | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/integrations', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Интеграции | Документация для разработчиковЭто полезныйматериал?Это полезный материал?ИнтеграцииОбновлено 24 мая 2024Так как GigaChain это версия LangChain, с помощью библиотеки вы сможете реализовать различные интеграции:использовать разные LLM;использовать разные чат-модели и модели для создания эмбеддингов;подключить различные загрузчики документов или системы организации памяти;и многое другое.Полный список интеграций — в документации LangChain.Миграция и устранение проблемБезопасность'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/migration', 'title': 'Миграция и устранение проблем | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/migration', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Миграция и устранение проблем | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Миграция и устранение проблемОбновлено 20 ноября 2024С 29.10.2024 GigaChain изменяет способ взаимодействия с LangChain. Теперь GigaChain предоставляет всю функциональность в рамках партнерского пакета langchain-gigachat и перестает быть ответвлением LangChain.Предыдущую версию GigaChain (v0.2.x) вы можете найти в ветке v_2.x_legacy.Для миграции с GigaChain (v0.2.x) и LangChain, и начала использования партнерского пакета, удалите все компоненты библиотек:# Удаление компонентов LangChainpip uninstall langchain langchain-experimental langchain-core langchain-community# Удаление компонентов GigaChainpip uninstall gigachain gigachain-experimental gigachain-core gigachain-communityПосле чего установите пакет langchain-gigachat:pip install langchain-gigachatУстранение проблем\\ufeffЕсли у вас возникли проблемы при работе с GigaChain убедитесь, что:вы используете Python версии 3.9 и выше;у вас установлена последняя версия langchain_gigachat.В любом случае для решения проблемы нужно удалить модули LangChain и повторно установить пакет langchain_gigachat.Модули langchain_hub и langsmith не требуют удаления и переустановки.Техники использования больших языковых моделейИнтеграции'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/overview', 'title': 'GigaChain | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='GigaChain | Документация для разработчиков'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/prompt-templates', 'title': 'Шаблоны промптов | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/prompt-templates', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Шаблоны промптов | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Шаблоны промптовОбновлено 20 ноября 2024При использовании GigaChain вы можете оформлять промпты с помощью шаблонов, которые задаются в отдельных YAML-файлах.Пример шаблона:input_variables: [dataset_size_min, dataset_size_max, subject, examples]output_parser: nulltemplate: \\'Сгенерируй от {dataset_size_min} до {dataset_size_max} синонимов для слова \"{subject}\". Примеры фраз: {examples}. Результат верни в формате JSON-списка без каких-либо пояснений, например, [\"синоним1\", \"синоним2\", \"синоним3\", \"синоним4\"]. Не повторяй фразы из примера и не дублируй фразы.\\'template_format: f-string_type: promptШаблон промптов может содержать поля:input_variables — список переменных, заданных в тексте шаблона промпта. Значения переменных задаются при вызове метода, использующего промпт.Пример:input_variables: [dataset_size_min, dataset_size_max, subject]output_parser — парсер выходных данных, полученных от нейросетевой модели. Используется для дополнительной обработки и структуризации ответов. Значение по умолчанию — null.template — текст шаблона. Может содержать переменные, заданные с помощью фигурных скобок. Переменные, использованные в тексте, должны быть заданы в списке input_variables.Пример:template: \\'Сгенерируй от {dataset_size_min} до {dataset_size_max} синонимов для слова \"{subject}\".\\'template_format — формат данных шаблона. Значение по умолчанию: f-string._type — тип шаблона. Для шаблонов промптов используйте значение prompt.Использование шаблона\\ufeffПример использования шаблона промптов GigaChain:from langchain_gigachat.tools.load_prompt import load_from_giga_hubfrom langchain_gigachat.chat_models import GigaChatfrom langchain.chains import LLMChainmodel = GigaChat(credentials=\"<ключ_авторизации>\")synonyms_with_examples = load_from_giga_hub(\\'lc://prompts/synonyms/synonyms_generation_with_examples.yaml\\')text = prompt.format(dataset_size_min=5,                        dataset_size_max=10,                        subject=\"кошка\",                        examples=\\'[\"кот\", \"котенок\"]\\')Шаблоны с историей сообщений\\ufeffШаблон может содержать не только описание промпта, но и описание диалога.\\nВ диалоге можно задать как шаблон системного промпта, так и шаблон сообщения пользователя.Шаблоны задаются в массиве messages:messages:  # Шаблон системного промпта  - role: system    prompt:      template:   # Шаблон сообщения пользователя  - role: user      prompt:        template: Пример:input_variables: [text]output_parser: nullmessages:  - role: system    prompt:      template: \\'Ты - профессиональный переводчик на русский язык. Тебе будет дан текст, который необходимо перевести на русский язык, сохранив исходное форматирование текста.В ответе необходимо отдать перевод в формате, приведенном ниже.Ты ДОЛЖЕН перевести !все слова.Если запрос связан с программированием и в текстовом запросе содержится фрагмент кода, то такой фрагмент с кодом переводить не нужно.Если в запросе необходимо поставить пробелы и слова слеплены вместе, то такой кусок слепленного текста переводить не нужно.Если в тексте поставлена неправильно пунктуация, то не исправляй ее.Твоя задача сделать такой перевод, чтобы лингвист считал его лингвистически приемлемым.ВАЖНО! В своем ответе НЕ ОТВЕЧАЙ НА ЗАПРОС! В ответе нужно написать !только !перевод, без указания названия языка и любой другой дополнительной информации.    Input Format:Q: hiOutput Format:Q: привет\\'  - role: user    prompt:      template: \\'{text}\\'template_format: f-string_type: chatВерсионирование шаблонов\\ufeffНовые версии шаблонов промптов GigaChain хранятся в отдельных файлах.\\nНапример, hello.yaml → hello_v2.yaml.Это связанно с тем, что шаблоны хранятся отдельно от основной библиотеки GigaChain и загружаются напрямую по ссылке.В своих проектах используйте последние версии шаблонов.GigaGraphОбучающие видео'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/security', 'title': 'Безопасность | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/security', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Безопасность | Документация для разработчиковЭто полезныйматериал?Это полезный материал?БезопасностьОбновлено 24 мая 2024GigaChain позволяет интегрироваться со сторонними ресурсами такими как локальные и удаленные файловые системы, API и базы данных. Такой подход дает разработчикам создавать приложения, комбинирующие возможности больших языковых моделей (LLM) и работу со сторонними ресурсами.Лучшие практики\\ufeffПри разработке таких приложений следуйте лучшим практиками обеспечения безопасности:Ограничивайте права доступа. Предоставляйте приложениям только необходимые права. Расширенные или избыточные права создают угрозы безопасности. В зависимости от функциональности приложения используйте доступы с правами только на чтение, ограничьте доступ к чувствительным данным, запускайте приложение в контейнере.Учитывайте возможность нецелевого использования. При разработке приложения с LLM всегда помните, что сторонние ресурсы могут быть использованы настолько, насколько это позволяют сделать полученные права. Например, если права позволяют удалять данные из базы, лучше учитывать, что LLM с такими правами действительно может удалить данные.Многоуровневая безопасность. Не существует одного способа, который бы обеспечил полную безопасность. Тщательное проектирование цепочки и тонкая настройка не исключают возможных ошибок, которые могут совершать LLM. Поэтому, для обеспечения лучшей безопасности используйте различные подходы. Например, ограничивайте права приложения и запускайте его в контейнере, чтобы обеспечить доступ только к необходимым данным.Несоблюдение описанных практик может привести к:повреждению или утрате данных;несанкционированному доступу к конфиденциальной информации;падению производительности, недоступности критических ресурсов и другим проблемам.Примеры сценариев, которые описывают возможные пути предотвращения проблем:Если у агента есть доступ к файловой системе, пользователь может попросить его удалить файлы, не подлежащие удалению, или вывести содержимое файлов с конфиденциальной информацией. Чтобы избежать этого, ограничьте доступ агента определенной директорией и предоставьте ему права на работу только с теми файлами, с которыми работать безопасно. Рассмотрите возможность запуска приложения в контейнере.Если у агента есть доступ к стороннему API, пользователь может попросить удалить данные в API или передать ему вредоносные данные. Чтобы избежать этого, вы можете ограничить права агента только чтением данных или позволить агенту работать только с теми эндпоинтами, которые не допустят таких операций.Если у агента есть доступ к базе данных, пользователь может попросить удалить или мутировать таблицу. Чтобы избежать этого ограничьте доступ агента к таблицам и рассмотрите возможность выдать агенту учетные данные с доступом только на чтение.При разработке приложений с доступом к различным внешним ресурсам вроде файловых систем, API или базам данных, проконсультируйтесь с ответственными за безопасность в вашей компании, чтобы понять, как лучше обеспечить безопасность ваших приложений.ИнтеграцииGigaServe'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/agents', 'title': 'Создание агента | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/agents', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Создание агента | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Создание агентаОбновлено 20 ноября 2024В разделе рассматриваются следующие основные понятия:Чат-моделиИнструментыАгентыЯзыковые модели просто генерируют текст и не могут выполнять действия.\\nРазработка агентов — это один из основных сценариев использования GigaChain.Агенты — системы, использующие LLM для рассуждений и определения действий, которые нужно предпринять, а также входных данных, которые нужно при этом использовать.Результаты этих действий затем могут быть переданы обратно агенту, чтобы он определил, нужно ли делать что-то еще или можно закончить работу.В разделе приведен пример агента, который может взаимодействовать с несколькими инструментами: локальной базой данных и поисковой системой.\\nС агентом можно вести разговор и наблюдать, как он вызывает инструменты.Пример агента\\ufeffПример ниже содержит код работающего агента, который использует модель для определения того, какой инструмент нужно вызвать.\\nАгент подготовлен для работы с поисковым инструментом и обладает разговорной памятью, что позволяет использовать его в роли развитого чат-бота.Ниже в разделе приводится пошаговый разбор каждого из компонентов агента.# Импортирование необходимой функциональностиfrom langchain_community.chat_models.gigachat import GigaChatfrom langchain_community.tools.tavily_search import TavilySearchResultsfrom langchain_core.messages import HumanMessagefrom langgraph.checkpoint.memory import MemorySaverfrom langgraph.prebuilt import create_react_agent# Создание агента {#sozdanie-agenta2}memory = MemorySaver()model = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,)search = TavilySearchResults(max_results=2)tools = [search]agent_executor = create_react_agent(model, tools, checkpointer=memory)# Использование агентаconfig = {\"configurable\": {\"thread_id\": \"abc100\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Привет! Меня зову Вася. Я живу в Москве\")]},    config,):    print(chunk)    print(\"----\")for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Узнай погоду в моем городе\")]}, config):    print(chunk)    print(\"----\")    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Здравствуйте, Вася! Рада слышать вас. Расскажите, могу ли я вам чем-нибудь помочь?\\', response_metadata={\\'token_usage\\': Usage(prompt_tokens=97, completion_tokens=29, total_tokens=126), \\'model_name\\': \\'GigaChat-Pro:2.2.25.3\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-aad23d97-0cb5-4977-8d2e-b1ce06751157-0\\')]}}    ----    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'tavily_search_results_json\\', \\'arguments\\': {\\'query\\': \\'погода в москве\\'}}}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=140, completion_tokens=23, total_tokens=163), \\'model_name\\': \\'GigaChat-Pro:2.2.25.3\\', \\'finish_reason\\': \\'function_call\\'}, id=\\'run-8989a123-6824-4ae2-839b-77e0290aa584-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'погода в москве\\'}, \\'id\\': \\'fb19fd4f-3bc1-4b7f-9cca-e669ab8d96e4\\', \\'type\\': \\'tool_call\\'}])]}}    ----    {\\'tools\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.gismeteo.ru/weather-moscow-4368/now/\", \"content\": \"\\\\\\\\u0423\\\\\\\\u0437\\\\\\\\u043d\\\\\\\\u0430\\\\\\\\u0439\\\\\\\\u0442\\\\\\\\u0435 \\\\\\\\u0444\\\\\\\\u0430\\\\\\\\u043a\\\\\\\\u0442\\\\\\\\u0438\\\\\\\\u0447\\\\\\\\u0435\\\\\\\\u0441\\\\\\\\u043a\\\\\\\\u0443\\\\\\\\u044e \\\\\\\\u043f\\\\\\\\u043e\\\\\\\\u0433\\\\\\\\u043e\\\\\\\\u0434\\\\\\\\u0443 \\\\\\\\u0432 \\\\\\\\u041c\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u043a\\\\\\\\u0432\\\\\\\\u0435 \\\\\\\\u043d\\\\\\\\u0430 \\\\\\\\u0441\\\\\\\\u0435\\\\\\\\u0433\\\\\\\\u043e\\\\\\\\u0434\\\\\\\\u043d\\\\\\\\u044f \\\\\\\\u0438 \\\\\\\\u043d\\\\\\\\u0430 \\\\\\\\u0431\\\\\\\\u043b\\\\\\\\u0438\\\\\\\\u0436\\\\\\\\u0430\\\\\\\\u0439\\\\\\\\u0448\\\\\\\\u0438\\\\\\\\u0435 \\\\\\\\u0434\\\\\\\\u043d\\\\\\\\u0438. \\\\\\\\u0421\\\\\\\\u043c\\\\\\\\u043e\\\\\\\\u0442\\\\\\\\u0440\\\\\\\\u0438\\\\\\\\u0442\\\\\\\\u0435 \\\\\\\\u043a\\\\\\\\u0430\\\\\\\\u0440\\\\\\\\u0442\\\\\\\\u0443 \\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0430\\\\\\\\u0434\\\\\\\\u043a\\\\\\\\u043e\\\\\\\\u0432, \\\\\\\\u0442\\\\\\\\u0435\\\\\\\\u043c\\\\\\\\u043f\\\\\\\\u0435\\\\\\\\u0440\\\\\\\\u0430\\\\\\\\u0442\\\\\\\\u0443\\\\\\\\u0440\\\\\\\\u044b, \\\\\\\\u0432\\\\\\\\u0435\\\\\\\\u0442\\\\\\\\u0435\\\\\\\\u0440\\\\\\\\u0430 \\\\\\\\u0438 \\\\\\\\u043e\\\\\\\\u0431\\\\\\\\u043b\\\\\\\\u0430\\\\\\\\u0447\\\\\\\\u043d\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0442\\\\\\\\u0438, \\\\\\\\u0430 \\\\\\\\u0442\\\\\\\\u0430\\\\\\\\u043a\\\\\\\\u0436\\\\\\\\u0435 \\\\\\\\u043d\\\\\\\\u043e\\\\\\\\u0432\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0442\\\\\\\\u0438 \\\\\\\\u0438 \\\\\\\\u043f\\\\\\\\u0440\\\\\\\\u0438\\\\\\\\u043c\\\\\\\\u0435\\\\\\\\u0442\\\\\\\\u044b.\"}, {\"url\": \"https://yandex.ru/pogoda/moscow\", \"content\": \"\\\\\\\\u0423\\\\\\\\u0437\\\\\\\\u043d\\\\\\\\u0430\\\\\\\\u0439\\\\\\\\u0442\\\\\\\\u0435 \\\\\\\\u043f\\\\\\\\u0440\\\\\\\\u043e\\\\\\\\u0433\\\\\\\\u043d\\\\\\\\u043e\\\\\\\\u0437 \\\\\\\\u043f\\\\\\\\u043e\\\\\\\\u0433\\\\\\\\u043e\\\\\\\\u0434\\\\\\\\u044b \\\\\\\\u0432 \\\\\\\\u041c\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u043a\\\\\\\\u0432\\\\\\\\u0435 \\\\\\\\u043d\\\\\\\\u0430 \\\\\\\\u0441\\\\\\\\u0435\\\\\\\\u0433\\\\\\\\u043e\\\\\\\\u0434\\\\\\\\u043d\\\\\\\\u044f, \\\\\\\\u0437\\\\\\\\u0430\\\\\\\\u0432\\\\\\\\u0442\\\\\\\\u0440\\\\\\\\u0430 \\\\\\\\u0438 \\\\\\\\u0431\\\\\\\\u043b\\\\\\\\u0438\\\\\\\\u0436\\\\\\\\u0430\\\\\\\\u0439\\\\\\\\u0448\\\\\\\\u0438\\\\\\\\u0435 \\\\\\\\u0434\\\\\\\\u043d\\\\\\\\u0438. \\\\\\\\u0421\\\\\\\\u043c\\\\\\\\u043e\\\\\\\\u0442\\\\\\\\u0440\\\\\\\\u0438\\\\\\\\u0442\\\\\\\\u0435 \\\\\\\\u0442\\\\\\\\u0435\\\\\\\\u043c\\\\\\\\u043f\\\\\\\\u0435\\\\\\\\u0440\\\\\\\\u0430\\\\\\\\u0442\\\\\\\\u0443\\\\\\\\u0440\\\\\\\\u0443, \\\\\\\\u0434\\\\\\\\u0430\\\\\\\\u0432\\\\\\\\u043b\\\\\\\\u0435\\\\\\\\u043d\\\\\\\\u0438\\\\\\\\u0435, \\\\\\\\u0432\\\\\\\\u043b\\\\\\\\u0430\\\\\\\\u0436\\\\\\\\u043d\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0442\\\\\\\\u044c, \\\\\\\\u0441\\\\\\\\u043a\\\\\\\\u043e\\\\\\\\u0440\\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0442\\\\\\\\u044c \\\\\\\\u0432\\\\\\\\u0435\\\\\\\\u0442\\\\\\\\u0440\\\\\\\\u0430 \\\\\\\\u0438 \\\\\\\\u043e\\\\\\\\u0441\\\\\\\\u0430\\\\\\\\u0434\\\\\\\\u043a\\\\\\\\u0438 \\\\\\\\u043d\\\\\\\\u0430 \\\\\\\\u043a\\\\\\\\u0430\\\\\\\\u0440\\\\\\\\u0442\\\\\\\\u0435 \\\\\\\\u0438 \\\\\\\\u0432 \\\\\\\\u0442\\\\\\\\u0430\\\\\\\\u0431\\\\\\\\u043b\\\\\\\\u0438\\\\\\\\u0446\\\\\\\\u0435.\"}]\\', name=\\'tavily_search_results_json\\', tool_call_id=\\'fb19fd4f-3bc1-4b7f-9cca-e669ab8d96e4\\', artifact={\\'query\\': \\'погода в москве\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Погода В Москве Сейчас | Gismeteo\\', \\'url\\': \\'https://www.gismeteo.ru/weather-moscow-4368/now/\\', \\'content\\': \\'Узнайте фактическую погоду в Москве на сегодня и на ближайшие дни. Смотрите карту осадков, температуры, ветера и облачности, а также новости и приметы.\\', \\'score\\': 0.9981613, \\'raw_content\\': None}, {\\'title\\': \\'Прогноз погоды в Москве на 10 дней — Яндекс.Погода\\', \\'url\\': \\'https://yandex.ru/pogoda/moscow\\', \\'content\\': \\'Узнайте прогноз погоды в Москве на сегодня, завтра и ближайшие дни. Смотрите температуру, давление, влажность, скорость ветра и осадки на карте и в таблице.\\', \\'score\\': 0.99698395, \\'raw_content\\': None}], \\'response_time\\': 2.27})]}}    ----    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Погода в Москве сейчас облачная и прохладная. Температура воздуха около 15 градусов по Цельсию.\\', response_metadata={\\'token_usage\\': Usage(prompt_tokens=1744, completion_tokens=29, total_tokens=1773), \\'model_name\\': \\'GigaChat-Pro:2.2.25.3\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-b864e6be-a222-496d-aeab-2da9bea7ad1b-0\\')]}}    ----Ключ авторизации — строка, полученная в результате кодирования в Base64 клиентского идентификатора (Client ID) и ключа (Client Secret) API. Вы можете использовать готовый ключ из личного кабинета или самостоятельно закодировать Client ID и Client Secret.Пример ключа авторизации:MjIzODA0YTktMDU3OC00MTZmLWI4MWYtYzUwNjg3Njk4MzMzOjljMTI2MGQyLTFkNTEtNGRkOS05ZGVhLTBhNjAzZTdjZjQ3Mw==Ключ авторизации, Client ID и Client Secret вы можете получить после создания проекта GigaChat API:для физических лиц;для ИП и юридических лиц.Подготовка к разработке\\ufeffJupyter-блокноты\\ufeffЭто руководство, как и большинство других в документации, использует Jupyter-блокноты. Они отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями: недоступностью API, нетипичным выводом и другими.Подробнее об установке Jupyter — в официальной документации.Установка\\ufeffДля установки GigaChain выполните команды:%%capture --no-stderr%pip install -U langchain-gigachat langgraph langchain-community tavily-pythonПодробнее об установке — в разделе Установка.Tavily\\ufeffВ качестве инструмента в примере используется поисковый движок Tavily.\\nДля работы с ним вам нужно получить и задать ключ API:export TAVILY_API_KEY=\"...\"В Jupyter-блокноте ключ можно использовать так:# Используйте эту ячейку, чтобы задать ключ в блокнотеimport getpassimport osos.environ[\"TAVILY_API_KEY\"] = getpass.getpass()Определение инструментов\\ufeffСначала создайте инструменты, которые будет использовать агент.\\nОсновным инструментом в примере выступает поисковый движок Tavily.\\nGigaChain предоставляет интеграцию для простого использования поисковой системы Tavily в качестве инструмента.from langchain_community.tools.tavily_search import TavilySearchResultssearch = TavilySearchResults(max_results=2)search_results = search.invoke(\"Узнай на weatherapi погоду в Москве\")print(search_results)# Если нужно, вы можете создать другие инструменты.# После создания всех необходимых инструментов# их можно сохранить в списке, к которому можно обращаться позднее.tools = [search]    [{\\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Moscow\\', \\'region\\': \\'Moscow City\\', \\'country\\': \\'Russia\\', \\'lat\\': 55.7522, \\'lon\\': 37.6156, \\'tz_id\\': \\'Europe/Moscow\\', \\'localtime_epoch\\': 1732032969, \\'localtime\\': \\'2024-11-19 19:16\\'}, \\'current\\': {\\'last_updated_epoch\\': 1732032900, \\'last_updated\\': \\'2024-11-19 19:15\\', \\'temp_c\\': 1.1, \\'temp_f\\': 34.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 9.6, \\'wind_kph\\': 15.5, \\'wind_degree\\': 245, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.74, \\'precip_mm\\': 0.02, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 0, \\'feelslike_c\\': -3.2, \\'feelslike_f\\': 26.3, \\'windchill_c\\': -2.4, \\'windchill_f\\': 27.8, \\'heatindex_c\\': 1.7, \\'heatindex_f\\': 35.1, \\'dewpoint_c\\': -0.5, \\'dewpoint_f\\': 31.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.4, \\'gust_kph\\': 21.6}}\"}, {\\'url\\': \\'https://weather.rambler.ru/v-moskve/19-november/\\', \\'content\\': \\'5 ° Реутов. 6 ° Котельники. 4 ° Лыткарино. 4 ° Долгопрудный. Подробный прогноз погоды в Москве на 19 ноября 2024: температура воздуха, ветер, осадки, давление, влажность, а также геомагнитная\\'}]Использование языковых моделей\\ufeffПример ниже показывает как использовать языковую модель для вызова инструментов.\\nКроме моделей GigaChat, GigaChain позволяет использовать и другие модели.# | output: false# | echo: falsefrom langchain_gigachat.chat_models import GigaChatmodel = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,)Для вызова модели передайте ей список сообщений.\\nПо умолчанию ответом будет строка content.from langchain_core.messages import HumanMessageresponse = model.invoke([HumanMessage(content=\"Привет!\")])response.content    \\'Привет! Рад тебя видеть. Как твои дела?\\'Используйте метод .bind_tools, чтобы дать модели знать, к каким инструментам она может обращаться.model_with_tools = model.bind_tools(tools)Сначала, посмотрите как ответит модель на обычное сообщение.\\nОтвет модели можно найти в двух полях ContentString и tool_calls.response = model_with_tools.invoke([HumanMessage(content=\"Привет!\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")    ContentString: Привет! Рад тебя видеть. Как могу быть полезен?    ToolCalls: []Теперь попробуйте вызвать модель с помощью запроса, который предполагает использование инструмента.response = model_with_tools.invoke(    [HumanMessage(content=\"Используй функцию поиска Tavily, чтобы сделать запрос на weatherapi и рассказать о погоде в Москве\")])print(f\"ContentString: {response.content}\")print(f\"ToolCalls: {response.tool_calls}\")    ContentString:     ToolCalls: [{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weatherapi Moscow\\'}, \\'id\\': \\'ac35392b-2b86-4541-bcca-8264c83a1793\\', \\'type\\': \\'tool_call\\'}]Поле ContentString теперь пустое, но по содержимому массива ToolCalls видно, что модель хочет, чтобы вы вызвали инструмент поиска Tavily.Модель не может самостоятельно вызвать инструмент, для этого нужно создать агента.Создание агента\\ufeffДля создания агента используйте LangGraph — инструмент, который предоставляет высокоуровневый интерфейс для создания агентов. LangGraph дает доступ к низкоуровневым инструментам, которые дают полный контроль над логикой работы агента.\\nИнициализируйте агент с моделью и набором инструментов.В агент можно передавать model, а не model_with_tools, т.к. метод create_react_agent самостоятельно вызывает .bind_tools.from langgraph.prebuilt import create_react_agentagent_executor = create_react_agent(model, tools)Запуск агента\\ufeffТеперь вы можете проверить работу агента на нескольких запросах.Сейчас агент не сохраняет информацию о состоянии и не помнит историю взаимодействия с пользователем.В результате работы агент возвращает итоговое состояние, которое кроме выходных данных также содержит все входные данные.\\nКак получить только выходные данные показано в примерах ниже.Посмотрите, как агент отвечает, когда не нужно вызывать инструменты:response = agent_executor.invoke({\"messages\": [HumanMessage(content=\"Привет!\")]})response[\"messages\"]    [HumanMessage(content=\\'Привет!\\', additional_kwargs={}, response_metadata={}, id=\\'23904d42-79c0-4a7a-b057-074af66c0d1e\\'), AIMessage(content=\\'Здравствуйте! Чем могу помочь?\\', additional_kwargs={\\'functions_state_id\\': \\'c6f3aac4-5e7d-46b9-86cb-7ea0545a4691\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=110, completion_tokens=15, total_tokens=125), \\'model_name\\': \\'GigaChat-Pro:1.0.26.15\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-3983b6d5-75d8-4056-8595-055f4e733624-0\\')]Попробуйте обратиться к агенту с запросом, который предполагает вызов инструмента:response = agent_executor.invoke(    {\"messages\": [HumanMessage(content=\"Используй функцию поиска Tavily, чтобы сделать запрос на weatherapi и рассказать о погоде в Москве\")]})response[\"messages\"]    [HumanMessage(content=\\'Используй функцию поиска Tavily, чтобы сделать запрос на weatherapi и рассказать о погоде в Москве\\', additional_kwargs={}, response_metadata={}, id=\\'38d8b3a9-98c1-4953-a446-753f1a161048\\'), AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'tavily_search_results_json\\', \\'arguments\\': {\\'query\\': \\'weatherapi Москва\\'}}, \\'functions_state_id\\': \\'73ea62c8-4d63-44d8-90aa-fd3add771cd1\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=128, completion_tokens=34, total_tokens=162), \\'model_name\\': \\'GigaChat:1.0.26.15\\', \\'finish_reason\\': \\'function_call\\'}, id=\\'run-7c17a3f2-1c47-45b9-ab7f-6d19a207ca57-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weatherapi Москва\\'}, \\'id\\': \\'f0d93f59-f4dc-47e6-9e36-9188d7dfa7f4\\', \\'type\\': \\'tool_call\\'}]), ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'Moscow\\\\\\', \\\\\\'region\\\\\\': \\\\\\'Moscow City\\\\\\', \\\\\\'country\\\\\\': \\\\\\'Russia\\\\\\', \\\\\\'lat\\\\\\': 55.7522, \\\\\\'lon\\\\\\': 37.6156, \\\\\\'tz_id\\\\\\': \\\\\\'Europe/Moscow\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1732034130, \\\\\\'localtime\\\\\\': \\\\\\'2024-11-19 19:35\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1732033800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-11-19 19:30\\\\\\', \\\\\\'temp_c\\\\\\': 1.1, \\\\\\'temp_f\\\\\\': 34.0, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Clear\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/113.png\\\\\\', \\\\\\'code\\\\\\': 1000}, \\\\\\'wind_mph\\\\\\': 9.6, \\\\\\'wind_kph\\\\\\': 15.5, \\\\\\'wind_degree\\\\\\': 245, \\\\\\'wind_dir\\\\\\': \\\\\\'WSW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1007.0, \\\\\\'pressure_in\\\\\\': 29.74, \\\\\\'precip_mm\\\\\\': 0.02, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 86, \\\\\\'cloud\\\\\\': 0, \\\\\\'feelslike_c\\\\\\': -3.2, \\\\\\'feelslike_f\\\\\\': 26.3, \\\\\\'windchill_c\\\\\\': -2.4, \\\\\\'windchill_f\\\\\\': 27.8, \\\\\\'heatindex_c\\\\\\': 1.7, \\\\\\'heatindex_f\\\\\\': 35.1, \\\\\\'dewpoint_c\\\\\\': -0.5, \\\\\\'dewpoint_f\\\\\\': 31.2, \\\\\\'vis_km\\\\\\': 10.0, \\\\\\'vis_miles\\\\\\': 6.0, \\\\\\'uv\\\\\\': 0.0, \\\\\\'gust_mph\\\\\\': 13.4, \\\\\\'gust_kph\\\\\\': 21.6}}\"}, {\"url\": \"https://www.meteosource.com/weather-api-moscow\", \"content\": \"Weather API - Moscow. Real-time, forecast & historical accurate data. At an affordable price, you will receive accurate and reliable data for Moscow (Москва) that you can easily implement into your website or application. We provide weather data globally. Predictions for any GPS or City\"}]\\', name=\\'tavily_search_results_json\\', id=\\'64f7f6fe-ba3a-423f-b390-971ec0fe602d\\', tool_call_id=\\'f0d93f59-f4dc-47e6-9e36-9188d7dfa7f4\\', artifact={\\'query\\': \\'weatherapi Москва\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Weather in Moscow\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Moscow\\', \\'region\\': \\'Moscow City\\', \\'country\\': \\'Russia\\', \\'lat\\': 55.7522, \\'lon\\': 37.6156, \\'tz_id\\': \\'Europe/Moscow\\', \\'localtime_epoch\\': 1732034130, \\'localtime\\': \\'2024-11-19 19:35\\'}, \\'current\\': {\\'last_updated_epoch\\': 1732033800, \\'last_updated\\': \\'2024-11-19 19:30\\', \\'temp_c\\': 1.1, \\'temp_f\\': 34.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 9.6, \\'wind_kph\\': 15.5, \\'wind_degree\\': 245, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.74, \\'precip_mm\\': 0.02, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 0, \\'feelslike_c\\': -3.2, \\'feelslike_f\\': 26.3, \\'windchill_c\\': -2.4, \\'windchill_f\\': 27.8, \\'heatindex_c\\': 1.7, \\'heatindex_f\\': 35.1, \\'dewpoint_c\\': -0.5, \\'dewpoint_f\\': 31.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.4, \\'gust_kph\\': 21.6}}\", \\'score\\': 0.9982992, \\'raw_content\\': None}, {\\'title\\': \\'Meteosource - Weather API for Moscow - current weather and forecast data\\', \\'url\\': \\'https://www.meteosource.com/weather-api-moscow\\', \\'content\\': \\'Weather API - Moscow. Real-time, forecast & historical accurate data. At an affordable price, you will receive accurate and reliable data for Moscow (Москва) that you can easily implement into your website or application. We provide weather data globally. Predictions for any GPS or City\\', \\'score\\': 0.9962638, \\'raw_content\\': None}], \\'response_time\\': 3.98}), AIMessage(content=\\'Погода в Москве по данным WeatherAPI: сейчас облачно, температура воздуха около 1°C. Ветер слабый, направление западное. Давление 1007 мбар, влажность воздуха 86%.\\', additional_kwargs={\\'functions_state_id\\': \\'5991fbe9-05f1-4866-a3d1-d371b58b7537\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=823, completion_tokens=53, total_tokens=876), \\'model_name\\': \\'GigaChat:1.0.26.15\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-8bc71337-ea8c-4049-8a35-d0e8b76d0e22-0\\')]Потоковая передача сообщений\\ufeffВ предыдущих примерах агент вызывается с помощью метода .invoke и возвращает итоговой ответ.\\nЭто может занимать продолжительное время, если агент в процессе работы выполняет множество шагов.\\nДля демонстрации промежуточных результатов вы можете передавать сообщения по мере их возникновения.for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Используй функцию поиска Tavily, чтобы сделать запрос на weatherapi и рассказать о погоде в Москве\")]}):    print(chunk)    print(\"----\")    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'\\', additional_kwargs={\\'function_call\\': {\\'name\\': \\'tavily_search_results_json\\', \\'arguments\\': {\\'query\\': \\'weatherapi Москва\\'}}, \\'functions_state_id\\': \\'a45f74c9-10f3-4efd-b94c-df22d1be543c\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=128, completion_tokens=34, total_tokens=162), \\'model_name\\': \\'GigaChat:1.0.26.15\\', \\'finish_reason\\': \\'function_call\\'}, id=\\'run-021c4daa-dff9-448b-b868-90d4c4591dd0-0\\', tool_calls=[{\\'name\\': \\'tavily_search_results_json\\', \\'args\\': {\\'query\\': \\'weatherapi Москва\\'}, \\'id\\': \\'c0a3aefb-3ce7-4e73-8bc2-4815f1f976e0\\', \\'type\\': \\'tool_call\\'}])]}}    ----    {\\'tools\\': {\\'messages\\': [ToolMessage(content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'Moscow\\\\\\', \\\\\\'region\\\\\\': \\\\\\'Moscow City\\\\\\', \\\\\\'country\\\\\\': \\\\\\'Russia\\\\\\', \\\\\\'lat\\\\\\': 55.7522, \\\\\\'lon\\\\\\': 37.6156, \\\\\\'tz_id\\\\\\': \\\\\\'Europe/Moscow\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1732034130, \\\\\\'localtime\\\\\\': \\\\\\'2024-11-19 19:35\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1732033800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-11-19 19:30\\\\\\', \\\\\\'temp_c\\\\\\': 1.1, \\\\\\'temp_f\\\\\\': 34.0, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Clear\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/113.png\\\\\\', \\\\\\'code\\\\\\': 1000}, \\\\\\'wind_mph\\\\\\': 9.6, \\\\\\'wind_kph\\\\\\': 15.5, \\\\\\'wind_degree\\\\\\': 245, \\\\\\'wind_dir\\\\\\': \\\\\\'WSW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1007.0, \\\\\\'pressure_in\\\\\\': 29.74, \\\\\\'precip_mm\\\\\\': 0.02, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 86, \\\\\\'cloud\\\\\\': 0, \\\\\\'feelslike_c\\\\\\': -3.2, \\\\\\'feelslike_f\\\\\\': 26.3, \\\\\\'windchill_c\\\\\\': -2.4, \\\\\\'windchill_f\\\\\\': 27.8, \\\\\\'heatindex_c\\\\\\': 1.7, \\\\\\'heatindex_f\\\\\\': 35.1, \\\\\\'dewpoint_c\\\\\\': -0.5, \\\\\\'dewpoint_f\\\\\\': 31.2, \\\\\\'vis_km\\\\\\': 10.0, \\\\\\'vis_miles\\\\\\': 6.0, \\\\\\'uv\\\\\\': 0.0, \\\\\\'gust_mph\\\\\\': 13.4, \\\\\\'gust_kph\\\\\\': 21.6}}\"}, {\"url\": \"https://open-meteo.com/en/docs\", \"content\": \"Weather Forecast APIs with weather models from multiple national weather providers, combining the best models for accurate forecasts worldwide. Explore the API documentation to learn more about the available weather models, their origin countries, resolutions, forecast lengths, and update frequencies. Get detailed JSON hourly weather forecasts for up to 7 or 16 days by specifying the\"}]\\', name=\\'tavily_search_results_json\\', id=\\'94eeb125-b2d1-4d68-a7c4-84aaaf8f5e0f\\', tool_call_id=\\'c0a3aefb-3ce7-4e73-8bc2-4815f1f976e0\\', artifact={\\'query\\': \\'weatherapi Москва\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Weather in Moscow\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Moscow\\', \\'region\\': \\'Moscow City\\', \\'country\\': \\'Russia\\', \\'lat\\': 55.7522, \\'lon\\': 37.6156, \\'tz_id\\': \\'Europe/Moscow\\', \\'localtime_epoch\\': 1732034130, \\'localtime\\': \\'2024-11-19 19:35\\'}, \\'current\\': {\\'last_updated_epoch\\': 1732033800, \\'last_updated\\': \\'2024-11-19 19:30\\', \\'temp_c\\': 1.1, \\'temp_f\\': 34.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 9.6, \\'wind_kph\\': 15.5, \\'wind_degree\\': 245, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.74, \\'precip_mm\\': 0.02, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 0, \\'feelslike_c\\': -3.2, \\'feelslike_f\\': 26.3, \\'windchill_c\\': -2.4, \\'windchill_f\\': 27.8, \\'heatindex_c\\': 1.7, \\'heatindex_f\\': 35.1, \\'dewpoint_c\\': -0.5, \\'dewpoint_f\\': 31.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.4, \\'gust_kph\\': 21.6}}\", \\'score\\': 0.977252, \\'raw_content\\': None}, {\\'title\\': \\'️ Docs - Open-Meteo.com\\', \\'url\\': \\'https://open-meteo.com/en/docs\\', \\'content\\': \\'Weather Forecast APIs with weather models from multiple national weather providers, combining the best models for accurate forecasts worldwide. Explore the API documentation to learn more about the available weather models, their origin countries, resolutions, forecast lengths, and update frequencies. Get detailed JSON hourly weather forecasts for up to 7 or 16 days by specifying the\\', \\'score\\': 0.71611935, \\'raw_content\\': None}], \\'response_time\\': 3.9})]}}    ----    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Погода в Москве согласно запросу на WeatherAPI показывает следующие данные: сейчас 19:35, температура воздуха составляет 1,1°C, ощущается как -3,2°C. Направление ветра WSW, скорость 9,6 миль в час. Давление 1007 мб, влажность 86%. Ясно, осадков нет.\\', additional_kwargs={\\'functions_state_id\\': \\'5c2a46a5-b0dc-40db-8842-dcaf36d98006\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=831, completion_tokens=89, total_tokens=920), \\'model_name\\': \\'GigaChat:1.0.26.15\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-2a4c7f8e-5834-4cf3-8186-9ec7051f2ce5-0\\')]}}    ----Потоковая передача токенов\\ufeffКроме сообщений вы также можете использовать потоковую передачу токенов.\\nДля этого используйте метод .astream_events.Метод .astream_events работает в версиях Python 3.11 и выше.async for event in agent_executor.astream_events(    {\"messages\": [HumanMessage(content=\"Используй функцию поиска Tavily, чтобы сделать запрос на weatherapi и рассказать о погоде в Москве\")]},    version=\"v1\",):    kind = event[\"event\"]    if kind == \"on_chain_start\":        if (            event[\"name\"] == \"Agent\"        ):  # Назначается при создании агента с помощью метода `.with_config({\"run_name\": \"Agent\"})`            print(                f\"Starting agent: {event[\\'name\\']} with input: {event[\\'data\\'].get(\\'input\\')}\"            )    elif kind == \"on_chain_end\":        if (            event[\"name\"] == \"Agent\"        ):  # Назначается при создании агента с помощью метода `.with_config({\"run_name\": \"Agent\"})`            print()            print(\"--\")            print(                f\"Done agent: {event[\\'name\\']} with output: {event[\\'data\\'].get(\\'output\\')[\\'output\\']}\"            )    if kind == \"on_chat_model_stream\":        content = event[\"data\"][\"chunk\"].content        if content:            print(content, end=\"|\")    elif kind == \"on_tool_start\":        print(\"--\")        print(            f\"Starting tool: {event[\\'name\\']} with inputs: {event[\\'data\\'].get(\\'input\\')}\"        )    elif kind == \"on_tool_end\":        print(f\"Done tool: {event[\\'name\\']}\")        print(f\"Tool output was: {event[\\'data\\'].get(\\'output\\')}\")        print(\"--\")    --    Starting tool: tavily_search_results_json with inputs: {\\'query\\': \\'weatherapi Москва\\'}    Done tool: tavily_search_results_json    Tool output was: content=\\'[{\"url\": \"https://www.weatherapi.com/\", \"content\": \"{\\\\\\'location\\\\\\': {\\\\\\'name\\\\\\': \\\\\\'Moscow\\\\\\', \\\\\\'region\\\\\\': \\\\\\'Moscow City\\\\\\', \\\\\\'country\\\\\\': \\\\\\'Russia\\\\\\', \\\\\\'lat\\\\\\': 55.7522, \\\\\\'lon\\\\\\': 37.6156, \\\\\\'tz_id\\\\\\': \\\\\\'Europe/Moscow\\\\\\', \\\\\\'localtime_epoch\\\\\\': 1732034130, \\\\\\'localtime\\\\\\': \\\\\\'2024-11-19 19:35\\\\\\'}, \\\\\\'current\\\\\\': {\\\\\\'last_updated_epoch\\\\\\': 1732033800, \\\\\\'last_updated\\\\\\': \\\\\\'2024-11-19 19:30\\\\\\', \\\\\\'temp_c\\\\\\': 1.1, \\\\\\'temp_f\\\\\\': 34.0, \\\\\\'is_day\\\\\\': 0, \\\\\\'condition\\\\\\': {\\\\\\'text\\\\\\': \\\\\\'Clear\\\\\\', \\\\\\'icon\\\\\\': \\\\\\'//cdn.weatherapi.com/weather/64x64/night/113.png\\\\\\', \\\\\\'code\\\\\\': 1000}, \\\\\\'wind_mph\\\\\\': 9.6, \\\\\\'wind_kph\\\\\\': 15.5, \\\\\\'wind_degree\\\\\\': 245, \\\\\\'wind_dir\\\\\\': \\\\\\'WSW\\\\\\', \\\\\\'pressure_mb\\\\\\': 1007.0, \\\\\\'pressure_in\\\\\\': 29.74, \\\\\\'precip_mm\\\\\\': 0.02, \\\\\\'precip_in\\\\\\': 0.0, \\\\\\'humidity\\\\\\': 86, \\\\\\'cloud\\\\\\': 0, \\\\\\'feelslike_c\\\\\\': -3.2, \\\\\\'feelslike_f\\\\\\': 26.3, \\\\\\'windchill_c\\\\\\': -2.4, \\\\\\'windchill_f\\\\\\': 27.8, \\\\\\'heatindex_c\\\\\\': 1.7, \\\\\\'heatindex_f\\\\\\': 35.1, \\\\\\'dewpoint_c\\\\\\': -0.5, \\\\\\'dewpoint_f\\\\\\': 31.2, \\\\\\'vis_km\\\\\\': 10.0, \\\\\\'vis_miles\\\\\\': 6.0, \\\\\\'uv\\\\\\': 0.0, \\\\\\'gust_mph\\\\\\': 13.4, \\\\\\'gust_kph\\\\\\': 21.6}}\"}, {\"url\": \"https://www.cnn.com/2024/11/19/europe/ukraine-russia-atacms-biden-strike-intl/index.html\", \"content\": \"Updated 10:11 AM EST, Tue November 19, 2024 Link Copied! Follow: Russia See your ... Under the updated doctrine, Moscow will consider aggression from any non-nuclear state - but with the\"}]\\' name=\\'tavily_search_results_json\\' tool_call_id=\\'a2ec240c-b31a-45d1-a680-2ce2243272d9\\' artifact={\\'query\\': \\'weatherapi Москва\\', \\'follow_up_questions\\': None, \\'answer\\': None, \\'images\\': [], \\'results\\': [{\\'title\\': \\'Weather in Moscow\\', \\'url\\': \\'https://www.weatherapi.com/\\', \\'content\\': \"{\\'location\\': {\\'name\\': \\'Moscow\\', \\'region\\': \\'Moscow City\\', \\'country\\': \\'Russia\\', \\'lat\\': 55.7522, \\'lon\\': 37.6156, \\'tz_id\\': \\'Europe/Moscow\\', \\'localtime_epoch\\': 1732034130, \\'localtime\\': \\'2024-11-19 19:35\\'}, \\'current\\': {\\'last_updated_epoch\\': 1732033800, \\'last_updated\\': \\'2024-11-19 19:30\\', \\'temp_c\\': 1.1, \\'temp_f\\': 34.0, \\'is_day\\': 0, \\'condition\\': {\\'text\\': \\'Clear\\', \\'icon\\': \\'//cdn.weatherapi.com/weather/64x64/night/113.png\\', \\'code\\': 1000}, \\'wind_mph\\': 9.6, \\'wind_kph\\': 15.5, \\'wind_degree\\': 245, \\'wind_dir\\': \\'WSW\\', \\'pressure_mb\\': 1007.0, \\'pressure_in\\': 29.74, \\'precip_mm\\': 0.02, \\'precip_in\\': 0.0, \\'humidity\\': 86, \\'cloud\\': 0, \\'feelslike_c\\': -3.2, \\'feelslike_f\\': 26.3, \\'windchill_c\\': -2.4, \\'windchill_f\\': 27.8, \\'heatindex_c\\': 1.7, \\'heatindex_f\\': 35.1, \\'dewpoint_c\\': -0.5, \\'dewpoint_f\\': 31.2, \\'vis_km\\': 10.0, \\'vis_miles\\': 6.0, \\'uv\\': 0.0, \\'gust_mph\\': 13.4, \\'gust_kph\\': 21.6}}\", \\'score\\': 0.7923353, \\'raw_content\\': None}, {\\'title\\': \\'Ukraine fires US-made longer-range missiles into Russia for the first ...\\', \\'url\\': \\'https://www.cnn.com/2024/11/19/europe/ukraine-russia-atacms-biden-strike-intl/index.html\\', \\'content\\': \\'Updated 10:11 AM EST, Tue November 19, 2024 Link Copied! Follow: Russia See your ... Under the updated doctrine, Moscow will consider aggression from any non-nuclear state - but with the\\', \\'score\\': 0.23074637, \\'raw_content\\': None}], \\'response_time\\': 3.56}    --    Погода в Москве по данным сервиса Weather API на момент запроса:|        - Город:| Москва    - Страна:| Россия    - Текущее время:| 19:|35 (по московскому времени)    - Температура воздуха:| 1.|1°C (34°F)    - Погодные условия:| Ясно    - Ветер:| 9.|6 миль в час, направление WSW    - Влажность:| 86%    - Давление:| 1007 мб        Для получения более подробного прогноза рекомендую посетить официальный сайт Weather API или воспользоваться другими метеорологическими сервисами.|Добавление памяти\\ufeffДля добавления памяти нужно при вызове агента передать ему чекпойнтер и поле thread_id.\\nС помощью этого поля агент сможет понять, к какому разговору нужно вернуться.from langgraph.checkpoint.memory import MemorySavermemory = MemorySaver()agent_executor = create_react_agent(model, tools, checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Привет! Меня зовут Вася\")]}, config):    print(chunk)    print(\"----\")    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Привет, Вася! Рад знакомству. Чем могу быть полезен?\\', additional_kwargs={\\'functions_state_id\\': \\'9bccea4e-7cf2-424d-b6c6-831bc078868a\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=101, completion_tokens=20, total_tokens=121), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-bdd79550-936b-423a-b382-452f0adba5a9-0\\')]}}    ----for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Как меня зовут?\")]}, config):    print(chunk)    print(\"----\")    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'Тебя зовут Вася.\\', additional_kwargs={\\'functions_state_id\\': \\'d2d4af43-04cb-4b0c-8754-6515d54d3011\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=145, completion_tokens=12, total_tokens=157), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-d0e39541-1513-4cf8-9ce2-efeb1f0ef4d5-0\\')]}}    ----Для начала нового разговора вам достаточно изменить значение thread_id.config = {\"configurable\": {\"thread_id\": \"xyz123\"}}for chunk in agent_executor.stream(    {\"messages\": [HumanMessage(content=\"Как меня зовут?\")]}, config):    print(chunk)    print(\"----\")    {\\'agent\\': {\\'messages\\': [AIMessage(content=\\'К сожалению, я не могу знать вашего имени, если вы его не указали. Если хотите, можете написать свое имя, и я буду обращаться к вам так.\\', additional_kwargs={\\'functions_state_id\\': \\'9f09c19d-2e39-4590-b4a9-e87ae62a652b\\'}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=98, completion_tokens=37, total_tokens=135), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-df1d3d9c-970e-4d73-a772-8535aa5e95e4-0\\')]}}    ----Смотрите также\\ufeffБолее подробную информацию о разработке агентов ищите в документации LangGraph.Векторные хранилища и ретриверыАгент «Продавец телефонов»'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/chatbot', 'title': 'Разработка чат-бота | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/chatbot', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Разработка чат-бота | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Разработка чат-ботаОбновлено 21 ноября 2024Раздел содержит пример разработки чат-бота на основе LLM.\\nЭтот чат-бот может вести беседу и запоминать предыдущие действия пользователя.В примере рассмотрен чат-бот, который для ведения беседы использует только языковую модель.\\nТакже существуют другие способы разработки чат-ботов, которые могут вас заинтересовать:Агенты — чат-боты, которые могут выполнять действия.Здесь вы найдете базовую информацию о разработке чат-ботов, которая будет полезна при работе с приведенными выше разделами.\\nНо, если нужно, вы можете сразу начать с более сложных чат-ботов.Основные компоненты\\ufeffПример чат-бота показывает, как работать с такими компонентами, как:Чат-модели. Чат-боты работают с данными, представленными в виде сообщений, а не в виде необработанного текста. Поэтому для разработки лучше использовать чат-модели, а не текстовые LLM, которые возвращают простой текст.Шаблоны промптов. Шаблоны упрощают создание промптов, которые объединяют стандартные сообщения, ввод пользователя, историю чатов и, если нужно, дополнительный контекст.История чата. История позволяет чат-боту сохранять прошлые взаимодействия с пользователем и учитывать их при ответе на последующие вопросы.Подготовка к разработке\\ufeffJupyter-блокноты\\ufeffЭто руководство, как и большинство других в документации, использует Jupyter-блокноты. Они отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями: недоступностью API, нетипичным выводом и другими.Подробнее об установке jupyter — в официальной документации.Установка\\ufeffДля установки пакетов, которые понадобятся для работы с примером, выполните команду:pip install langchain-gigachat langgraphПодробнее об установке — в разделе Установка.Быстрый старт\\ufeffСначала ознакомьтесь, как использовать языковую модель отдельно.\\nХотя GigaChain поддерживает различные языковые модели, основным преимуществом библиотеки является возможность работы с моделями GigaChat.# | output: false# | echo: falsefrom langchain_gigachat.chat_models import GigaChatmodel = GigaChat(    credentials=\"ключ_аптворизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Max\",    verify_ssl_certs=False,)Объект GigaChat принимает параметры:credentials — ключ авторизации для обмена сообщениями с GigaChat API. О том как получить ключ авторизации — в разделе Быстрый старт.scope — версия API, к которой будет выполнен запрос. Необязательный параметр. Возможные значения:GIGACHAT_API_PERS — версия API для физических лиц;GIGACHAT_API_B2B — версия API для ИП и юрлиц при работе по предоплате.GIGACHAT_API_CORP — версия API для ИП и юрлиц при работе по постоплате.По умолчанию запросы передаются в версию для физических лиц.model — необязательный параметр, в котором можно явно задать модель GigaChat.По умолчанию запросы передаются в модель GigaChat Lite.streaming — необязательный параметр, который включает потоковую передачу токенов.verify_ssl_certs — необязательный параметр, с помощью которого можно отключить проверку сертификатов НУЦ Минцифры.Подробнее о параметрах GigaChat.Попробуйте обратиться к модели напрямую.Объекты ChatModel — это экземпляры Runnable-интерфейса GigaChain.\\nВсе экземпляры Runnable предоставляют стандартный интерфейс для взаимодействия.Так, чтобы обратиться к модели, достаточно вызвать метод .invoke() со списком сообщений.from langchain_core.messages import HumanMessagemodel.invoke([HumanMessage(content=\"Привет! Меня зовут Вася\")])    AIMessage(content=\\'Привет, Вася! Рад знакомству. Чем могу быть полезен?\\', additional_kwargs={}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=19, completion_tokens=16, total_tokens=35), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-9a83bbd9-b2ff-42c4-908b-3318448cc9a0-0\\')Сама модель не сохраняет информацию о состоянии.\\nВ этом можно убедиться, если задать ей дополнительный вопрос:model.invoke([HumanMessage(content=\"Как меня зовут?\")])    AIMessage(content=\\'К сожалению, я не могу знать вашего имени, если вы его не указали. Если хотите, можете написать свое имя, и я буду обращаться к вам так.\\', additional_kwargs={}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=16, completion_tokens=33, total_tokens=49), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-401243a7-252f-4f38-9401-cb315ea8d58f-0\\')Чтобы обойти это ограничение, передайте всю историю разговора в модель:from langchain_core.messages import AIMessagemodel.invoke(    [        HumanMessage(content=\"Привет! Меня зовут Вася\"),        AIMessage(            content=\"Здравствуйте, Вася! Я генеративная языковая модель от Сбера. Готова ответить на ваши вопросы.\"        ),        HumanMessage(content=\"Как меня зовут?\"),    ])    AIMessage(content=\\'Ваше имя — Вася.\\', additional_kwargs={}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=60, completion_tokens=8, total_tokens=68), \\'model_name\\': \\'GigaChat-Max:1.0.26.20\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-a3a735e6-4de2-4b57-99fb-60cf6d622588-0\\')Теперь модель может гораздо точнее отвечать на дополнительные вопросы.Работа с историей сообщений позволяет чат-боту вести разговор.\\nНиже показано, как ее реализовать.Персистенция сообщений\\ufeffВ LangGraph есть встроенный уровень персистентности, который помогает создавать чат-приложения с памятью.from langgraph.checkpoint.memory import MemorySaverfrom langgraph.graph import START, MessagesState, StateGraph# Инизиализируйте графworkflow = StateGraph(state_schema=MessagesState)# Определите функцию, которая вызывает модельdef call_model(state: MessagesState):    response = model.invoke(state[\"messages\"])    return {\"messages\": response}# Задайте вершину графаworkflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)# Добавьте памятьmemory = MemorySaver()app = workflow.compile(checkpointer=memory)Добавьте параметры конфигурации, которые всегда нужно передавать в runnable.\\nКонфигурация не является частью входных данных, но предоставляет полезную информацию.\\nВ примере используется параметр thread_id.config = {\"configurable\": {\"thread_id\": \"abc123\"}}Параметр позволяет реализовать несколько отдельных разговоров в одном приложении.query = \"Привет! Меня зовут Вася.\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()  # вывод содержит все сообщения в состоянии    ================================== Ai Message ==================================        Привет, Вася! Рад знакомству. Чем могу быть полезен?query = \"Как меня зовут?\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        Тебя зовут Вася.Теперь чат-бот запоминает информацию.\\nЕсли вы укажете новый thread_id, то увидите, что чат-бот начал разговор заново.config = {\"configurable\": {\"thread_id\": \"abc234\"}}input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        К сожалению, я не могу знать вашего имени, если вы его не указали. Если хотите, можете написать свое имя, и я буду обращаться к вам так.Но вы всегда можете вернуться к изначальному разговору, так как он сохраняется в базе данных.config = {\"configurable\": {\"thread_id\": \"abc123\"}}input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        Твое имя — Вася.Таким образом чат-бот может вести разговор с несколькими пользователями одновременно.Чтобы поддержать асинхронность, добавьте в вершину call_model асинхронную функцию и используйте метод .ainvoke для запуска приложения:# Асинхронная функция для использования в вершине графа:async def call_model(state: MessagesState):    response = await model.ainvoke(state[\"messages\"])    return {\"messages\": response}# Граф определяется как прежде:workflow = StateGraph(state_schema=MessagesState)workflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)app = workflow.compile(checkpointer=MemorySaver())# Асинхронный вызов:output = await app.ainvoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()Таким образом, ваш чат-бот сможет разговаривать с разными пользователями.Примеры ниже показывают, как использовать шаблон промпта, чтобы расширить и персонализировать данные, которые сохраняет чат-бот.Шаблоны промптов\\ufeffШаблоны промптов помогают преобразовать необработанные данные пользователя в формат, с которым может работать LLM.\\nВ данном случае необработанные данные — это просто сообщение, которое вы передаете в LLM.\\nПопробуйте развить сообщение.Сначала добавьте системное сообщение со своими инструкциями (но все еще принимая сообщения в качестве входных данных).\\nА затем добавьте больше входных данных, помимо сообщений.Для добавления системного сообщения создайте экземпляр ChatPromptTemplate.\\nЧтобы передать все сообщения, используйте MessagesPlaceholder.from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholderprompt = ChatPromptTemplate.from_messages(    [        (            \"system\",            \"Ты личный помощник. Старайся как можно лучше помочь пользователю.\",        ),        MessagesPlaceholder(variable_name=\"messages\"),    ])chain = prompt | modelТеперь можно добавить шаблон в приложение.workflow = StateGraph(state_schema=MessagesState)def call_model(state: MessagesState):    chain = prompt | model    response = chain.invoke(state)    return {\"messages\": response}workflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)Приложение запускается как прежде.config = {\"configurable\": {\"thread_id\": \"abc345\"}}query = \"Привет! Меня зовут Кира.\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        Здравствуйте, Кира! Рад знакомству с вами. Чем могу быть полезен?query = \"Как меня зовут?\"input_messages = [HumanMessage(query)]output = app.invoke({\"messages\": input_messages}, config)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        Ваше имя — Кира.Усложните полученный промпт.\\nПредположим, что шаблон промпта теперь выглядит примерно так:prompt = ChatPromptTemplate.from_messages(    [        (            \"system\",            \"Ты — личный ассистент. Старайся как можно лучше помочь пользователю. Отвечай на все вопросы пользователя на следующем языке: {language}. Не называй своего имени.\",        ),        MessagesPlaceholder(variable_name=\"messages\"),    ])Выше в промпт добавлена новая переменная language.\\nПриложение теперь принимает два параметра messages и language.\\nОбновите состояние приложения, чтобы отразить это.from typing import Sequencefrom langchain_core.messages import BaseMessagefrom langgraph.graph.message import add_messagesfrom typing_extensions import Annotated, TypedDictclass State(TypedDict):    messages: Annotated[Sequence[BaseMessage], add_messages]    language: strworkflow = StateGraph(state_schema=State)def call_model(state: State):    chain = prompt | model    response = chain.invoke(state)    return {\"messages\": [response]}workflow.add_edge(START, \"model\")workflow.add_node(\"model\", call_model)memory = MemorySaver()app = workflow.compile(checkpointer=memory)config = {\"configurable\": {\"thread_id\": \"abc456\"}}query = \"Привет! Меня зовут Вася.\"language = \"Spanish\"input_messages = [HumanMessage(query)]output = app.invoke(    {\"messages\": input_messages, \"language\": language},    config,)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        ¡Hola, Vasya! ¿Cómo estás hoy?Обратите внимание, что состояние приложения сохраняется.\\nТаким образом, если вы не хотите ничего менять, повторно передавать параметр language не нужно.query = \"Как меня зовут?\"input_messages = [HumanMessage(query)]output = app.invoke(    {\"messages\": input_messages},    config,)output[\"messages\"][-1].pretty_print()    ================================== Ai Message ==================================        Te llamas Vasya.Управление историей разговоров\\ufeffПри разработке чат-бота рано или поздно вам понадобится управлять историей разговоров.\\nКак правило, это продиктовано размером контекстного окна модели, в котором перестанут помещаться все сообщения разговора.\\nЧтобы избежать этого, нужно добавить этап, на котором будет ограничиваться размер передаваемых сообщений.При этом, этот этап должен срабатывать до шаблона промпта, но после загрузки предыдущих сообщений из Message History.Для этого перед промптом вы можете добавить шаг, который изменяет содержимое messages соответствующим образом, а затем обернуть полученную цепочку в класс Message History.В LangChain есть несколько встроенных инструментов для управления списком сообщений.\\nВ примере ниже для уменьшения количества сообщений, которые нужно передать в модель, используется функция trim_messages.\\nОна позволяет указать, сколько токенов в истории сообщений нужно сохранить, а также задать другие параметры. Например, всегда ли нужно сохранять системное сообщение и разрешать ли частичные сообщения.from langchain_core.messages import SystemMessage, trim_messagestrimmer = trim_messages(    max_tokens=35,    strategy=\"last\",    token_counter=model,    include_system=True,    allow_partial=False,    start_on=\"human\",)messages = [    SystemMessage(content=\"Ты — личный ассистент\"),    HumanMessage(content=\"Привет! Меня зовут Вася\"),    AIMessage(content=\"Привет!\"),    HumanMessage(content=\"Я люблю шоколадное мороженое\"),    AIMessage(content=\"Здорово\"),    HumanMessage(content=\"Сколько будет 2 + 2\"),    AIMessage(content=\"4\"),    HumanMessage(content=\"Спасибо\"),    AIMessage(content=\"Пожалуйста!\"),    HumanMessage(content=\"Тебе нравится наш разговор?\"),    AIMessage(content=\"Да!\"),]trimmer.invoke(messages)    [SystemMessage(content=\\'Ты — личный ассистент\\'), HumanMessage(content=\\'Сколько будет 2 + 2\\'), AIMessage(content=\\'4\\'), HumanMessage(content=\\'Спасибо\\'), AIMessage(content=\\'Пожалуйста!\\'), HumanMessage(content=\\'Тебе нравится наш разговор?\\'), AIMessage(content=\\'Да!\\')]Потоковая передача\\ufeffПотоковая передача ответа — важная составляющая хорошего пользовательского опыта при разработке чат-ботов.\\nЯзыковые модели могут долго генерировать ответ, поэтому для повышения отзывчивости большинство приложений обрабатывает и отображает каждый токен по мере его генерации.\\nЭто позволяет пользователю видеть прогресс.Для работы с потоковой передачей все цепочки предоставляют метод .stream, в том числе и те, что используют историю сообщений.\\nИспользуйте его, чтобы получить потоковый ответ.config = {\"configurable\": {\"thread_id\": \"abc789\"}}query = \"Привет! Я Вася. Расскажи историю из 100 слов\"language = \"English\"input_messages = [HumanMessage(query)]for chunk, metadata in app.stream(    {\"messages\": input_messages, \"language\": language},    config,    stream_mode=\"messages\",):    if isinstance(chunk, AIMessage):  # Filter to just model responses        print(chunk.content, end=\"|\")    Hello, Vasya!| Once upon a time, there was a little boy named Alex who lived in a small village.| One day, he found an old book hidden in the attic.| The book told stories of magical creatures and faraway lands.| Alex decided to go on an adventure to find these places.| He packed his bag and set off into the unknown.| Along the way, he met many interesting people and saw amazing things.| Finally, after months of traveling, he reached his destination - a beautiful castle surrounded by forests and mountains.| There, he discovered that magic truly existed!||Смотрите также\\ufeffАгенты — чат-боты, которые могут выполнять действия.Разработка простого LLM-приложенияВекторные хранилища и ретриверы'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/llm-chain', 'title': 'Разработка простого LLM-приложения | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/llm-chain', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Разработка простого LLM-приложения | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Разработка простого LLM-приложенияОбновлено 20 ноября 2024В этом разделе показан пример разработки LLM-приложения, которое переводит текст с английского языка на другой язык.\\nИтоговое приложение включает всего один вызов LLM плюс некоторую работу с промптами.\\nЭто довольно простое приложение, но оно показывает, что множество функций можно реализовать только с помощью промптов и вызова LLM.Основные понятия\\ufeffВ разделе рассмотрены следующие основные понятия:использование языковых моделей;использование шаблонов промптов и парсеров вывода;объединение в цепочку шаблона промптов + LLM + парсера вывода с помощью GigaChain;развертывание вашего приложения с GigaServe.Подготовка к разработке\\ufeffJupyter-блокноты\\ufeffЭто руководство, как и большинство других в документации, использует Jupyter-блокноты. Они отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями: недоступностью API, нетипичным выводом и другими.Подробнее об установке jupyter — в официальной документации.Установка\\ufeffДля установки GigaChain выполните команду:pip install langchain-gigachatПодробнее об установке — в разделе Установка.Работа с языковыми моделями\\ufeffВ первую очередь для работы использования GigaChain нужно подключить языковую модель.Хотя GigaChain поддерживает различные языковые модели, основным преимуществом библиотеки является возможность работы с моделями GigaChat.# | output: false# | echo: falsefrom langchain_gigachat.chat_models import GigaChatmodel = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat\",    verify_ssl_certs=False,)Объект GigaChat принимает параметры:credentials — ключ авторизации для обмена сообщениями с GigaChat API. О том, как получить ключ авторизации — в разделе Быстрый старт.scope — необязательный параметр, в котором можно указать версию API, к которой нужно обратиться. Возможные значения:GIGACHAT_API_PERS — версия API для физических лиц;GIGACHAT_API_CORP — версия API для ИП и юрлиц.По умолчанию запросы передаются в версию для физических лиц.model — необязательный параметр, в котором можно явно задать модель GigaChat.verify_ssl_certs — необязательный параметр, с помощью которого можно отключить проверку сертификатов НУЦ Минцифры.Попробуйте обратиться к модели напрямую.Объекты ChatModel — это экземпляры Runnable-интерфейса GigaChain.\\nВсе экземпляры Runnable предоставляют стандартный интерфейс для взаимподействия.Так, чтобы обратиться к модели, достаточно вызвать метод .invoke() со списком сообщений.from langchain_core.messages import HumanMessage, SystemMessagemessages = [    SystemMessage(content=\"Переведи следующее сообщение с русского на английский\"),    HumanMessage(content=\"привет!\"),]model.invoke(messages)    AIMessage(content=\\'Hello!\\', additional_kwargs={}, response_metadata={\\'token_usage\\': Usage(prompt_tokens=24, completion_tokens=3, total_tokens=27), \\'model_name\\': \\'GigaChat:1.0.26.15\\', \\'finish_reason\\': \\'stop\\'}, id=\\'run-18c3ad4a-677f-4a2e-836f-e9751c83f825-0\\')Парсеры вывода OutputParsers\\ufeffОтвет модели возвращается в форме сообщения AIMessage.\\nОн содержит сгенерированный текст и дополнительную информацию, например, количество затраченных токенов.\\nЗачастую для работы достаточно сгенерированного текста.\\nЧтобы получить ответ отдельно, используйте парсер вывода.Импортируйте простой парсер вывода.from langchain_core.output_parsers import StrOutputParserparser = StrOutputParser()Парсер можно использовать отдельно.\\nНапример, вы можете сохранить результат вызова модели и затем передать его в парсер.result = model.invoke(messages)parser.invoke(result)    \\'Hello!\\'Но чаще вам будет нужно соединять в цепочку парсер вывода и модель.\\nВ таких случаях парсер вызывается каждый раз при обращении к цепочке.\\nИтоговая цепочка будет принимать на вход тип данных модели (строку или список сообщений) и возвращать тип данных парсера вывода (строка).Вы можете создать цепочку с помощью оператора |, который используется в GigaChain для собъединения двух и более компонетов.chain = model | parserchain.invoke(messages)    \\'Hello!\\'Шаблоны промптов\\ufeffСейчас список сообщений в примере передается напрямую в модель.\\nСам список сообщений, как правило, формируется логикой приложения из ввода пользователя.\\nОбычно такая логика принимает необработанный ввод и преобразует его в список сообщений, готовых для передачи в языковую модель.\\nТипичные преобразования включают добавление системного сообщения или изменение шаблона с учетом ввода пользователя.Шаблоны промптов (PromptTemplates) — это конструкции GigaChain, которые принимают необработанный ввод пользователя и возвращают данные (промпт), готовые для передачи в языковую модель.Создайте шаблон промпта, который будет принимать две пользовательские переменные:language — язык, на который нужно перевести текст;text — текст для перевода.Для этого импортируйте ChatPromptTemplate:from langchain_core.prompts import ChatPromptTemplateСоздайте строку, которая будет оформлена как системное сообщение:system_template = \"Переведи следующий текст на {language}:\"Теперь вы можете создать шаблон промпта.\\nОн будет состоять из комбинации system_template и шаблона для ввода текста.prompt_template = ChatPromptTemplate.from_messages(    [(\"system\", system_template), (\"user\", \"{text}\")])Входными данными для этого шаблона является словарь.\\nВы можете поэкспериментировать с этим шаблоном, чтобы увидеть, что он делает сам по себе.result = prompt_template.invoke({\"language\": \"английский\", \"text\": \"привет\"})result    ChatPromptValue(messages=[SystemMessage(content=\\'Переведи следующий текст на английский:\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'привет\\', additional_kwargs={}, response_metadata={})])Шаблон возвращает объект ChatPromptValue, который состоит из двух сообщений.\\nДоступ к сообщениям можно получить с помощью метода .to_messages():result.to_messages()    [SystemMessage(content=\\'Переведи следующий текст на английский:\\', additional_kwargs={}, response_metadata={}), HumanMessage(content=\\'привет\\', additional_kwargs={}, response_metadata={})]Соединение всех компонентов вместе\\ufeffТеперь объедините все три компонента вместе: шаблон, модель и парсер вывода с помощью оператора |.chain = prompt_template | model | parserchain.invoke({\"language\": \"английский\", \"text\": \"привет\"})    \\'Hello\\'Это простой пример использования LangChain Expression Language (LCEL) для соединения вместе модулей GigaChain.\\nВ таком подходе есть ряд преимуществ. В частности, он обеспечивает оптимизированную работу с потоковой передачей.Развертывание с GigaServe\\ufeffGigaServe помогает разворачивать цепочки GigaChain в виде REST API.\\nИспользовать GigaServe для работы с GigaChain необязательно.Пример ниже показывает, как вы можете развернуть приложение с помощью GigaServe.\\nПример использует Python-файл, работа с которым выполняется с помощью командной строки.Установка GigaServe:pip install \"gigaserve[all]\"Сервер\\ufeffДля создания сервера для приложения создайте файл serve.py.\\nФайл будет содержать логику для развертывания приложения.\\nФайл состоит из трех частей:Определение цепочки, которую вы создали выше.Приложение FastAPI.Определение пути для доступа к цепочки с помощью langserve.add_routes.#!/usr/bin/env pythonfrom typing import Listfrom fastapi import FastAPIfrom langchain_core.prompts import ChatPromptTemplatefrom langchain_core.output_parsers import StrOutputParserfrom langchain_gigachat.chat_models import GigaChatfrom langserve import add_routes# 1. Создание шаблона промптаsystem_template = \"Переведи следующий текст на {language}:\"prompt_template = ChatPromptTemplate.from_messages([    (\\'system\\', system_template),    (\\'user\\', \\'{text}\\')])# 2. Создание моделиmodel = GigaChat(credentials=\"ключ_авторизации\", scope=\"GIGACHAT_API_PERS\", model=\"GigaChat-Pro\", verify_ssl_certs=False)# 3. Создание парсераparser = StrOutputParser()# 4. Создание цепочкиchain = prompt_template | model | parser# 5. Определение приложенияapp = FastAPI(  title=\"GigaChain Server\",  version=\"1.0\",  description=\"Простой сервер API, использующий Runnable-интерфейсы GigaChain.\",)# 6. Добавление пути цепочкиadd_routes(    app,    chain,    path=\"/chain\",)if __name__ == \"__main__\":    import uvicorn    uvicorn.run(app, host=\"localhost\", port=8000)Запустите файл:python serve.pyВы увидите, что ваша цепочка доступна по адресу http://localhost:8000.Песочница\\ufeffПриложения GigaServe предоставляют доступ к простому пользовательскому интерфейсу для настройки и вызова приложения с потоковым выводом и отображением промежуточных шагов.\\nВы можете попробовать его по адресу http://localhost:8000/chain/playground/.\\nЗадай такие же входные данные — {\"language\": \"английский\", \"text\": \"привет\"} — приложение должно ответить как и раньше.Клиент\\ufeffДля настройки клиентской части используйте langserve.RemoteRunnable.\\nЭто даст возможность взаимодействовать с доступной цепочкой так, как если бы она выполнялась на стороне клиента.from langserve import RemoteRunnableremote_chain = RemoteRunnable(\"http://localhost:8000/chain/\")remote_chain.invoke({\"language\": \"английский\", \"text\": \"привет\"})    \\'Hello\\'Подробнее — в документации GigaServe.Смотрите также\\ufeffЧтобы глубже погрузиться в разработку приложений с помощью GigaChain, ознакомьтесь с разделами:Обучающие материалы.Основные понятия.Обучающие материалыРазработка чат-бота'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/overview', 'title': 'Обучающие материалы | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/overview', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Обучающие материалы | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Обучающие материалыОбновлено 21 ноября 2024В этом разделе собраны простые примеры, которые наглядно демонстрируют основные особенности и сценарии работы с GigaChain.Всем примеры в этом разделе, как большинство примеров в документации вообще, используют Jupyter-блокноты, которые хранятся в github-репозитории GigaChain.\\nОни отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами.Подробнее об установке Jupyter — в официальной документации.Обучающие материалы будут пополняться по мере адаптации примеров для работы с моделями GigaChat.Следите за обновлениями.Основы\\ufeffРазработка простого LLM-приложения с помощью LCEL.Разработка чат-бота.Работа с векторными хранилищами и ретриверами.Разработка агента.Примеры\\ufeffАгент «Продавец телефонов».Быстрый стартРазработка простого LLM-приложения'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/retrievers', 'title': 'Векторные хранилища и ретриверы | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/tutorials/retrievers', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Векторные хранилища и ретриверы | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Векторные хранилища и ретриверыОбновлено 21 ноября 2024В этом разделе вы узнаете, как использовать GigaChain для работы с векторными хранилищам и ретриверами.\\nРетриверы и векторные хранилища важны для приложений, которые извлекают данные для рассуждений в рамках инференса модели, например, в случае генерации с дополнением извлечения данных или RAG.Основные понятия\\ufeffВ этом разделе основное внимание уделяется извлечению текстовых данных.\\nОсновные понятия:документы;векторные хранилища;ретриверы.Подготовка к разработке\\ufeffJupyter-блокноты\\ufeffКак и большинство других руководств в документации, этот раздел использует Jupyter-блокнот.\\nБлокноты отлично подходят для изучения работы с LLM-системами, так как предоставляют интерактивную среду для работы с руководствами и позволяют работать с непредвиденными ситуациями, например недоступностью API или нетипичным выводом.Подробнее об установке Jupyter — в официальной документации.Установка\\ufeffУстановите пакеты, которые понадобятся для работы с примерами:pip install langchain-gigachat langchain-chromaПодробнее об установке GigaChain — в разделе Установка.Документы\\ufeffGigaChain реализует класс Document, который представляет единицу текста и связанные с ним метаданные.\\nУ этого класса есть два атрибута:page_content — строка, представляющая содержимое;metadata — словарь, содержащий произвольные метаданные.Атрибут metadata может содержать данные об источнике документа, его связи с другими документами и другую дополнительную информацию.\\nОтдельный объект Document часто представляет фрагмент более крупного документа.Создайте несколько образцов документов:from langchain_core.documents import Documentdocuments = [    Document(        page_content=\"Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),    Document(        page_content=\"Кошки — независимые животные, которым нужно собственное пространство.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),    Document(        page_content=\"Золотые рыбки — отличные домашние животные для начинающих. За ними достаточно просто ухаживать.\",        metadata={\"source\": \"fish-pets-doc\"},    ),    Document(        page_content=\"Попугаи — умные птицы, которые способны имитировать человеческую речь.\",        metadata={\"source\": \"bird-pets-doc\"},    ),    Document(        page_content=\"Кролики — социальные животные, которым нужно много места, чтобы прыгать.\",        metadata={\"source\": \"mammal-pets-doc\"},    ),]В примере выше представлено пять документов с дополнительными данными, которые указывают на три различных источника (source).Векторные хранилища\\ufeffВекторный поиск — это распространенный способ поиска по сохраненным неструктурированным данным, например, неструктурированному тексту.\\nВ основе поиска лежит работа с сохраненными числовыми векторами, которые ассоциированы с текстом.\\nПри запросе к хранилищу, вы можете представить текст запроса в виде вектора той же размерности и использовать метрики векторной схожести для поиска подходящих данных в хранилище.Объекты VectorStore предоставляют методы для добавления текста и объектов Document в хранилище, а так же методы для поиска документов в хранилище с использованием различных метрик схожести.\\nКак правило, хранилища инициализируются с использованием моделей, которые поддерживают векторное представление текста.\\nТакие модели определяют, как текстовые данные переводятся в числовые векторы.GigaChain предоставляет набор интеграций с различными векторными хранилищами.\\nНекоторые из них могут требовать соответствующие учетные данные для использования.\\nДругие, такие как Postgres, работают в отдельной инфраструктуре, которую можно запускать локально или через сторонние сервисы.\\nКакие-то могут работать в памяти и используются для легких нагрузок.В этом разделе показана работа объектов VectorStore с использованием Chroma — векторным хранилищем, которое поддерживает работу в памяти.Как правило, для создания векторного хранилища нужно предоставить модель, которая будет отвечать за векторное представление текста.Примере для создания векторного представления текста используется модель GigaChat Embeddings.from langchain_chroma import Chromafrom langchain_gigachat.embeddings.gigachat import GigaChatEmbeddingsvectorstore = Chroma.from_documents(    documents,    embedding=GigaChatEmbeddings(        credentials=\"ключ_авторизации\",        scope=\"GIGACHAT_API_PERS\",        verify_ssl_certs=False,    ),)Авторизационные данные — строка, полученная в результате кодирования в Base64 клиентского идентификатора (Client ID) и ключа (Client Secret) API. Вы можете использовать готовые данные из личного кабинета или самостоятельно закодировать идентификатор и ключ.Пример строки авторизационных данных:MjIzODA0YTktMDU3OC00MTZmLWI4MWYtYzUwNjg3Njk4MzMzOjljMTI2MGQyLTFkNTEtNGRkOS05ZGVhLTBhNjAzZTdjZjQ3Mw==Идентификатор, ключ и авторизационные данные вы можете получить после создания проекта GigaChat API:для физических лиц;для ИП и юридических лиц.Вызов метода .from_documents добавляет документы в векторное хранилище.\\nОбъект VectorStore предоставляет методы для добавления документов, которые также можно вызвать после создания объекта.\\nБольшинство интеграций позволяет подключаться к существующему векторному хранилищу, например, предоставив клиент, название индекса или другую информацию.После создания объекта VectorStore с необходимыми документами, вы можете выполнять поиск по ним.\\nОбъект VectorStore включает методы для выполнения запросов:синхронно и асинхронно;по текстовому запросу и по его вектору;с возвращением и без возвращения оценок схожести;по схожести и максимальной маржинальной релевантности, которая позволяет сбалансировать схожесть с разнообразием в извлеченных результатах.В общем случае результат работы методов будет содержать объектов Document.Примеры\\ufeffВозврат документов на основе схожести с текстовым запросом:vectorstore.similarity_search(\"кошка\")    [Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\'), Document(metadata={\\'source\\': \\'bird-pets-doc\\'}, page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\')]Асинхронный запрос:await vectorstore.asimilarity_search(\"кошка\")    [Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\'), Document(metadata={\\'source\\': \\'bird-pets-doc\\'}, page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\')]Оценка схожести запроса и содержимого хранилища:# Оценка зависит от выбранного векторного хранилища.# Chroma возвращает метрику расстояния, которая должна варьироваться обратно пропорционально схожести.vectorstore.similarity_search_with_score(\"кошка\")    [(Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\'),  218.2356719970703), (Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\'),  319.75384521484375), (Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\'),  349.84930419921875), (Document(metadata={\\'source\\': \\'bird-pets-doc\\'}, page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\'),  352.6993103027344)]Возврат документов на основе схожести с запросом, представленным в виде вектора:embedding = GigaChatEmbeddings(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    verify_ssl_certs=False,).embed_query(\"кошка\")vectorstore.similarity_search_by_vector(embedding)    [Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\'), Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кролики — социальные животные, которым нужно много места, чтобы прыгать.\\'), Document(metadata={\\'source\\': \\'bird-pets-doc\\'}, page_content=\\'Попугаи — умные птицы, которые способны имитировать человеческую речь.\\')]Больше информации о векторных хранилищах:Справка APIРетриверы\\ufeffОбъекты VectorStore не являются Runnable-объектами и поэтому их нельзя использовать в LCEL-цепочках напрямую.В то же время ретриверы GigaChain (Retrievers) — являются экземплярами Runnable, поэтому они реализуют стандартный набор методов (например, синхронные и асинхронные операции invoke и batch) и предназначены для включения в цепочки LCEL.Вы можете самостоятельно создать ретривер, не прибегая к классу Retriever.\\nДля этого нужно выбрать метод, который будет использоваться для извлечения документов, и создать Runnable.\\nПример ниже показывает, как создать ретривер, который использует метод similarity_search, на основе Runnable:from typing import Listfrom langchain_core.documents import Documentfrom langchain_core.runnables import RunnableLambdaretriever = RunnableLambda(vectorstore.similarity_search).bind(    k=1)  # выбор наиболе подходящего результатаretriever.batch([\"кошка\", \"акула\"])    [[Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\')], [Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\')]]Векторные хранилища предоставляют метод as_retriever, который создаст экземпляр класса Retriever, а именно VectorStoreRetriever.\\nЭти ретриверы включают заданные атрибуты search_type и search_kwargs, которые определяют, какие методы базового векторного хранилища вызывать и как задавать их параметры.\\nТак, вы можете повторить функциональность из примера выше с помощью следующего кода:retriever = vectorstore.as_retriever(    search_type=\"similarity\",    search_kwargs={\"k\": 1},)retriever.batch([\"кошка\", \"акула\"])    [[Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Кошки — независимые животные, которым нужно собственное пространство.\\')], [Document(metadata={\\'source\\': \\'mammal-pets-doc\\'}, page_content=\\'Собаки — отличные компаньоны, которые известны своей преданностью и дружелюбием.\\')]]VectorStoreRetriever поддерживает типы поиска \"similarity\" (по умолчанию), \"mmr\" (maximum marginal relevance, описано выше) и \"similarity_score_threshold\".\\nПоследний тип можно использовать для отсечки документов, выводимых ретривером, на основе оценки схожести.Ретриверы можно легко включить в более сложные RAG-приложения, которые объединяют заданный вопрос с извлеченным контекстом в промпт для модели.# | output: false# | echo: falsefrom langchain_gigachat.chat_models import GigaChatmodel = GigaChat(    credentials=\"ключ_авторизации\",    scope=\"GIGACHAT_API_PERS\",    model=\"GigaChat-Pro\",    verify_ssl_certs=False,)from langchain_core.prompts import ChatPromptTemplatefrom langchain_core.runnables import RunnablePassthroughmessage = \"\"\"Отвечай на вопросы только с помощью полученного контекста.{question}Контекст:{context}\"\"\"prompt = ChatPromptTemplate.from_messages([(\"human\", message)])rag_chain = {\"context\": retriever, \"question\": RunnablePassthrough()} | prompt | modelresponse = rag_chain.invoke(\"Расскажи о кошках\")print(response.content)    Кошки – это независимые животные, которым требуется свое собственное пространство.Разработка чат-ботаСоздание агента'),\n",
       " Document(metadata={'source': 'https://developers.sber.ru/docs/ru/gigachain/video-tutorials', 'title': 'Обучающие видео | Документация для разработчиков | langchain-gigachat', 'description': '', 'language': '', 'loc': 'https://developers.sber.ru/docs/ru/gigachain/video-tutorials', 'changefreq': 'weekly', 'priority': '0.5'}, page_content='Обучающие видео | Документация для разработчиковЭто полезныйматериал?Это полезный материал?Обучающие видеоОбновлено 11 сентября 2024В этом разделе собраны обучающие видео по работе с GigaChain.НазваниеТипАвторВводное видео о возможностях API на платформе EdutoriaВидеоБыстрый старт: GigaChat API и GigaChain за 1 минутуВидеоКак общаться с GigaChat API с помощью GigaChain? (Туториал)ВидеоурокСергей ТращенковКак сделать агентов на основе GigaChat? Подробный туториал на PythonВидеоурокСергей ТращенковРеализация RAG на основе GigaChat. Как искать и генерировать ответы по базе знаний?ВидеоурокСергей ТращенковGigaChain. Как загрузить документы, чтобы ИИ отвечал по ним?ВидеоурокСергей ТращенковRAG. Делаем вопросно-ответную систему с поиском по базе видеороликовВидеоурокСергей ТращенковGigaChat API и БД. Как можно общаться с базами данных с помощью ИИ?ВидеоурокСергей ТращенковРабота с LLM GigaChatКурсGigaChat: нейросетевая модель для маркетологов и не толькоКурсШаблоны промптов')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gigachain_docs = load_langchain_gigachat_docs()\n",
    "gigachain_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_docs = []\n",
    "all_docs.extend(gigachat_docs)\n",
    "all_docs.extend(gigachain_docs)\n",
    "len(all_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents splited. Count: 324\n"
     ]
    }
   ],
   "source": [
    "from langchain.text_splitter import MarkdownTextSplitter\n",
    "\n",
    "text_splitter = MarkdownTextSplitter(chunk_size=2000, chunk_overlap=500)\n",
    "doc_splits = text_splitter.split_documents(all_docs)\n",
    "print(f\"Documents splited. Count: {len(doc_splits)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tqdm\n",
    "from pinecone import Pinecone, ServerlessSpec\n",
    "\n",
    "pinecone_api_key = os.environ.get(\"PINECONE_API_KEY\")\n",
    "pc = Pinecone(api_key=pinecone_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "index_name = os.environ.get(\"PINECONE_INDEX_NAME\", \"gigachain-test-gigar-newdb\")\n",
    "pc.create_index(\n",
    "    name=index_name,\n",
    "    dimension=2560,\n",
    "    metric=\"cosine\",\n",
    "    spec=ServerlessSpec(cloud=\"aws\", region=\"us-east-1\"),\n",
    ")\n",
    "while not pc.describe_index(index_name).status[\"ready\"]:\n",
    "    time.sleep(1)\n",
    "    \n",
    "index = pc.Index(index_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings.gigachat import GigaChatEmbeddings\n",
    "embeddings = GigaChatEmbeddings(model=\"EmbeddingsGigaR\")\n",
    "# from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "# embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_pinecone import PineconeVectorStore\n",
    "vector_store = PineconeVectorStore(index=index, embedding=embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Загрузка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "from uuid import uuid4\n",
    "uuids = [str(uuid4()) for _ in range(len(doc_splits))]\n",
    "vector_store.add_documents(documents=doc_splits, ids=uuids)\n",
    "retriever = vector_store.as_retriever()\n",
    "print(\"OK\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
